// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: spark/connect/expressions.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

//
// Licensed to the Apache Software Foundation (ASF) under one or more
// contributor license agreements.  See the NOTICE file distributed with
// this work for additional information regarding copyright ownership.
// The ASF licenses this file to You under the Apache License, Version 2.0
// (the "License"); you may not use this file except in compliance with
// the License.  You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import Foundation
import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Expression used to refer to fields, functions and similar. This can be used everywhere
/// expressions in SQL appear.
struct Spark_Connect_Expression: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var common: Spark_Connect_ExpressionCommon {
    get {return _storage._common ?? Spark_Connect_ExpressionCommon()}
    set {_uniqueStorage()._common = newValue}
  }
  /// Returns true if `common` has been explicitly set.
  var hasCommon: Bool {return _storage._common != nil}
  /// Clears the value of `common`. Subsequent reads from it will return its default value.
  mutating func clearCommon() {_uniqueStorage()._common = nil}

  var exprType: OneOf_ExprType? {
    get {return _storage._exprType}
    set {_uniqueStorage()._exprType = newValue}
  }

  var literal: Spark_Connect_Expression.Literal {
    get {
      if case .literal(let v)? = _storage._exprType {return v}
      return Spark_Connect_Expression.Literal()
    }
    set {_uniqueStorage()._exprType = .literal(newValue)}
  }

  var unresolvedAttribute: Spark_Connect_Expression.UnresolvedAttribute {
    get {
      if case .unresolvedAttribute(let v)? = _storage._exprType {return v}
      return Spark_Connect_Expression.UnresolvedAttribute()
    }
    set {_uniqueStorage()._exprType = .unresolvedAttribute(newValue)}
  }

  var unresolvedFunction: Spark_Connect_Expression.UnresolvedFunction {
    get {
      if case .unresolvedFunction(let v)? = _storage._exprType {return v}
      return Spark_Connect_Expression.UnresolvedFunction()
    }
    set {_uniqueStorage()._exprType = .unresolvedFunction(newValue)}
  }

  var expressionString: Spark_Connect_Expression.ExpressionString {
    get {
      if case .expressionString(let v)? = _storage._exprType {return v}
      return Spark_Connect_Expression.ExpressionString()
    }
    set {_uniqueStorage()._exprType = .expressionString(newValue)}
  }

  var unresolvedStar: Spark_Connect_Expression.UnresolvedStar {
    get {
      if case .unresolvedStar(let v)? = _storage._exprType {return v}
      return Spark_Connect_Expression.UnresolvedStar()
    }
    set {_uniqueStorage()._exprType = .unresolvedStar(newValue)}
  }

  var alias: Spark_Connect_Expression.Alias {
    get {
      if case .alias(let v)? = _storage._exprType {return v}
      return Spark_Connect_Expression.Alias()
    }
    set {_uniqueStorage()._exprType = .alias(newValue)}
  }

  var cast: Spark_Connect_Expression.Cast {
    get {
      if case .cast(let v)? = _storage._exprType {return v}
      return Spark_Connect_Expression.Cast()
    }
    set {_uniqueStorage()._exprType = .cast(newValue)}
  }

  var unresolvedRegex: Spark_Connect_Expression.UnresolvedRegex {
    get {
      if case .unresolvedRegex(let v)? = _storage._exprType {return v}
      return Spark_Connect_Expression.UnresolvedRegex()
    }
    set {_uniqueStorage()._exprType = .unresolvedRegex(newValue)}
  }

  var sortOrder: Spark_Connect_Expression.SortOrder {
    get {
      if case .sortOrder(let v)? = _storage._exprType {return v}
      return Spark_Connect_Expression.SortOrder()
    }
    set {_uniqueStorage()._exprType = .sortOrder(newValue)}
  }

  var lambdaFunction: Spark_Connect_Expression.LambdaFunction {
    get {
      if case .lambdaFunction(let v)? = _storage._exprType {return v}
      return Spark_Connect_Expression.LambdaFunction()
    }
    set {_uniqueStorage()._exprType = .lambdaFunction(newValue)}
  }

  var window: Spark_Connect_Expression.Window {
    get {
      if case .window(let v)? = _storage._exprType {return v}
      return Spark_Connect_Expression.Window()
    }
    set {_uniqueStorage()._exprType = .window(newValue)}
  }

  var unresolvedExtractValue: Spark_Connect_Expression.UnresolvedExtractValue {
    get {
      if case .unresolvedExtractValue(let v)? = _storage._exprType {return v}
      return Spark_Connect_Expression.UnresolvedExtractValue()
    }
    set {_uniqueStorage()._exprType = .unresolvedExtractValue(newValue)}
  }

  var updateFields: Spark_Connect_Expression.UpdateFields {
    get {
      if case .updateFields(let v)? = _storage._exprType {return v}
      return Spark_Connect_Expression.UpdateFields()
    }
    set {_uniqueStorage()._exprType = .updateFields(newValue)}
  }

  var unresolvedNamedLambdaVariable: Spark_Connect_Expression.UnresolvedNamedLambdaVariable {
    get {
      if case .unresolvedNamedLambdaVariable(let v)? = _storage._exprType {return v}
      return Spark_Connect_Expression.UnresolvedNamedLambdaVariable()
    }
    set {_uniqueStorage()._exprType = .unresolvedNamedLambdaVariable(newValue)}
  }

  var commonInlineUserDefinedFunction: Spark_Connect_CommonInlineUserDefinedFunction {
    get {
      if case .commonInlineUserDefinedFunction(let v)? = _storage._exprType {return v}
      return Spark_Connect_CommonInlineUserDefinedFunction()
    }
    set {_uniqueStorage()._exprType = .commonInlineUserDefinedFunction(newValue)}
  }

  var callFunction: Spark_Connect_CallFunction {
    get {
      if case .callFunction(let v)? = _storage._exprType {return v}
      return Spark_Connect_CallFunction()
    }
    set {_uniqueStorage()._exprType = .callFunction(newValue)}
  }

  var namedArgumentExpression: Spark_Connect_NamedArgumentExpression {
    get {
      if case .namedArgumentExpression(let v)? = _storage._exprType {return v}
      return Spark_Connect_NamedArgumentExpression()
    }
    set {_uniqueStorage()._exprType = .namedArgumentExpression(newValue)}
  }

  var mergeAction: Spark_Connect_MergeAction {
    get {
      if case .mergeAction(let v)? = _storage._exprType {return v}
      return Spark_Connect_MergeAction()
    }
    set {_uniqueStorage()._exprType = .mergeAction(newValue)}
  }

  var typedAggregateExpression: Spark_Connect_TypedAggregateExpression {
    get {
      if case .typedAggregateExpression(let v)? = _storage._exprType {return v}
      return Spark_Connect_TypedAggregateExpression()
    }
    set {_uniqueStorage()._exprType = .typedAggregateExpression(newValue)}
  }

  var subqueryExpression: Spark_Connect_SubqueryExpression {
    get {
      if case .subqueryExpression(let v)? = _storage._exprType {return v}
      return Spark_Connect_SubqueryExpression()
    }
    set {_uniqueStorage()._exprType = .subqueryExpression(newValue)}
  }

  /// This field is used to mark extensions to the protocol. When plugins generate arbitrary
  /// relations they can add them here. During the planning the correct resolution is done.
  var `extension`: SwiftProtobuf.Google_Protobuf_Any {
    get {
      if case .extension(let v)? = _storage._exprType {return v}
      return SwiftProtobuf.Google_Protobuf_Any()
    }
    set {_uniqueStorage()._exprType = .extension(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_ExprType: Equatable, Sendable {
    case literal(Spark_Connect_Expression.Literal)
    case unresolvedAttribute(Spark_Connect_Expression.UnresolvedAttribute)
    case unresolvedFunction(Spark_Connect_Expression.UnresolvedFunction)
    case expressionString(Spark_Connect_Expression.ExpressionString)
    case unresolvedStar(Spark_Connect_Expression.UnresolvedStar)
    case alias(Spark_Connect_Expression.Alias)
    case cast(Spark_Connect_Expression.Cast)
    case unresolvedRegex(Spark_Connect_Expression.UnresolvedRegex)
    case sortOrder(Spark_Connect_Expression.SortOrder)
    case lambdaFunction(Spark_Connect_Expression.LambdaFunction)
    case window(Spark_Connect_Expression.Window)
    case unresolvedExtractValue(Spark_Connect_Expression.UnresolvedExtractValue)
    case updateFields(Spark_Connect_Expression.UpdateFields)
    case unresolvedNamedLambdaVariable(Spark_Connect_Expression.UnresolvedNamedLambdaVariable)
    case commonInlineUserDefinedFunction(Spark_Connect_CommonInlineUserDefinedFunction)
    case callFunction(Spark_Connect_CallFunction)
    case namedArgumentExpression(Spark_Connect_NamedArgumentExpression)
    case mergeAction(Spark_Connect_MergeAction)
    case typedAggregateExpression(Spark_Connect_TypedAggregateExpression)
    case subqueryExpression(Spark_Connect_SubqueryExpression)
    /// This field is used to mark extensions to the protocol. When plugins generate arbitrary
    /// relations they can add them here. During the planning the correct resolution is done.
    case `extension`(SwiftProtobuf.Google_Protobuf_Any)

  }

  /// Expression for the OVER clause or WINDOW clause.
  struct Window: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) The window function.
    var windowFunction: Spark_Connect_Expression {
      get {return _storage._windowFunction ?? Spark_Connect_Expression()}
      set {_uniqueStorage()._windowFunction = newValue}
    }
    /// Returns true if `windowFunction` has been explicitly set.
    var hasWindowFunction: Bool {return _storage._windowFunction != nil}
    /// Clears the value of `windowFunction`. Subsequent reads from it will return its default value.
    mutating func clearWindowFunction() {_uniqueStorage()._windowFunction = nil}

    /// (Optional) The way that input rows are partitioned.
    var partitionSpec: [Spark_Connect_Expression] {
      get {return _storage._partitionSpec}
      set {_uniqueStorage()._partitionSpec = newValue}
    }

    /// (Optional) Ordering of rows in a partition.
    var orderSpec: [Spark_Connect_Expression.SortOrder] {
      get {return _storage._orderSpec}
      set {_uniqueStorage()._orderSpec = newValue}
    }

    /// (Optional) Window frame in a partition.
    ///
    /// If not set, it will be treated as 'UnspecifiedFrame'.
    var frameSpec: Spark_Connect_Expression.Window.WindowFrame {
      get {return _storage._frameSpec ?? Spark_Connect_Expression.Window.WindowFrame()}
      set {_uniqueStorage()._frameSpec = newValue}
    }
    /// Returns true if `frameSpec` has been explicitly set.
    var hasFrameSpec: Bool {return _storage._frameSpec != nil}
    /// Clears the value of `frameSpec`. Subsequent reads from it will return its default value.
    mutating func clearFrameSpec() {_uniqueStorage()._frameSpec = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    /// The window frame
    struct WindowFrame: @unchecked Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      /// (Required) The type of the frame.
      var frameType: Spark_Connect_Expression.Window.WindowFrame.FrameType {
        get {return _storage._frameType}
        set {_uniqueStorage()._frameType = newValue}
      }

      /// (Required) The lower bound of the frame.
      var lower: Spark_Connect_Expression.Window.WindowFrame.FrameBoundary {
        get {return _storage._lower ?? Spark_Connect_Expression.Window.WindowFrame.FrameBoundary()}
        set {_uniqueStorage()._lower = newValue}
      }
      /// Returns true if `lower` has been explicitly set.
      var hasLower: Bool {return _storage._lower != nil}
      /// Clears the value of `lower`. Subsequent reads from it will return its default value.
      mutating func clearLower() {_uniqueStorage()._lower = nil}

      /// (Required) The upper bound of the frame.
      var upper: Spark_Connect_Expression.Window.WindowFrame.FrameBoundary {
        get {return _storage._upper ?? Spark_Connect_Expression.Window.WindowFrame.FrameBoundary()}
        set {_uniqueStorage()._upper = newValue}
      }
      /// Returns true if `upper` has been explicitly set.
      var hasUpper: Bool {return _storage._upper != nil}
      /// Clears the value of `upper`. Subsequent reads from it will return its default value.
      mutating func clearUpper() {_uniqueStorage()._upper = nil}

      var unknownFields = SwiftProtobuf.UnknownStorage()

      enum FrameType: SwiftProtobuf.Enum, Swift.CaseIterable {
        typealias RawValue = Int
        case undefined // = 0

        /// RowFrame treats rows in a partition individually.
        case row // = 1

        /// RangeFrame treats rows in a partition as groups of peers.
        /// All rows having the same 'ORDER BY' ordering are considered as peers.
        case range // = 2
        case UNRECOGNIZED(Int)

        init() {
          self = .undefined
        }

        init?(rawValue: Int) {
          switch rawValue {
          case 0: self = .undefined
          case 1: self = .row
          case 2: self = .range
          default: self = .UNRECOGNIZED(rawValue)
          }
        }

        var rawValue: Int {
          switch self {
          case .undefined: return 0
          case .row: return 1
          case .range: return 2
          case .UNRECOGNIZED(let i): return i
          }
        }

        // The compiler won't synthesize support with the UNRECOGNIZED case.
        static let allCases: [Spark_Connect_Expression.Window.WindowFrame.FrameType] = [
          .undefined,
          .row,
          .range,
        ]

      }

      struct FrameBoundary: @unchecked Sendable {
        // SwiftProtobuf.Message conformance is added in an extension below. See the
        // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
        // methods supported on all messages.

        var boundary: OneOf_Boundary? {
          get {return _storage._boundary}
          set {_uniqueStorage()._boundary = newValue}
        }

        /// CURRENT ROW boundary
        var currentRow: Bool {
          get {
            if case .currentRow(let v)? = _storage._boundary {return v}
            return false
          }
          set {_uniqueStorage()._boundary = .currentRow(newValue)}
        }

        /// UNBOUNDED boundary.
        /// For lower bound, it will be converted to 'UnboundedPreceding'.
        /// for upper bound, it will be converted to 'UnboundedFollowing'.
        var unbounded: Bool {
          get {
            if case .unbounded(let v)? = _storage._boundary {return v}
            return false
          }
          set {_uniqueStorage()._boundary = .unbounded(newValue)}
        }

        /// This is an expression for future proofing. We are expecting literals on the server side.
        var value: Spark_Connect_Expression {
          get {
            if case .value(let v)? = _storage._boundary {return v}
            return Spark_Connect_Expression()
          }
          set {_uniqueStorage()._boundary = .value(newValue)}
        }

        var unknownFields = SwiftProtobuf.UnknownStorage()

        enum OneOf_Boundary: Equatable, Sendable {
          /// CURRENT ROW boundary
          case currentRow(Bool)
          /// UNBOUNDED boundary.
          /// For lower bound, it will be converted to 'UnboundedPreceding'.
          /// for upper bound, it will be converted to 'UnboundedFollowing'.
          case unbounded(Bool)
          /// This is an expression for future proofing. We are expecting literals on the server side.
          case value(Spark_Connect_Expression)

        }

        init() {}

        fileprivate var _storage = _StorageClass.defaultInstance
      }

      init() {}

      fileprivate var _storage = _StorageClass.defaultInstance
    }

    init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  /// SortOrder is used to specify the  data ordering, it is normally used in Sort and Window.
  /// It is an unevaluable expression and cannot be evaluated, so can not be used in Projection.
  struct SortOrder: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) The expression to be sorted.
    var child: Spark_Connect_Expression {
      get {return _storage._child ?? Spark_Connect_Expression()}
      set {_uniqueStorage()._child = newValue}
    }
    /// Returns true if `child` has been explicitly set.
    var hasChild: Bool {return _storage._child != nil}
    /// Clears the value of `child`. Subsequent reads from it will return its default value.
    mutating func clearChild() {_uniqueStorage()._child = nil}

    /// (Required) The sort direction, should be ASCENDING or DESCENDING.
    var direction: Spark_Connect_Expression.SortOrder.SortDirection {
      get {return _storage._direction}
      set {_uniqueStorage()._direction = newValue}
    }

    /// (Required) How to deal with NULLs, should be NULLS_FIRST or NULLS_LAST.
    var nullOrdering: Spark_Connect_Expression.SortOrder.NullOrdering {
      get {return _storage._nullOrdering}
      set {_uniqueStorage()._nullOrdering = newValue}
    }

    var unknownFields = SwiftProtobuf.UnknownStorage()

    enum SortDirection: SwiftProtobuf.Enum, Swift.CaseIterable {
      typealias RawValue = Int
      case unspecified // = 0
      case ascending // = 1
      case descending // = 2
      case UNRECOGNIZED(Int)

      init() {
        self = .unspecified
      }

      init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .unspecified
        case 1: self = .ascending
        case 2: self = .descending
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      var rawValue: Int {
        switch self {
        case .unspecified: return 0
        case .ascending: return 1
        case .descending: return 2
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      static let allCases: [Spark_Connect_Expression.SortOrder.SortDirection] = [
        .unspecified,
        .ascending,
        .descending,
      ]

    }

    enum NullOrdering: SwiftProtobuf.Enum, Swift.CaseIterable {
      typealias RawValue = Int
      case sortNullsUnspecified // = 0
      case sortNullsFirst // = 1
      case sortNullsLast // = 2
      case UNRECOGNIZED(Int)

      init() {
        self = .sortNullsUnspecified
      }

      init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .sortNullsUnspecified
        case 1: self = .sortNullsFirst
        case 2: self = .sortNullsLast
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      var rawValue: Int {
        switch self {
        case .sortNullsUnspecified: return 0
        case .sortNullsFirst: return 1
        case .sortNullsLast: return 2
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      static let allCases: [Spark_Connect_Expression.SortOrder.NullOrdering] = [
        .sortNullsUnspecified,
        .sortNullsFirst,
        .sortNullsLast,
      ]

    }

    init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  struct Cast: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) the expression to be casted.
    var expr: Spark_Connect_Expression {
      get {return _storage._expr ?? Spark_Connect_Expression()}
      set {_uniqueStorage()._expr = newValue}
    }
    /// Returns true if `expr` has been explicitly set.
    var hasExpr: Bool {return _storage._expr != nil}
    /// Clears the value of `expr`. Subsequent reads from it will return its default value.
    mutating func clearExpr() {_uniqueStorage()._expr = nil}

    /// (Required) the data type that the expr to be casted to.
    var castToType: OneOf_CastToType? {
      get {return _storage._castToType}
      set {_uniqueStorage()._castToType = newValue}
    }

    var type: Spark_Connect_DataType {
      get {
        if case .type(let v)? = _storage._castToType {return v}
        return Spark_Connect_DataType()
      }
      set {_uniqueStorage()._castToType = .type(newValue)}
    }

    /// If this is set, Server will use Catalyst parser to parse this string to DataType.
    var typeStr: String {
      get {
        if case .typeStr(let v)? = _storage._castToType {return v}
        return String()
      }
      set {_uniqueStorage()._castToType = .typeStr(newValue)}
    }

    /// (Optional) The expression evaluation mode.
    var evalMode: Spark_Connect_Expression.Cast.EvalMode {
      get {return _storage._evalMode}
      set {_uniqueStorage()._evalMode = newValue}
    }

    var unknownFields = SwiftProtobuf.UnknownStorage()

    /// (Required) the data type that the expr to be casted to.
    enum OneOf_CastToType: Equatable, Sendable {
      case type(Spark_Connect_DataType)
      /// If this is set, Server will use Catalyst parser to parse this string to DataType.
      case typeStr(String)

    }

    enum EvalMode: SwiftProtobuf.Enum, Swift.CaseIterable {
      typealias RawValue = Int
      case unspecified // = 0
      case legacy // = 1
      case ansi // = 2
      case `try` // = 3
      case UNRECOGNIZED(Int)

      init() {
        self = .unspecified
      }

      init?(rawValue: Int) {
        switch rawValue {
        case 0: self = .unspecified
        case 1: self = .legacy
        case 2: self = .ansi
        case 3: self = .try
        default: self = .UNRECOGNIZED(rawValue)
        }
      }

      var rawValue: Int {
        switch self {
        case .unspecified: return 0
        case .legacy: return 1
        case .ansi: return 2
        case .try: return 3
        case .UNRECOGNIZED(let i): return i
        }
      }

      // The compiler won't synthesize support with the UNRECOGNIZED case.
      static let allCases: [Spark_Connect_Expression.Cast.EvalMode] = [
        .unspecified,
        .legacy,
        .ansi,
        .try,
      ]

    }

    init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  struct Literal: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var literalType: Spark_Connect_Expression.Literal.OneOf_LiteralType? = nil

    var null: Spark_Connect_DataType {
      get {
        if case .null(let v)? = literalType {return v}
        return Spark_Connect_DataType()
      }
      set {literalType = .null(newValue)}
    }

    var binary: Data {
      get {
        if case .binary(let v)? = literalType {return v}
        return Data()
      }
      set {literalType = .binary(newValue)}
    }

    var boolean: Bool {
      get {
        if case .boolean(let v)? = literalType {return v}
        return false
      }
      set {literalType = .boolean(newValue)}
    }

    var byte: Int32 {
      get {
        if case .byte(let v)? = literalType {return v}
        return 0
      }
      set {literalType = .byte(newValue)}
    }

    var short: Int32 {
      get {
        if case .short(let v)? = literalType {return v}
        return 0
      }
      set {literalType = .short(newValue)}
    }

    var integer: Int32 {
      get {
        if case .integer(let v)? = literalType {return v}
        return 0
      }
      set {literalType = .integer(newValue)}
    }

    var long: Int64 {
      get {
        if case .long(let v)? = literalType {return v}
        return 0
      }
      set {literalType = .long(newValue)}
    }

    var float: Float {
      get {
        if case .float(let v)? = literalType {return v}
        return 0
      }
      set {literalType = .float(newValue)}
    }

    var double: Double {
      get {
        if case .double(let v)? = literalType {return v}
        return 0
      }
      set {literalType = .double(newValue)}
    }

    var decimal: Spark_Connect_Expression.Literal.Decimal {
      get {
        if case .decimal(let v)? = literalType {return v}
        return Spark_Connect_Expression.Literal.Decimal()
      }
      set {literalType = .decimal(newValue)}
    }

    var string: String {
      get {
        if case .string(let v)? = literalType {return v}
        return String()
      }
      set {literalType = .string(newValue)}
    }

    /// Date in units of days since the UNIX epoch.
    var date: Int32 {
      get {
        if case .date(let v)? = literalType {return v}
        return 0
      }
      set {literalType = .date(newValue)}
    }

    /// Timestamp in units of microseconds since the UNIX epoch.
    var timestamp: Int64 {
      get {
        if case .timestamp(let v)? = literalType {return v}
        return 0
      }
      set {literalType = .timestamp(newValue)}
    }

    /// Timestamp in units of microseconds since the UNIX epoch (without timezone information).
    var timestampNtz: Int64 {
      get {
        if case .timestampNtz(let v)? = literalType {return v}
        return 0
      }
      set {literalType = .timestampNtz(newValue)}
    }

    var calendarInterval: Spark_Connect_Expression.Literal.CalendarInterval {
      get {
        if case .calendarInterval(let v)? = literalType {return v}
        return Spark_Connect_Expression.Literal.CalendarInterval()
      }
      set {literalType = .calendarInterval(newValue)}
    }

    var yearMonthInterval: Int32 {
      get {
        if case .yearMonthInterval(let v)? = literalType {return v}
        return 0
      }
      set {literalType = .yearMonthInterval(newValue)}
    }

    var dayTimeInterval: Int64 {
      get {
        if case .dayTimeInterval(let v)? = literalType {return v}
        return 0
      }
      set {literalType = .dayTimeInterval(newValue)}
    }

    var array: Spark_Connect_Expression.Literal.Array {
      get {
        if case .array(let v)? = literalType {return v}
        return Spark_Connect_Expression.Literal.Array()
      }
      set {literalType = .array(newValue)}
    }

    var map: Spark_Connect_Expression.Literal.Map {
      get {
        if case .map(let v)? = literalType {return v}
        return Spark_Connect_Expression.Literal.Map()
      }
      set {literalType = .map(newValue)}
    }

    var `struct`: Spark_Connect_Expression.Literal.Struct {
      get {
        if case .struct(let v)? = literalType {return v}
        return Spark_Connect_Expression.Literal.Struct()
      }
      set {literalType = .struct(newValue)}
    }

    var specializedArray: Spark_Connect_Expression.Literal.SpecializedArray {
      get {
        if case .specializedArray(let v)? = literalType {return v}
        return Spark_Connect_Expression.Literal.SpecializedArray()
      }
      set {literalType = .specializedArray(newValue)}
    }

    var unknownFields = SwiftProtobuf.UnknownStorage()

    enum OneOf_LiteralType: Equatable, @unchecked Sendable {
      case null(Spark_Connect_DataType)
      case binary(Data)
      case boolean(Bool)
      case byte(Int32)
      case short(Int32)
      case integer(Int32)
      case long(Int64)
      case float(Float)
      case double(Double)
      case decimal(Spark_Connect_Expression.Literal.Decimal)
      case string(String)
      /// Date in units of days since the UNIX epoch.
      case date(Int32)
      /// Timestamp in units of microseconds since the UNIX epoch.
      case timestamp(Int64)
      /// Timestamp in units of microseconds since the UNIX epoch (without timezone information).
      case timestampNtz(Int64)
      case calendarInterval(Spark_Connect_Expression.Literal.CalendarInterval)
      case yearMonthInterval(Int32)
      case dayTimeInterval(Int64)
      case array(Spark_Connect_Expression.Literal.Array)
      case map(Spark_Connect_Expression.Literal.Map)
      case `struct`(Spark_Connect_Expression.Literal.Struct)
      case specializedArray(Spark_Connect_Expression.Literal.SpecializedArray)

    }

    struct Decimal: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      /// the string representation.
      var value: String = String()

      /// The maximum number of digits allowed in the value.
      /// the maximum precision is 38.
      var precision: Int32 {
        get {return _precision ?? 0}
        set {_precision = newValue}
      }
      /// Returns true if `precision` has been explicitly set.
      var hasPrecision: Bool {return self._precision != nil}
      /// Clears the value of `precision`. Subsequent reads from it will return its default value.
      mutating func clearPrecision() {self._precision = nil}

      /// declared scale of decimal literal
      var scale: Int32 {
        get {return _scale ?? 0}
        set {_scale = newValue}
      }
      /// Returns true if `scale` has been explicitly set.
      var hasScale: Bool {return self._scale != nil}
      /// Clears the value of `scale`. Subsequent reads from it will return its default value.
      mutating func clearScale() {self._scale = nil}

      var unknownFields = SwiftProtobuf.UnknownStorage()

      init() {}

      fileprivate var _precision: Int32? = nil
      fileprivate var _scale: Int32? = nil
    }

    struct CalendarInterval: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      var months: Int32 = 0

      var days: Int32 = 0

      var microseconds: Int64 = 0

      var unknownFields = SwiftProtobuf.UnknownStorage()

      init() {}
    }

    struct Array: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      var elementType: Spark_Connect_DataType {
        get {return _elementType ?? Spark_Connect_DataType()}
        set {_elementType = newValue}
      }
      /// Returns true if `elementType` has been explicitly set.
      var hasElementType: Bool {return self._elementType != nil}
      /// Clears the value of `elementType`. Subsequent reads from it will return its default value.
      mutating func clearElementType() {self._elementType = nil}

      var elements: [Spark_Connect_Expression.Literal] = []

      var unknownFields = SwiftProtobuf.UnknownStorage()

      init() {}

      fileprivate var _elementType: Spark_Connect_DataType? = nil
    }

    struct Map: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      var keyType: Spark_Connect_DataType {
        get {return _keyType ?? Spark_Connect_DataType()}
        set {_keyType = newValue}
      }
      /// Returns true if `keyType` has been explicitly set.
      var hasKeyType: Bool {return self._keyType != nil}
      /// Clears the value of `keyType`. Subsequent reads from it will return its default value.
      mutating func clearKeyType() {self._keyType = nil}

      var valueType: Spark_Connect_DataType {
        get {return _valueType ?? Spark_Connect_DataType()}
        set {_valueType = newValue}
      }
      /// Returns true if `valueType` has been explicitly set.
      var hasValueType: Bool {return self._valueType != nil}
      /// Clears the value of `valueType`. Subsequent reads from it will return its default value.
      mutating func clearValueType() {self._valueType = nil}

      var keys: [Spark_Connect_Expression.Literal] = []

      var values: [Spark_Connect_Expression.Literal] = []

      var unknownFields = SwiftProtobuf.UnknownStorage()

      init() {}

      fileprivate var _keyType: Spark_Connect_DataType? = nil
      fileprivate var _valueType: Spark_Connect_DataType? = nil
    }

    struct Struct: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      var structType: Spark_Connect_DataType {
        get {return _structType ?? Spark_Connect_DataType()}
        set {_structType = newValue}
      }
      /// Returns true if `structType` has been explicitly set.
      var hasStructType: Bool {return self._structType != nil}
      /// Clears the value of `structType`. Subsequent reads from it will return its default value.
      mutating func clearStructType() {self._structType = nil}

      var elements: [Spark_Connect_Expression.Literal] = []

      var unknownFields = SwiftProtobuf.UnknownStorage()

      init() {}

      fileprivate var _structType: Spark_Connect_DataType? = nil
    }

    struct SpecializedArray: Sendable {
      // SwiftProtobuf.Message conformance is added in an extension below. See the
      // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
      // methods supported on all messages.

      var valueType: Spark_Connect_Expression.Literal.SpecializedArray.OneOf_ValueType? = nil

      var bools: Spark_Connect_Bools {
        get {
          if case .bools(let v)? = valueType {return v}
          return Spark_Connect_Bools()
        }
        set {valueType = .bools(newValue)}
      }

      var ints: Spark_Connect_Ints {
        get {
          if case .ints(let v)? = valueType {return v}
          return Spark_Connect_Ints()
        }
        set {valueType = .ints(newValue)}
      }

      var longs: Spark_Connect_Longs {
        get {
          if case .longs(let v)? = valueType {return v}
          return Spark_Connect_Longs()
        }
        set {valueType = .longs(newValue)}
      }

      var floats: Spark_Connect_Floats {
        get {
          if case .floats(let v)? = valueType {return v}
          return Spark_Connect_Floats()
        }
        set {valueType = .floats(newValue)}
      }

      var doubles: Spark_Connect_Doubles {
        get {
          if case .doubles(let v)? = valueType {return v}
          return Spark_Connect_Doubles()
        }
        set {valueType = .doubles(newValue)}
      }

      var strings: Spark_Connect_Strings {
        get {
          if case .strings(let v)? = valueType {return v}
          return Spark_Connect_Strings()
        }
        set {valueType = .strings(newValue)}
      }

      var unknownFields = SwiftProtobuf.UnknownStorage()

      enum OneOf_ValueType: Equatable, Sendable {
        case bools(Spark_Connect_Bools)
        case ints(Spark_Connect_Ints)
        case longs(Spark_Connect_Longs)
        case floats(Spark_Connect_Floats)
        case doubles(Spark_Connect_Doubles)
        case strings(Spark_Connect_Strings)

      }

      init() {}
    }

    init() {}
  }

  /// An unresolved attribute that is not explicitly bound to a specific column, but the column
  /// is resolved during analysis by name.
  struct UnresolvedAttribute: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) An identifier that will be parsed by Catalyst parser. This should follow the
    /// Spark SQL identifier syntax.
    var unparsedIdentifier: String = String()

    /// (Optional) The id of corresponding connect plan.
    var planID: Int64 {
      get {return _planID ?? 0}
      set {_planID = newValue}
    }
    /// Returns true if `planID` has been explicitly set.
    var hasPlanID: Bool {return self._planID != nil}
    /// Clears the value of `planID`. Subsequent reads from it will return its default value.
    mutating func clearPlanID() {self._planID = nil}

    /// (Optional) The requested column is a metadata column.
    var isMetadataColumn: Bool {
      get {return _isMetadataColumn ?? false}
      set {_isMetadataColumn = newValue}
    }
    /// Returns true if `isMetadataColumn` has been explicitly set.
    var hasIsMetadataColumn: Bool {return self._isMetadataColumn != nil}
    /// Clears the value of `isMetadataColumn`. Subsequent reads from it will return its default value.
    mutating func clearIsMetadataColumn() {self._isMetadataColumn = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _planID: Int64? = nil
    fileprivate var _isMetadataColumn: Bool? = nil
  }

  /// An unresolved function is not explicitly bound to one explicit function, but the function
  /// is resolved during analysis following Sparks name resolution rules.
  struct UnresolvedFunction: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) name (or unparsed name for user defined function) for the unresolved function.
    var functionName: String = String()

    /// (Optional) Function arguments. Empty arguments are allowed.
    var arguments: [Spark_Connect_Expression] = []

    /// (Required) Indicate if this function should be applied on distinct values.
    var isDistinct: Bool = false

    /// (Required) Indicate if this is a user defined function.
    ///
    /// When it is not a user defined function, Connect will use the function name directly.
    /// When it is a user defined function, Connect will parse the function name first.
    var isUserDefinedFunction: Bool = false

    /// (Optional) Indicate if this function is defined in the internal function registry.
    /// If not set, the server will try to look up the function in the internal function registry
    /// and decide appropriately.
    var isInternal: Bool {
      get {return _isInternal ?? false}
      set {_isInternal = newValue}
    }
    /// Returns true if `isInternal` has been explicitly set.
    var hasIsInternal: Bool {return self._isInternal != nil}
    /// Clears the value of `isInternal`. Subsequent reads from it will return its default value.
    mutating func clearIsInternal() {self._isInternal = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _isInternal: Bool? = nil
  }

  /// Expression as string.
  struct ExpressionString: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) A SQL expression that will be parsed by Catalyst parser.
    var expression: String = String()

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  /// UnresolvedStar is used to expand all the fields of a relation or struct.
  struct UnresolvedStar: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Optional) The target of the expansion.
    ///
    /// If set, it should end with '.*' and will be parsed by 'parseAttributeName'
    /// in the server side.
    var unparsedTarget: String {
      get {return _unparsedTarget ?? String()}
      set {_unparsedTarget = newValue}
    }
    /// Returns true if `unparsedTarget` has been explicitly set.
    var hasUnparsedTarget: Bool {return self._unparsedTarget != nil}
    /// Clears the value of `unparsedTarget`. Subsequent reads from it will return its default value.
    mutating func clearUnparsedTarget() {self._unparsedTarget = nil}

    /// (Optional) The id of corresponding connect plan.
    var planID: Int64 {
      get {return _planID ?? 0}
      set {_planID = newValue}
    }
    /// Returns true if `planID` has been explicitly set.
    var hasPlanID: Bool {return self._planID != nil}
    /// Clears the value of `planID`. Subsequent reads from it will return its default value.
    mutating func clearPlanID() {self._planID = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _unparsedTarget: String? = nil
    fileprivate var _planID: Int64? = nil
  }

  /// Represents all of the input attributes to a given relational operator, for example in
  /// "SELECT `(id)?+.+` FROM ...".
  struct UnresolvedRegex: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) The column name used to extract column with regex.
    var colName: String = String()

    /// (Optional) The id of corresponding connect plan.
    var planID: Int64 {
      get {return _planID ?? 0}
      set {_planID = newValue}
    }
    /// Returns true if `planID` has been explicitly set.
    var hasPlanID: Bool {return self._planID != nil}
    /// Clears the value of `planID`. Subsequent reads from it will return its default value.
    mutating func clearPlanID() {self._planID = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _planID: Int64? = nil
  }

  /// Extracts a value or values from an Expression
  struct UnresolvedExtractValue: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) The expression to extract value from, can be
    /// Map, Array, Struct or array of Structs.
    var child: Spark_Connect_Expression {
      get {return _storage._child ?? Spark_Connect_Expression()}
      set {_uniqueStorage()._child = newValue}
    }
    /// Returns true if `child` has been explicitly set.
    var hasChild: Bool {return _storage._child != nil}
    /// Clears the value of `child`. Subsequent reads from it will return its default value.
    mutating func clearChild() {_uniqueStorage()._child = nil}

    /// (Required) The expression to describe the extraction, can be
    /// key of Map, index of Array, field name of Struct.
    var extraction: Spark_Connect_Expression {
      get {return _storage._extraction ?? Spark_Connect_Expression()}
      set {_uniqueStorage()._extraction = newValue}
    }
    /// Returns true if `extraction` has been explicitly set.
    var hasExtraction: Bool {return _storage._extraction != nil}
    /// Clears the value of `extraction`. Subsequent reads from it will return its default value.
    mutating func clearExtraction() {_uniqueStorage()._extraction = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  /// Add, replace or drop a field of `StructType` expression by name.
  struct UpdateFields: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) The struct expression.
    var structExpression: Spark_Connect_Expression {
      get {return _storage._structExpression ?? Spark_Connect_Expression()}
      set {_uniqueStorage()._structExpression = newValue}
    }
    /// Returns true if `structExpression` has been explicitly set.
    var hasStructExpression: Bool {return _storage._structExpression != nil}
    /// Clears the value of `structExpression`. Subsequent reads from it will return its default value.
    mutating func clearStructExpression() {_uniqueStorage()._structExpression = nil}

    /// (Required) The field name.
    var fieldName: String {
      get {return _storage._fieldName}
      set {_uniqueStorage()._fieldName = newValue}
    }

    /// (Optional) The expression to add or replace.
    ///
    /// When not set, it means this field will be dropped.
    var valueExpression: Spark_Connect_Expression {
      get {return _storage._valueExpression ?? Spark_Connect_Expression()}
      set {_uniqueStorage()._valueExpression = newValue}
    }
    /// Returns true if `valueExpression` has been explicitly set.
    var hasValueExpression: Bool {return _storage._valueExpression != nil}
    /// Clears the value of `valueExpression`. Subsequent reads from it will return its default value.
    mutating func clearValueExpression() {_uniqueStorage()._valueExpression = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  struct Alias: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) The expression that alias will be added on.
    var expr: Spark_Connect_Expression {
      get {return _storage._expr ?? Spark_Connect_Expression()}
      set {_uniqueStorage()._expr = newValue}
    }
    /// Returns true if `expr` has been explicitly set.
    var hasExpr: Bool {return _storage._expr != nil}
    /// Clears the value of `expr`. Subsequent reads from it will return its default value.
    mutating func clearExpr() {_uniqueStorage()._expr = nil}

    /// (Required) a list of name parts for the alias.
    ///
    /// Scalar columns only has one name that presents.
    var name: [String] {
      get {return _storage._name}
      set {_uniqueStorage()._name = newValue}
    }

    /// (Optional) Alias metadata expressed as a JSON map.
    var metadata: String {
      get {return _storage._metadata ?? String()}
      set {_uniqueStorage()._metadata = newValue}
    }
    /// Returns true if `metadata` has been explicitly set.
    var hasMetadata: Bool {return _storage._metadata != nil}
    /// Clears the value of `metadata`. Subsequent reads from it will return its default value.
    mutating func clearMetadata() {_uniqueStorage()._metadata = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  struct LambdaFunction: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) The lambda function.
    ///
    /// The function body should use 'UnresolvedAttribute' as arguments, the sever side will
    /// replace 'UnresolvedAttribute' with 'UnresolvedNamedLambdaVariable'.
    var function: Spark_Connect_Expression {
      get {return _storage._function ?? Spark_Connect_Expression()}
      set {_uniqueStorage()._function = newValue}
    }
    /// Returns true if `function` has been explicitly set.
    var hasFunction: Bool {return _storage._function != nil}
    /// Clears the value of `function`. Subsequent reads from it will return its default value.
    mutating func clearFunction() {_uniqueStorage()._function = nil}

    /// (Required) Function variables. Must contains 1 ~ 3 variables.
    var arguments: [Spark_Connect_Expression.UnresolvedNamedLambdaVariable] {
      get {return _storage._arguments}
      set {_uniqueStorage()._arguments = newValue}
    }

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  struct UnresolvedNamedLambdaVariable: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) a list of name parts for the variable. Must not be empty.
    var nameParts: [String] = []

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

struct Spark_Connect_ExpressionCommon: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required) Keep the information of the origin for this expression such as stacktrace.
  var origin: Spark_Connect_Origin {
    get {return _origin ?? Spark_Connect_Origin()}
    set {_origin = newValue}
  }
  /// Returns true if `origin` has been explicitly set.
  var hasOrigin: Bool {return self._origin != nil}
  /// Clears the value of `origin`. Subsequent reads from it will return its default value.
  mutating func clearOrigin() {self._origin = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _origin: Spark_Connect_Origin? = nil
}

struct Spark_Connect_CommonInlineUserDefinedFunction: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required) Name of the user-defined function.
  var functionName: String = String()

  /// (Optional) Indicate if the user-defined function is deterministic.
  var deterministic: Bool = false

  /// (Optional) Function arguments. Empty arguments are allowed.
  var arguments: [Spark_Connect_Expression] = []

  /// (Required) Indicate the function type of the user-defined function.
  var function: Spark_Connect_CommonInlineUserDefinedFunction.OneOf_Function? = nil

  var pythonUdf: Spark_Connect_PythonUDF {
    get {
      if case .pythonUdf(let v)? = function {return v}
      return Spark_Connect_PythonUDF()
    }
    set {function = .pythonUdf(newValue)}
  }

  var scalarScalaUdf: Spark_Connect_ScalarScalaUDF {
    get {
      if case .scalarScalaUdf(let v)? = function {return v}
      return Spark_Connect_ScalarScalaUDF()
    }
    set {function = .scalarScalaUdf(newValue)}
  }

  var javaUdf: Spark_Connect_JavaUDF {
    get {
      if case .javaUdf(let v)? = function {return v}
      return Spark_Connect_JavaUDF()
    }
    set {function = .javaUdf(newValue)}
  }

  /// (Required) Indicate if this function should be applied on distinct values.
  var isDistinct: Bool = false

  var unknownFields = SwiftProtobuf.UnknownStorage()

  /// (Required) Indicate the function type of the user-defined function.
  enum OneOf_Function: Equatable, Sendable {
    case pythonUdf(Spark_Connect_PythonUDF)
    case scalarScalaUdf(Spark_Connect_ScalarScalaUDF)
    case javaUdf(Spark_Connect_JavaUDF)

  }

  init() {}
}

struct Spark_Connect_PythonUDF: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required) Output type of the Python UDF
  var outputType: Spark_Connect_DataType {
    get {return _outputType ?? Spark_Connect_DataType()}
    set {_outputType = newValue}
  }
  /// Returns true if `outputType` has been explicitly set.
  var hasOutputType: Bool {return self._outputType != nil}
  /// Clears the value of `outputType`. Subsequent reads from it will return its default value.
  mutating func clearOutputType() {self._outputType = nil}

  /// (Required) EvalType of the Python UDF
  var evalType: Int32 = 0

  /// (Required) The encoded commands of the Python UDF
  var command: Data = Data()

  /// (Required) Python version being used in the client.
  var pythonVer: String = String()

  /// (Optional) Additional includes for the Python UDF.
  var additionalIncludes: [String] = []

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _outputType: Spark_Connect_DataType? = nil
}

struct Spark_Connect_ScalarScalaUDF: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required) Serialized JVM object containing UDF definition, input encoders and output encoder
  var payload: Data = Data()

  /// (Optional) Input type(s) of the UDF
  var inputTypes: [Spark_Connect_DataType] = []

  /// (Required) Output type of the UDF
  var outputType: Spark_Connect_DataType {
    get {return _outputType ?? Spark_Connect_DataType()}
    set {_outputType = newValue}
  }
  /// Returns true if `outputType` has been explicitly set.
  var hasOutputType: Bool {return self._outputType != nil}
  /// Clears the value of `outputType`. Subsequent reads from it will return its default value.
  mutating func clearOutputType() {self._outputType = nil}

  /// (Required) True if the UDF can return null value
  var nullable: Bool = false

  /// (Required) Indicate if the UDF is an aggregate function
  var aggregate: Bool = false

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _outputType: Spark_Connect_DataType? = nil
}

struct Spark_Connect_JavaUDF: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required) Fully qualified name of Java class
  var className: String = String()

  /// (Optional) Output type of the Java UDF
  var outputType: Spark_Connect_DataType {
    get {return _outputType ?? Spark_Connect_DataType()}
    set {_outputType = newValue}
  }
  /// Returns true if `outputType` has been explicitly set.
  var hasOutputType: Bool {return self._outputType != nil}
  /// Clears the value of `outputType`. Subsequent reads from it will return its default value.
  mutating func clearOutputType() {self._outputType = nil}

  /// (Required) Indicate if the Java user-defined function is an aggregate function
  var aggregate: Bool = false

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _outputType: Spark_Connect_DataType? = nil
}

struct Spark_Connect_TypedAggregateExpression: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required) The aggregate function object packed into bytes.
  var scalarScalaUdf: Spark_Connect_ScalarScalaUDF {
    get {return _scalarScalaUdf ?? Spark_Connect_ScalarScalaUDF()}
    set {_scalarScalaUdf = newValue}
  }
  /// Returns true if `scalarScalaUdf` has been explicitly set.
  var hasScalarScalaUdf: Bool {return self._scalarScalaUdf != nil}
  /// Clears the value of `scalarScalaUdf`. Subsequent reads from it will return its default value.
  mutating func clearScalarScalaUdf() {self._scalarScalaUdf = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _scalarScalaUdf: Spark_Connect_ScalarScalaUDF? = nil
}

struct Spark_Connect_CallFunction: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required) Unparsed name of the SQL function.
  var functionName: String = String()

  /// (Optional) Function arguments. Empty arguments are allowed.
  var arguments: [Spark_Connect_Expression] = []

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

struct Spark_Connect_NamedArgumentExpression: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required) The key of the named argument.
  var key: String {
    get {return _storage._key}
    set {_uniqueStorage()._key = newValue}
  }

  /// (Required) The value expression of the named argument.
  var value: Spark_Connect_Expression {
    get {return _storage._value ?? Spark_Connect_Expression()}
    set {_uniqueStorage()._value = newValue}
  }
  /// Returns true if `value` has been explicitly set.
  var hasValue: Bool {return _storage._value != nil}
  /// Clears the value of `value`. Subsequent reads from it will return its default value.
  mutating func clearValue() {_uniqueStorage()._value = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

struct Spark_Connect_MergeAction: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required) The action type of the merge action.
  var actionType: Spark_Connect_MergeAction.ActionType {
    get {return _storage._actionType}
    set {_uniqueStorage()._actionType = newValue}
  }

  /// (Optional) The condition expression of the merge action.
  var condition: Spark_Connect_Expression {
    get {return _storage._condition ?? Spark_Connect_Expression()}
    set {_uniqueStorage()._condition = newValue}
  }
  /// Returns true if `condition` has been explicitly set.
  var hasCondition: Bool {return _storage._condition != nil}
  /// Clears the value of `condition`. Subsequent reads from it will return its default value.
  mutating func clearCondition() {_uniqueStorage()._condition = nil}

  /// (Optional) The assignments of the merge action. Required for ActionTypes INSERT and UPDATE.
  var assignments: [Spark_Connect_MergeAction.Assignment] {
    get {return _storage._assignments}
    set {_uniqueStorage()._assignments = newValue}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum ActionType: SwiftProtobuf.Enum, Swift.CaseIterable {
    typealias RawValue = Int
    case invalid // = 0
    case delete // = 1
    case insert // = 2
    case insertStar // = 3
    case update // = 4
    case updateStar // = 5
    case UNRECOGNIZED(Int)

    init() {
      self = .invalid
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .invalid
      case 1: self = .delete
      case 2: self = .insert
      case 3: self = .insertStar
      case 4: self = .update
      case 5: self = .updateStar
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .invalid: return 0
      case .delete: return 1
      case .insert: return 2
      case .insertStar: return 3
      case .update: return 4
      case .updateStar: return 5
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    static let allCases: [Spark_Connect_MergeAction.ActionType] = [
      .invalid,
      .delete,
      .insert,
      .insertStar,
      .update,
      .updateStar,
    ]

  }

  struct Assignment: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) The key of the assignment.
    var key: Spark_Connect_Expression {
      get {return _key ?? Spark_Connect_Expression()}
      set {_key = newValue}
    }
    /// Returns true if `key` has been explicitly set.
    var hasKey: Bool {return self._key != nil}
    /// Clears the value of `key`. Subsequent reads from it will return its default value.
    mutating func clearKey() {self._key = nil}

    /// (Required) The value of the assignment.
    var value: Spark_Connect_Expression {
      get {return _value ?? Spark_Connect_Expression()}
      set {_value = newValue}
    }
    /// Returns true if `value` has been explicitly set.
    var hasValue: Bool {return self._value != nil}
    /// Clears the value of `value`. Subsequent reads from it will return its default value.
    mutating func clearValue() {self._value = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _key: Spark_Connect_Expression? = nil
    fileprivate var _value: Spark_Connect_Expression? = nil
  }

  init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

struct Spark_Connect_SubqueryExpression: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required) The ID of the corresponding connect plan.
  var planID: Int64 = 0

  /// (Required) The type of the subquery.
  var subqueryType: Spark_Connect_SubqueryExpression.SubqueryType = .unknown

  /// (Optional) Options specific to table arguments.
  var tableArgOptions: Spark_Connect_SubqueryExpression.TableArgOptions {
    get {return _tableArgOptions ?? Spark_Connect_SubqueryExpression.TableArgOptions()}
    set {_tableArgOptions = newValue}
  }
  /// Returns true if `tableArgOptions` has been explicitly set.
  var hasTableArgOptions: Bool {return self._tableArgOptions != nil}
  /// Clears the value of `tableArgOptions`. Subsequent reads from it will return its default value.
  mutating func clearTableArgOptions() {self._tableArgOptions = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum SubqueryType: SwiftProtobuf.Enum, Swift.CaseIterable {
    typealias RawValue = Int
    case unknown // = 0
    case scalar // = 1
    case exists // = 2
    case tableArg // = 3
    case UNRECOGNIZED(Int)

    init() {
      self = .unknown
    }

    init?(rawValue: Int) {
      switch rawValue {
      case 0: self = .unknown
      case 1: self = .scalar
      case 2: self = .exists
      case 3: self = .tableArg
      default: self = .UNRECOGNIZED(rawValue)
      }
    }

    var rawValue: Int {
      switch self {
      case .unknown: return 0
      case .scalar: return 1
      case .exists: return 2
      case .tableArg: return 3
      case .UNRECOGNIZED(let i): return i
      }
    }

    // The compiler won't synthesize support with the UNRECOGNIZED case.
    static let allCases: [Spark_Connect_SubqueryExpression.SubqueryType] = [
      .unknown,
      .scalar,
      .exists,
      .tableArg,
    ]

  }

  /// Nested message for table argument options.
  struct TableArgOptions: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Optional) The way that input rows are partitioned.
    var partitionSpec: [Spark_Connect_Expression] = []

    /// (Optional) Ordering of rows in a partition.
    var orderSpec: [Spark_Connect_Expression.SortOrder] = []

    /// (Optional) Whether this is a single partition.
    var withSinglePartition: Bool {
      get {return _withSinglePartition ?? false}
      set {_withSinglePartition = newValue}
    }
    /// Returns true if `withSinglePartition` has been explicitly set.
    var hasWithSinglePartition: Bool {return self._withSinglePartition != nil}
    /// Clears the value of `withSinglePartition`. Subsequent reads from it will return its default value.
    mutating func clearWithSinglePartition() {self._withSinglePartition = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _withSinglePartition: Bool? = nil
  }

  init() {}

  fileprivate var _tableArgOptions: Spark_Connect_SubqueryExpression.TableArgOptions? = nil
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "spark.connect"

extension Spark_Connect_Expression: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".Expression"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    18: .same(proto: "common"),
    1: .same(proto: "literal"),
    2: .standard(proto: "unresolved_attribute"),
    3: .standard(proto: "unresolved_function"),
    4: .standard(proto: "expression_string"),
    5: .standard(proto: "unresolved_star"),
    6: .same(proto: "alias"),
    7: .same(proto: "cast"),
    8: .standard(proto: "unresolved_regex"),
    9: .standard(proto: "sort_order"),
    10: .standard(proto: "lambda_function"),
    11: .same(proto: "window"),
    12: .standard(proto: "unresolved_extract_value"),
    13: .standard(proto: "update_fields"),
    14: .standard(proto: "unresolved_named_lambda_variable"),
    15: .standard(proto: "common_inline_user_defined_function"),
    16: .standard(proto: "call_function"),
    17: .standard(proto: "named_argument_expression"),
    19: .standard(proto: "merge_action"),
    20: .standard(proto: "typed_aggregate_expression"),
    21: .standard(proto: "subquery_expression"),
    999: .same(proto: "extension"),
  ]

  fileprivate class _StorageClass {
    var _common: Spark_Connect_ExpressionCommon? = nil
    var _exprType: Spark_Connect_Expression.OneOf_ExprType?

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _common = source._common
      _exprType = source._exprType
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try {
          var v: Spark_Connect_Expression.Literal?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .literal(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .literal(v)
          }
        }()
        case 2: try {
          var v: Spark_Connect_Expression.UnresolvedAttribute?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .unresolvedAttribute(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .unresolvedAttribute(v)
          }
        }()
        case 3: try {
          var v: Spark_Connect_Expression.UnresolvedFunction?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .unresolvedFunction(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .unresolvedFunction(v)
          }
        }()
        case 4: try {
          var v: Spark_Connect_Expression.ExpressionString?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .expressionString(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .expressionString(v)
          }
        }()
        case 5: try {
          var v: Spark_Connect_Expression.UnresolvedStar?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .unresolvedStar(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .unresolvedStar(v)
          }
        }()
        case 6: try {
          var v: Spark_Connect_Expression.Alias?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .alias(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .alias(v)
          }
        }()
        case 7: try {
          var v: Spark_Connect_Expression.Cast?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .cast(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .cast(v)
          }
        }()
        case 8: try {
          var v: Spark_Connect_Expression.UnresolvedRegex?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .unresolvedRegex(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .unresolvedRegex(v)
          }
        }()
        case 9: try {
          var v: Spark_Connect_Expression.SortOrder?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .sortOrder(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .sortOrder(v)
          }
        }()
        case 10: try {
          var v: Spark_Connect_Expression.LambdaFunction?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .lambdaFunction(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .lambdaFunction(v)
          }
        }()
        case 11: try {
          var v: Spark_Connect_Expression.Window?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .window(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .window(v)
          }
        }()
        case 12: try {
          var v: Spark_Connect_Expression.UnresolvedExtractValue?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .unresolvedExtractValue(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .unresolvedExtractValue(v)
          }
        }()
        case 13: try {
          var v: Spark_Connect_Expression.UpdateFields?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .updateFields(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .updateFields(v)
          }
        }()
        case 14: try {
          var v: Spark_Connect_Expression.UnresolvedNamedLambdaVariable?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .unresolvedNamedLambdaVariable(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .unresolvedNamedLambdaVariable(v)
          }
        }()
        case 15: try {
          var v: Spark_Connect_CommonInlineUserDefinedFunction?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .commonInlineUserDefinedFunction(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .commonInlineUserDefinedFunction(v)
          }
        }()
        case 16: try {
          var v: Spark_Connect_CallFunction?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .callFunction(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .callFunction(v)
          }
        }()
        case 17: try {
          var v: Spark_Connect_NamedArgumentExpression?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .namedArgumentExpression(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .namedArgumentExpression(v)
          }
        }()
        case 18: try { try decoder.decodeSingularMessageField(value: &_storage._common) }()
        case 19: try {
          var v: Spark_Connect_MergeAction?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .mergeAction(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .mergeAction(v)
          }
        }()
        case 20: try {
          var v: Spark_Connect_TypedAggregateExpression?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .typedAggregateExpression(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .typedAggregateExpression(v)
          }
        }()
        case 21: try {
          var v: Spark_Connect_SubqueryExpression?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .subqueryExpression(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .subqueryExpression(v)
          }
        }()
        case 999: try {
          var v: SwiftProtobuf.Google_Protobuf_Any?
          var hadOneofValue = false
          if let current = _storage._exprType {
            hadOneofValue = true
            if case .extension(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._exprType = .extension(v)
          }
        }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      switch _storage._exprType {
      case .literal?: try {
        guard case .literal(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      }()
      case .unresolvedAttribute?: try {
        guard case .unresolvedAttribute(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }()
      case .unresolvedFunction?: try {
        guard case .unresolvedFunction(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      }()
      case .expressionString?: try {
        guard case .expressionString(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      }()
      case .unresolvedStar?: try {
        guard case .unresolvedStar(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      }()
      case .alias?: try {
        guard case .alias(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      }()
      case .cast?: try {
        guard case .cast(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      }()
      case .unresolvedRegex?: try {
        guard case .unresolvedRegex(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      }()
      case .sortOrder?: try {
        guard case .sortOrder(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      }()
      case .lambdaFunction?: try {
        guard case .lambdaFunction(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      }()
      case .window?: try {
        guard case .window(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      }()
      case .unresolvedExtractValue?: try {
        guard case .unresolvedExtractValue(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
      }()
      case .updateFields?: try {
        guard case .updateFields(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 13)
      }()
      case .unresolvedNamedLambdaVariable?: try {
        guard case .unresolvedNamedLambdaVariable(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 14)
      }()
      case .commonInlineUserDefinedFunction?: try {
        guard case .commonInlineUserDefinedFunction(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 15)
      }()
      case .callFunction?: try {
        guard case .callFunction(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 16)
      }()
      case .namedArgumentExpression?: try {
        guard case .namedArgumentExpression(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 17)
      }()
      default: break
      }
      try { if let v = _storage._common {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 18)
      } }()
      switch _storage._exprType {
      case .mergeAction?: try {
        guard case .mergeAction(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 19)
      }()
      case .typedAggregateExpression?: try {
        guard case .typedAggregateExpression(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 20)
      }()
      case .subqueryExpression?: try {
        guard case .subqueryExpression(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 21)
      }()
      case .extension?: try {
        guard case .extension(let v)? = _storage._exprType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 999)
      }()
      default: break
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression, rhs: Spark_Connect_Expression) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._common != rhs_storage._common {return false}
        if _storage._exprType != rhs_storage._exprType {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.Window: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.protoMessageName + ".Window"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "window_function"),
    2: .standard(proto: "partition_spec"),
    3: .standard(proto: "order_spec"),
    4: .standard(proto: "frame_spec"),
  ]

  fileprivate class _StorageClass {
    var _windowFunction: Spark_Connect_Expression? = nil
    var _partitionSpec: [Spark_Connect_Expression] = []
    var _orderSpec: [Spark_Connect_Expression.SortOrder] = []
    var _frameSpec: Spark_Connect_Expression.Window.WindowFrame? = nil

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _windowFunction = source._windowFunction
      _partitionSpec = source._partitionSpec
      _orderSpec = source._orderSpec
      _frameSpec = source._frameSpec
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._windowFunction) }()
        case 2: try { try decoder.decodeRepeatedMessageField(value: &_storage._partitionSpec) }()
        case 3: try { try decoder.decodeRepeatedMessageField(value: &_storage._orderSpec) }()
        case 4: try { try decoder.decodeSingularMessageField(value: &_storage._frameSpec) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._windowFunction {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      } }()
      if !_storage._partitionSpec.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._partitionSpec, fieldNumber: 2)
      }
      if !_storage._orderSpec.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._orderSpec, fieldNumber: 3)
      }
      try { if let v = _storage._frameSpec {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.Window, rhs: Spark_Connect_Expression.Window) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._windowFunction != rhs_storage._windowFunction {return false}
        if _storage._partitionSpec != rhs_storage._partitionSpec {return false}
        if _storage._orderSpec != rhs_storage._orderSpec {return false}
        if _storage._frameSpec != rhs_storage._frameSpec {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.Window.WindowFrame: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.Window.protoMessageName + ".WindowFrame"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "frame_type"),
    2: .same(proto: "lower"),
    3: .same(proto: "upper"),
  ]

  fileprivate class _StorageClass {
    var _frameType: Spark_Connect_Expression.Window.WindowFrame.FrameType = .undefined
    var _lower: Spark_Connect_Expression.Window.WindowFrame.FrameBoundary? = nil
    var _upper: Spark_Connect_Expression.Window.WindowFrame.FrameBoundary? = nil

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _frameType = source._frameType
      _lower = source._lower
      _upper = source._upper
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularEnumField(value: &_storage._frameType) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._lower) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._upper) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if _storage._frameType != .undefined {
        try visitor.visitSingularEnumField(value: _storage._frameType, fieldNumber: 1)
      }
      try { if let v = _storage._lower {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      } }()
      try { if let v = _storage._upper {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.Window.WindowFrame, rhs: Spark_Connect_Expression.Window.WindowFrame) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._frameType != rhs_storage._frameType {return false}
        if _storage._lower != rhs_storage._lower {return false}
        if _storage._upper != rhs_storage._upper {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.Window.WindowFrame.FrameType: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "FRAME_TYPE_UNDEFINED"),
    1: .same(proto: "FRAME_TYPE_ROW"),
    2: .same(proto: "FRAME_TYPE_RANGE"),
  ]
}

extension Spark_Connect_Expression.Window.WindowFrame.FrameBoundary: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.Window.WindowFrame.protoMessageName + ".FrameBoundary"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "current_row"),
    2: .same(proto: "unbounded"),
    3: .same(proto: "value"),
  ]

  fileprivate class _StorageClass {
    var _boundary: Spark_Connect_Expression.Window.WindowFrame.FrameBoundary.OneOf_Boundary?

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _boundary = source._boundary
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try {
          var v: Bool?
          try decoder.decodeSingularBoolField(value: &v)
          if let v = v {
            if _storage._boundary != nil {try decoder.handleConflictingOneOf()}
            _storage._boundary = .currentRow(v)
          }
        }()
        case 2: try {
          var v: Bool?
          try decoder.decodeSingularBoolField(value: &v)
          if let v = v {
            if _storage._boundary != nil {try decoder.handleConflictingOneOf()}
            _storage._boundary = .unbounded(v)
          }
        }()
        case 3: try {
          var v: Spark_Connect_Expression?
          var hadOneofValue = false
          if let current = _storage._boundary {
            hadOneofValue = true
            if case .value(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._boundary = .value(v)
          }
        }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      switch _storage._boundary {
      case .currentRow?: try {
        guard case .currentRow(let v)? = _storage._boundary else { preconditionFailure() }
        try visitor.visitSingularBoolField(value: v, fieldNumber: 1)
      }()
      case .unbounded?: try {
        guard case .unbounded(let v)? = _storage._boundary else { preconditionFailure() }
        try visitor.visitSingularBoolField(value: v, fieldNumber: 2)
      }()
      case .value?: try {
        guard case .value(let v)? = _storage._boundary else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      }()
      case nil: break
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.Window.WindowFrame.FrameBoundary, rhs: Spark_Connect_Expression.Window.WindowFrame.FrameBoundary) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._boundary != rhs_storage._boundary {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.SortOrder: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.protoMessageName + ".SortOrder"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "child"),
    2: .same(proto: "direction"),
    3: .standard(proto: "null_ordering"),
  ]

  fileprivate class _StorageClass {
    var _child: Spark_Connect_Expression? = nil
    var _direction: Spark_Connect_Expression.SortOrder.SortDirection = .unspecified
    var _nullOrdering: Spark_Connect_Expression.SortOrder.NullOrdering = .sortNullsUnspecified

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _child = source._child
      _direction = source._direction
      _nullOrdering = source._nullOrdering
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._child) }()
        case 2: try { try decoder.decodeSingularEnumField(value: &_storage._direction) }()
        case 3: try { try decoder.decodeSingularEnumField(value: &_storage._nullOrdering) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._child {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      } }()
      if _storage._direction != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._direction, fieldNumber: 2)
      }
      if _storage._nullOrdering != .sortNullsUnspecified {
        try visitor.visitSingularEnumField(value: _storage._nullOrdering, fieldNumber: 3)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.SortOrder, rhs: Spark_Connect_Expression.SortOrder) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._child != rhs_storage._child {return false}
        if _storage._direction != rhs_storage._direction {return false}
        if _storage._nullOrdering != rhs_storage._nullOrdering {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.SortOrder.SortDirection: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "SORT_DIRECTION_UNSPECIFIED"),
    1: .same(proto: "SORT_DIRECTION_ASCENDING"),
    2: .same(proto: "SORT_DIRECTION_DESCENDING"),
  ]
}

extension Spark_Connect_Expression.SortOrder.NullOrdering: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "SORT_NULLS_UNSPECIFIED"),
    1: .same(proto: "SORT_NULLS_FIRST"),
    2: .same(proto: "SORT_NULLS_LAST"),
  ]
}

extension Spark_Connect_Expression.Cast: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.protoMessageName + ".Cast"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "expr"),
    2: .same(proto: "type"),
    3: .standard(proto: "type_str"),
    4: .standard(proto: "eval_mode"),
  ]

  fileprivate class _StorageClass {
    var _expr: Spark_Connect_Expression? = nil
    var _castToType: Spark_Connect_Expression.Cast.OneOf_CastToType?
    var _evalMode: Spark_Connect_Expression.Cast.EvalMode = .unspecified

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _expr = source._expr
      _castToType = source._castToType
      _evalMode = source._evalMode
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._expr) }()
        case 2: try {
          var v: Spark_Connect_DataType?
          var hadOneofValue = false
          if let current = _storage._castToType {
            hadOneofValue = true
            if case .type(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._castToType = .type(v)
          }
        }()
        case 3: try {
          var v: String?
          try decoder.decodeSingularStringField(value: &v)
          if let v = v {
            if _storage._castToType != nil {try decoder.handleConflictingOneOf()}
            _storage._castToType = .typeStr(v)
          }
        }()
        case 4: try { try decoder.decodeSingularEnumField(value: &_storage._evalMode) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._expr {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      } }()
      switch _storage._castToType {
      case .type?: try {
        guard case .type(let v)? = _storage._castToType else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }()
      case .typeStr?: try {
        guard case .typeStr(let v)? = _storage._castToType else { preconditionFailure() }
        try visitor.visitSingularStringField(value: v, fieldNumber: 3)
      }()
      case nil: break
      }
      if _storage._evalMode != .unspecified {
        try visitor.visitSingularEnumField(value: _storage._evalMode, fieldNumber: 4)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.Cast, rhs: Spark_Connect_Expression.Cast) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._expr != rhs_storage._expr {return false}
        if _storage._castToType != rhs_storage._castToType {return false}
        if _storage._evalMode != rhs_storage._evalMode {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.Cast.EvalMode: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "EVAL_MODE_UNSPECIFIED"),
    1: .same(proto: "EVAL_MODE_LEGACY"),
    2: .same(proto: "EVAL_MODE_ANSI"),
    3: .same(proto: "EVAL_MODE_TRY"),
  ]
}

extension Spark_Connect_Expression.Literal: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.protoMessageName + ".Literal"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "null"),
    2: .same(proto: "binary"),
    3: .same(proto: "boolean"),
    4: .same(proto: "byte"),
    5: .same(proto: "short"),
    6: .same(proto: "integer"),
    7: .same(proto: "long"),
    10: .same(proto: "float"),
    11: .same(proto: "double"),
    12: .same(proto: "decimal"),
    13: .same(proto: "string"),
    16: .same(proto: "date"),
    17: .same(proto: "timestamp"),
    18: .standard(proto: "timestamp_ntz"),
    19: .standard(proto: "calendar_interval"),
    20: .standard(proto: "year_month_interval"),
    21: .standard(proto: "day_time_interval"),
    22: .same(proto: "array"),
    23: .same(proto: "map"),
    24: .same(proto: "struct"),
    25: .standard(proto: "specialized_array"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Spark_Connect_DataType?
        var hadOneofValue = false
        if let current = self.literalType {
          hadOneofValue = true
          if case .null(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.literalType = .null(v)
        }
      }()
      case 2: try {
        var v: Data?
        try decoder.decodeSingularBytesField(value: &v)
        if let v = v {
          if self.literalType != nil {try decoder.handleConflictingOneOf()}
          self.literalType = .binary(v)
        }
      }()
      case 3: try {
        var v: Bool?
        try decoder.decodeSingularBoolField(value: &v)
        if let v = v {
          if self.literalType != nil {try decoder.handleConflictingOneOf()}
          self.literalType = .boolean(v)
        }
      }()
      case 4: try {
        var v: Int32?
        try decoder.decodeSingularInt32Field(value: &v)
        if let v = v {
          if self.literalType != nil {try decoder.handleConflictingOneOf()}
          self.literalType = .byte(v)
        }
      }()
      case 5: try {
        var v: Int32?
        try decoder.decodeSingularInt32Field(value: &v)
        if let v = v {
          if self.literalType != nil {try decoder.handleConflictingOneOf()}
          self.literalType = .short(v)
        }
      }()
      case 6: try {
        var v: Int32?
        try decoder.decodeSingularInt32Field(value: &v)
        if let v = v {
          if self.literalType != nil {try decoder.handleConflictingOneOf()}
          self.literalType = .integer(v)
        }
      }()
      case 7: try {
        var v: Int64?
        try decoder.decodeSingularInt64Field(value: &v)
        if let v = v {
          if self.literalType != nil {try decoder.handleConflictingOneOf()}
          self.literalType = .long(v)
        }
      }()
      case 10: try {
        var v: Float?
        try decoder.decodeSingularFloatField(value: &v)
        if let v = v {
          if self.literalType != nil {try decoder.handleConflictingOneOf()}
          self.literalType = .float(v)
        }
      }()
      case 11: try {
        var v: Double?
        try decoder.decodeSingularDoubleField(value: &v)
        if let v = v {
          if self.literalType != nil {try decoder.handleConflictingOneOf()}
          self.literalType = .double(v)
        }
      }()
      case 12: try {
        var v: Spark_Connect_Expression.Literal.Decimal?
        var hadOneofValue = false
        if let current = self.literalType {
          hadOneofValue = true
          if case .decimal(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.literalType = .decimal(v)
        }
      }()
      case 13: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.literalType != nil {try decoder.handleConflictingOneOf()}
          self.literalType = .string(v)
        }
      }()
      case 16: try {
        var v: Int32?
        try decoder.decodeSingularInt32Field(value: &v)
        if let v = v {
          if self.literalType != nil {try decoder.handleConflictingOneOf()}
          self.literalType = .date(v)
        }
      }()
      case 17: try {
        var v: Int64?
        try decoder.decodeSingularInt64Field(value: &v)
        if let v = v {
          if self.literalType != nil {try decoder.handleConflictingOneOf()}
          self.literalType = .timestamp(v)
        }
      }()
      case 18: try {
        var v: Int64?
        try decoder.decodeSingularInt64Field(value: &v)
        if let v = v {
          if self.literalType != nil {try decoder.handleConflictingOneOf()}
          self.literalType = .timestampNtz(v)
        }
      }()
      case 19: try {
        var v: Spark_Connect_Expression.Literal.CalendarInterval?
        var hadOneofValue = false
        if let current = self.literalType {
          hadOneofValue = true
          if case .calendarInterval(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.literalType = .calendarInterval(v)
        }
      }()
      case 20: try {
        var v: Int32?
        try decoder.decodeSingularInt32Field(value: &v)
        if let v = v {
          if self.literalType != nil {try decoder.handleConflictingOneOf()}
          self.literalType = .yearMonthInterval(v)
        }
      }()
      case 21: try {
        var v: Int64?
        try decoder.decodeSingularInt64Field(value: &v)
        if let v = v {
          if self.literalType != nil {try decoder.handleConflictingOneOf()}
          self.literalType = .dayTimeInterval(v)
        }
      }()
      case 22: try {
        var v: Spark_Connect_Expression.Literal.Array?
        var hadOneofValue = false
        if let current = self.literalType {
          hadOneofValue = true
          if case .array(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.literalType = .array(v)
        }
      }()
      case 23: try {
        var v: Spark_Connect_Expression.Literal.Map?
        var hadOneofValue = false
        if let current = self.literalType {
          hadOneofValue = true
          if case .map(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.literalType = .map(v)
        }
      }()
      case 24: try {
        var v: Spark_Connect_Expression.Literal.Struct?
        var hadOneofValue = false
        if let current = self.literalType {
          hadOneofValue = true
          if case .struct(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.literalType = .struct(v)
        }
      }()
      case 25: try {
        var v: Spark_Connect_Expression.Literal.SpecializedArray?
        var hadOneofValue = false
        if let current = self.literalType {
          hadOneofValue = true
          if case .specializedArray(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.literalType = .specializedArray(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.literalType {
    case .null?: try {
      guard case .null(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .binary?: try {
      guard case .binary(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularBytesField(value: v, fieldNumber: 2)
    }()
    case .boolean?: try {
      guard case .boolean(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularBoolField(value: v, fieldNumber: 3)
    }()
    case .byte?: try {
      guard case .byte(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularInt32Field(value: v, fieldNumber: 4)
    }()
    case .short?: try {
      guard case .short(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularInt32Field(value: v, fieldNumber: 5)
    }()
    case .integer?: try {
      guard case .integer(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularInt32Field(value: v, fieldNumber: 6)
    }()
    case .long?: try {
      guard case .long(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularInt64Field(value: v, fieldNumber: 7)
    }()
    case .float?: try {
      guard case .float(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularFloatField(value: v, fieldNumber: 10)
    }()
    case .double?: try {
      guard case .double(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularDoubleField(value: v, fieldNumber: 11)
    }()
    case .decimal?: try {
      guard case .decimal(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
    }()
    case .string?: try {
      guard case .string(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 13)
    }()
    case .date?: try {
      guard case .date(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularInt32Field(value: v, fieldNumber: 16)
    }()
    case .timestamp?: try {
      guard case .timestamp(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularInt64Field(value: v, fieldNumber: 17)
    }()
    case .timestampNtz?: try {
      guard case .timestampNtz(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularInt64Field(value: v, fieldNumber: 18)
    }()
    case .calendarInterval?: try {
      guard case .calendarInterval(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 19)
    }()
    case .yearMonthInterval?: try {
      guard case .yearMonthInterval(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularInt32Field(value: v, fieldNumber: 20)
    }()
    case .dayTimeInterval?: try {
      guard case .dayTimeInterval(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularInt64Field(value: v, fieldNumber: 21)
    }()
    case .array?: try {
      guard case .array(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 22)
    }()
    case .map?: try {
      guard case .map(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 23)
    }()
    case .struct?: try {
      guard case .struct(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 24)
    }()
    case .specializedArray?: try {
      guard case .specializedArray(let v)? = self.literalType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 25)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.Literal, rhs: Spark_Connect_Expression.Literal) -> Bool {
    if lhs.literalType != rhs.literalType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.Literal.Decimal: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.Literal.protoMessageName + ".Decimal"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "value"),
    2: .same(proto: "precision"),
    3: .same(proto: "scale"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.value) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self._precision) }()
      case 3: try { try decoder.decodeSingularInt32Field(value: &self._scale) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.value.isEmpty {
      try visitor.visitSingularStringField(value: self.value, fieldNumber: 1)
    }
    try { if let v = self._precision {
      try visitor.visitSingularInt32Field(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._scale {
      try visitor.visitSingularInt32Field(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.Literal.Decimal, rhs: Spark_Connect_Expression.Literal.Decimal) -> Bool {
    if lhs.value != rhs.value {return false}
    if lhs._precision != rhs._precision {return false}
    if lhs._scale != rhs._scale {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.Literal.CalendarInterval: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.Literal.protoMessageName + ".CalendarInterval"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "months"),
    2: .same(proto: "days"),
    3: .same(proto: "microseconds"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt32Field(value: &self.months) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.days) }()
      case 3: try { try decoder.decodeSingularInt64Field(value: &self.microseconds) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.months != 0 {
      try visitor.visitSingularInt32Field(value: self.months, fieldNumber: 1)
    }
    if self.days != 0 {
      try visitor.visitSingularInt32Field(value: self.days, fieldNumber: 2)
    }
    if self.microseconds != 0 {
      try visitor.visitSingularInt64Field(value: self.microseconds, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.Literal.CalendarInterval, rhs: Spark_Connect_Expression.Literal.CalendarInterval) -> Bool {
    if lhs.months != rhs.months {return false}
    if lhs.days != rhs.days {return false}
    if lhs.microseconds != rhs.microseconds {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.Literal.Array: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.Literal.protoMessageName + ".Array"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "element_type"),
    2: .same(proto: "elements"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._elementType) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.elements) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._elementType {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.elements.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.elements, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.Literal.Array, rhs: Spark_Connect_Expression.Literal.Array) -> Bool {
    if lhs._elementType != rhs._elementType {return false}
    if lhs.elements != rhs.elements {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.Literal.Map: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.Literal.protoMessageName + ".Map"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "key_type"),
    2: .standard(proto: "value_type"),
    3: .same(proto: "keys"),
    4: .same(proto: "values"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._keyType) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._valueType) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.keys) }()
      case 4: try { try decoder.decodeRepeatedMessageField(value: &self.values) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._keyType {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._valueType {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if !self.keys.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.keys, fieldNumber: 3)
    }
    if !self.values.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.values, fieldNumber: 4)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.Literal.Map, rhs: Spark_Connect_Expression.Literal.Map) -> Bool {
    if lhs._keyType != rhs._keyType {return false}
    if lhs._valueType != rhs._valueType {return false}
    if lhs.keys != rhs.keys {return false}
    if lhs.values != rhs.values {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.Literal.Struct: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.Literal.protoMessageName + ".Struct"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "struct_type"),
    2: .same(proto: "elements"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._structType) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.elements) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._structType {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.elements.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.elements, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.Literal.Struct, rhs: Spark_Connect_Expression.Literal.Struct) -> Bool {
    if lhs._structType != rhs._structType {return false}
    if lhs.elements != rhs.elements {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.Literal.SpecializedArray: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.Literal.protoMessageName + ".SpecializedArray"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "bools"),
    2: .same(proto: "ints"),
    3: .same(proto: "longs"),
    4: .same(proto: "floats"),
    5: .same(proto: "doubles"),
    6: .same(proto: "strings"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Spark_Connect_Bools?
        var hadOneofValue = false
        if let current = self.valueType {
          hadOneofValue = true
          if case .bools(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.valueType = .bools(v)
        }
      }()
      case 2: try {
        var v: Spark_Connect_Ints?
        var hadOneofValue = false
        if let current = self.valueType {
          hadOneofValue = true
          if case .ints(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.valueType = .ints(v)
        }
      }()
      case 3: try {
        var v: Spark_Connect_Longs?
        var hadOneofValue = false
        if let current = self.valueType {
          hadOneofValue = true
          if case .longs(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.valueType = .longs(v)
        }
      }()
      case 4: try {
        var v: Spark_Connect_Floats?
        var hadOneofValue = false
        if let current = self.valueType {
          hadOneofValue = true
          if case .floats(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.valueType = .floats(v)
        }
      }()
      case 5: try {
        var v: Spark_Connect_Doubles?
        var hadOneofValue = false
        if let current = self.valueType {
          hadOneofValue = true
          if case .doubles(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.valueType = .doubles(v)
        }
      }()
      case 6: try {
        var v: Spark_Connect_Strings?
        var hadOneofValue = false
        if let current = self.valueType {
          hadOneofValue = true
          if case .strings(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.valueType = .strings(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.valueType {
    case .bools?: try {
      guard case .bools(let v)? = self.valueType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .ints?: try {
      guard case .ints(let v)? = self.valueType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case .longs?: try {
      guard case .longs(let v)? = self.valueType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case .floats?: try {
      guard case .floats(let v)? = self.valueType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }()
    case .doubles?: try {
      guard case .doubles(let v)? = self.valueType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }()
    case .strings?: try {
      guard case .strings(let v)? = self.valueType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.Literal.SpecializedArray, rhs: Spark_Connect_Expression.Literal.SpecializedArray) -> Bool {
    if lhs.valueType != rhs.valueType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.UnresolvedAttribute: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.protoMessageName + ".UnresolvedAttribute"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "unparsed_identifier"),
    2: .standard(proto: "plan_id"),
    3: .standard(proto: "is_metadata_column"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.unparsedIdentifier) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self._planID) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self._isMetadataColumn) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.unparsedIdentifier.isEmpty {
      try visitor.visitSingularStringField(value: self.unparsedIdentifier, fieldNumber: 1)
    }
    try { if let v = self._planID {
      try visitor.visitSingularInt64Field(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._isMetadataColumn {
      try visitor.visitSingularBoolField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.UnresolvedAttribute, rhs: Spark_Connect_Expression.UnresolvedAttribute) -> Bool {
    if lhs.unparsedIdentifier != rhs.unparsedIdentifier {return false}
    if lhs._planID != rhs._planID {return false}
    if lhs._isMetadataColumn != rhs._isMetadataColumn {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.UnresolvedFunction: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.protoMessageName + ".UnresolvedFunction"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "function_name"),
    2: .same(proto: "arguments"),
    3: .standard(proto: "is_distinct"),
    4: .standard(proto: "is_user_defined_function"),
    5: .standard(proto: "is_internal"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.functionName) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.arguments) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.isDistinct) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.isUserDefinedFunction) }()
      case 5: try { try decoder.decodeSingularBoolField(value: &self._isInternal) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.functionName.isEmpty {
      try visitor.visitSingularStringField(value: self.functionName, fieldNumber: 1)
    }
    if !self.arguments.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.arguments, fieldNumber: 2)
    }
    if self.isDistinct != false {
      try visitor.visitSingularBoolField(value: self.isDistinct, fieldNumber: 3)
    }
    if self.isUserDefinedFunction != false {
      try visitor.visitSingularBoolField(value: self.isUserDefinedFunction, fieldNumber: 4)
    }
    try { if let v = self._isInternal {
      try visitor.visitSingularBoolField(value: v, fieldNumber: 5)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.UnresolvedFunction, rhs: Spark_Connect_Expression.UnresolvedFunction) -> Bool {
    if lhs.functionName != rhs.functionName {return false}
    if lhs.arguments != rhs.arguments {return false}
    if lhs.isDistinct != rhs.isDistinct {return false}
    if lhs.isUserDefinedFunction != rhs.isUserDefinedFunction {return false}
    if lhs._isInternal != rhs._isInternal {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.ExpressionString: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.protoMessageName + ".ExpressionString"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "expression"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.expression) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.expression.isEmpty {
      try visitor.visitSingularStringField(value: self.expression, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.ExpressionString, rhs: Spark_Connect_Expression.ExpressionString) -> Bool {
    if lhs.expression != rhs.expression {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.UnresolvedStar: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.protoMessageName + ".UnresolvedStar"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "unparsed_target"),
    2: .standard(proto: "plan_id"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self._unparsedTarget) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self._planID) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._unparsedTarget {
      try visitor.visitSingularStringField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._planID {
      try visitor.visitSingularInt64Field(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.UnresolvedStar, rhs: Spark_Connect_Expression.UnresolvedStar) -> Bool {
    if lhs._unparsedTarget != rhs._unparsedTarget {return false}
    if lhs._planID != rhs._planID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.UnresolvedRegex: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.protoMessageName + ".UnresolvedRegex"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "col_name"),
    2: .standard(proto: "plan_id"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.colName) }()
      case 2: try { try decoder.decodeSingularInt64Field(value: &self._planID) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.colName.isEmpty {
      try visitor.visitSingularStringField(value: self.colName, fieldNumber: 1)
    }
    try { if let v = self._planID {
      try visitor.visitSingularInt64Field(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.UnresolvedRegex, rhs: Spark_Connect_Expression.UnresolvedRegex) -> Bool {
    if lhs.colName != rhs.colName {return false}
    if lhs._planID != rhs._planID {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.UnresolvedExtractValue: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.protoMessageName + ".UnresolvedExtractValue"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "child"),
    2: .same(proto: "extraction"),
  ]

  fileprivate class _StorageClass {
    var _child: Spark_Connect_Expression? = nil
    var _extraction: Spark_Connect_Expression? = nil

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _child = source._child
      _extraction = source._extraction
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._child) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._extraction) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._child {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      } }()
      try { if let v = _storage._extraction {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.UnresolvedExtractValue, rhs: Spark_Connect_Expression.UnresolvedExtractValue) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._child != rhs_storage._child {return false}
        if _storage._extraction != rhs_storage._extraction {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.UpdateFields: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.protoMessageName + ".UpdateFields"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "struct_expression"),
    2: .standard(proto: "field_name"),
    3: .standard(proto: "value_expression"),
  ]

  fileprivate class _StorageClass {
    var _structExpression: Spark_Connect_Expression? = nil
    var _fieldName: String = String()
    var _valueExpression: Spark_Connect_Expression? = nil

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _structExpression = source._structExpression
      _fieldName = source._fieldName
      _valueExpression = source._valueExpression
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._structExpression) }()
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._fieldName) }()
        case 3: try { try decoder.decodeSingularMessageField(value: &_storage._valueExpression) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._structExpression {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      } }()
      if !_storage._fieldName.isEmpty {
        try visitor.visitSingularStringField(value: _storage._fieldName, fieldNumber: 2)
      }
      try { if let v = _storage._valueExpression {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.UpdateFields, rhs: Spark_Connect_Expression.UpdateFields) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._structExpression != rhs_storage._structExpression {return false}
        if _storage._fieldName != rhs_storage._fieldName {return false}
        if _storage._valueExpression != rhs_storage._valueExpression {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.Alias: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.protoMessageName + ".Alias"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "expr"),
    2: .same(proto: "name"),
    3: .same(proto: "metadata"),
  ]

  fileprivate class _StorageClass {
    var _expr: Spark_Connect_Expression? = nil
    var _name: [String] = []
    var _metadata: String? = nil

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _expr = source._expr
      _name = source._name
      _metadata = source._metadata
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._expr) }()
        case 2: try { try decoder.decodeRepeatedStringField(value: &_storage._name) }()
        case 3: try { try decoder.decodeSingularStringField(value: &_storage._metadata) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._expr {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      } }()
      if !_storage._name.isEmpty {
        try visitor.visitRepeatedStringField(value: _storage._name, fieldNumber: 2)
      }
      try { if let v = _storage._metadata {
        try visitor.visitSingularStringField(value: v, fieldNumber: 3)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.Alias, rhs: Spark_Connect_Expression.Alias) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._expr != rhs_storage._expr {return false}
        if _storage._name != rhs_storage._name {return false}
        if _storage._metadata != rhs_storage._metadata {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.LambdaFunction: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.protoMessageName + ".LambdaFunction"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "function"),
    2: .same(proto: "arguments"),
  ]

  fileprivate class _StorageClass {
    var _function: Spark_Connect_Expression? = nil
    var _arguments: [Spark_Connect_Expression.UnresolvedNamedLambdaVariable] = []

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _function = source._function
      _arguments = source._arguments
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._function) }()
        case 2: try { try decoder.decodeRepeatedMessageField(value: &_storage._arguments) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._function {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      } }()
      if !_storage._arguments.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._arguments, fieldNumber: 2)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.LambdaFunction, rhs: Spark_Connect_Expression.LambdaFunction) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._function != rhs_storage._function {return false}
        if _storage._arguments != rhs_storage._arguments {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_Expression.UnresolvedNamedLambdaVariable: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_Expression.protoMessageName + ".UnresolvedNamedLambdaVariable"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "name_parts"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedStringField(value: &self.nameParts) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.nameParts.isEmpty {
      try visitor.visitRepeatedStringField(value: self.nameParts, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Expression.UnresolvedNamedLambdaVariable, rhs: Spark_Connect_Expression.UnresolvedNamedLambdaVariable) -> Bool {
    if lhs.nameParts != rhs.nameParts {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_ExpressionCommon: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".ExpressionCommon"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "origin"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._origin) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._origin {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_ExpressionCommon, rhs: Spark_Connect_ExpressionCommon) -> Bool {
    if lhs._origin != rhs._origin {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_CommonInlineUserDefinedFunction: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".CommonInlineUserDefinedFunction"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "function_name"),
    2: .same(proto: "deterministic"),
    3: .same(proto: "arguments"),
    4: .standard(proto: "python_udf"),
    5: .standard(proto: "scalar_scala_udf"),
    6: .standard(proto: "java_udf"),
    7: .standard(proto: "is_distinct"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.functionName) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self.deterministic) }()
      case 3: try { try decoder.decodeRepeatedMessageField(value: &self.arguments) }()
      case 4: try {
        var v: Spark_Connect_PythonUDF?
        var hadOneofValue = false
        if let current = self.function {
          hadOneofValue = true
          if case .pythonUdf(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.function = .pythonUdf(v)
        }
      }()
      case 5: try {
        var v: Spark_Connect_ScalarScalaUDF?
        var hadOneofValue = false
        if let current = self.function {
          hadOneofValue = true
          if case .scalarScalaUdf(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.function = .scalarScalaUdf(v)
        }
      }()
      case 6: try {
        var v: Spark_Connect_JavaUDF?
        var hadOneofValue = false
        if let current = self.function {
          hadOneofValue = true
          if case .javaUdf(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.function = .javaUdf(v)
        }
      }()
      case 7: try { try decoder.decodeSingularBoolField(value: &self.isDistinct) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.functionName.isEmpty {
      try visitor.visitSingularStringField(value: self.functionName, fieldNumber: 1)
    }
    if self.deterministic != false {
      try visitor.visitSingularBoolField(value: self.deterministic, fieldNumber: 2)
    }
    if !self.arguments.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.arguments, fieldNumber: 3)
    }
    switch self.function {
    case .pythonUdf?: try {
      guard case .pythonUdf(let v)? = self.function else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }()
    case .scalarScalaUdf?: try {
      guard case .scalarScalaUdf(let v)? = self.function else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }()
    case .javaUdf?: try {
      guard case .javaUdf(let v)? = self.function else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }()
    case nil: break
    }
    if self.isDistinct != false {
      try visitor.visitSingularBoolField(value: self.isDistinct, fieldNumber: 7)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_CommonInlineUserDefinedFunction, rhs: Spark_Connect_CommonInlineUserDefinedFunction) -> Bool {
    if lhs.functionName != rhs.functionName {return false}
    if lhs.deterministic != rhs.deterministic {return false}
    if lhs.arguments != rhs.arguments {return false}
    if lhs.function != rhs.function {return false}
    if lhs.isDistinct != rhs.isDistinct {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_PythonUDF: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".PythonUDF"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "output_type"),
    2: .standard(proto: "eval_type"),
    3: .same(proto: "command"),
    4: .standard(proto: "python_ver"),
    5: .standard(proto: "additional_includes"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._outputType) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self.evalType) }()
      case 3: try { try decoder.decodeSingularBytesField(value: &self.command) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.pythonVer) }()
      case 5: try { try decoder.decodeRepeatedStringField(value: &self.additionalIncludes) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._outputType {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if self.evalType != 0 {
      try visitor.visitSingularInt32Field(value: self.evalType, fieldNumber: 2)
    }
    if !self.command.isEmpty {
      try visitor.visitSingularBytesField(value: self.command, fieldNumber: 3)
    }
    if !self.pythonVer.isEmpty {
      try visitor.visitSingularStringField(value: self.pythonVer, fieldNumber: 4)
    }
    if !self.additionalIncludes.isEmpty {
      try visitor.visitRepeatedStringField(value: self.additionalIncludes, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_PythonUDF, rhs: Spark_Connect_PythonUDF) -> Bool {
    if lhs._outputType != rhs._outputType {return false}
    if lhs.evalType != rhs.evalType {return false}
    if lhs.command != rhs.command {return false}
    if lhs.pythonVer != rhs.pythonVer {return false}
    if lhs.additionalIncludes != rhs.additionalIncludes {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_ScalarScalaUDF: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".ScalarScalaUDF"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "payload"),
    2: .same(proto: "inputTypes"),
    3: .same(proto: "outputType"),
    4: .same(proto: "nullable"),
    5: .same(proto: "aggregate"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularBytesField(value: &self.payload) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.inputTypes) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._outputType) }()
      case 4: try { try decoder.decodeSingularBoolField(value: &self.nullable) }()
      case 5: try { try decoder.decodeSingularBoolField(value: &self.aggregate) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.payload.isEmpty {
      try visitor.visitSingularBytesField(value: self.payload, fieldNumber: 1)
    }
    if !self.inputTypes.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.inputTypes, fieldNumber: 2)
    }
    try { if let v = self._outputType {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    if self.nullable != false {
      try visitor.visitSingularBoolField(value: self.nullable, fieldNumber: 4)
    }
    if self.aggregate != false {
      try visitor.visitSingularBoolField(value: self.aggregate, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_ScalarScalaUDF, rhs: Spark_Connect_ScalarScalaUDF) -> Bool {
    if lhs.payload != rhs.payload {return false}
    if lhs.inputTypes != rhs.inputTypes {return false}
    if lhs._outputType != rhs._outputType {return false}
    if lhs.nullable != rhs.nullable {return false}
    if lhs.aggregate != rhs.aggregate {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_JavaUDF: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".JavaUDF"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "class_name"),
    2: .standard(proto: "output_type"),
    3: .same(proto: "aggregate"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.className) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._outputType) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.aggregate) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.className.isEmpty {
      try visitor.visitSingularStringField(value: self.className, fieldNumber: 1)
    }
    try { if let v = self._outputType {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if self.aggregate != false {
      try visitor.visitSingularBoolField(value: self.aggregate, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_JavaUDF, rhs: Spark_Connect_JavaUDF) -> Bool {
    if lhs.className != rhs.className {return false}
    if lhs._outputType != rhs._outputType {return false}
    if lhs.aggregate != rhs.aggregate {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_TypedAggregateExpression: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".TypedAggregateExpression"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "scalar_scala_udf"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._scalarScalaUdf) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._scalarScalaUdf {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_TypedAggregateExpression, rhs: Spark_Connect_TypedAggregateExpression) -> Bool {
    if lhs._scalarScalaUdf != rhs._scalarScalaUdf {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_CallFunction: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".CallFunction"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "function_name"),
    2: .same(proto: "arguments"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.functionName) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.arguments) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.functionName.isEmpty {
      try visitor.visitSingularStringField(value: self.functionName, fieldNumber: 1)
    }
    if !self.arguments.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.arguments, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_CallFunction, rhs: Spark_Connect_CallFunction) -> Bool {
    if lhs.functionName != rhs.functionName {return false}
    if lhs.arguments != rhs.arguments {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_NamedArgumentExpression: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".NamedArgumentExpression"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "key"),
    2: .same(proto: "value"),
  ]

  fileprivate class _StorageClass {
    var _key: String = String()
    var _value: Spark_Connect_Expression? = nil

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _key = source._key
      _value = source._value
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._key) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._value) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._key.isEmpty {
        try visitor.visitSingularStringField(value: _storage._key, fieldNumber: 1)
      }
      try { if let v = _storage._value {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_NamedArgumentExpression, rhs: Spark_Connect_NamedArgumentExpression) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._key != rhs_storage._key {return false}
        if _storage._value != rhs_storage._value {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MergeAction: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".MergeAction"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "action_type"),
    2: .same(proto: "condition"),
    3: .same(proto: "assignments"),
  ]

  fileprivate class _StorageClass {
    var _actionType: Spark_Connect_MergeAction.ActionType = .invalid
    var _condition: Spark_Connect_Expression? = nil
    var _assignments: [Spark_Connect_MergeAction.Assignment] = []

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _actionType = source._actionType
      _condition = source._condition
      _assignments = source._assignments
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularEnumField(value: &_storage._actionType) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._condition) }()
        case 3: try { try decoder.decodeRepeatedMessageField(value: &_storage._assignments) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if _storage._actionType != .invalid {
        try visitor.visitSingularEnumField(value: _storage._actionType, fieldNumber: 1)
      }
      try { if let v = _storage._condition {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      } }()
      if !_storage._assignments.isEmpty {
        try visitor.visitRepeatedMessageField(value: _storage._assignments, fieldNumber: 3)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MergeAction, rhs: Spark_Connect_MergeAction) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._actionType != rhs_storage._actionType {return false}
        if _storage._condition != rhs_storage._condition {return false}
        if _storage._assignments != rhs_storage._assignments {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MergeAction.ActionType: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "ACTION_TYPE_INVALID"),
    1: .same(proto: "ACTION_TYPE_DELETE"),
    2: .same(proto: "ACTION_TYPE_INSERT"),
    3: .same(proto: "ACTION_TYPE_INSERT_STAR"),
    4: .same(proto: "ACTION_TYPE_UPDATE"),
    5: .same(proto: "ACTION_TYPE_UPDATE_STAR"),
  ]
}

extension Spark_Connect_MergeAction.Assignment: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MergeAction.protoMessageName + ".Assignment"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "key"),
    2: .same(proto: "value"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._key) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._value) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._key {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._value {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MergeAction.Assignment, rhs: Spark_Connect_MergeAction.Assignment) -> Bool {
    if lhs._key != rhs._key {return false}
    if lhs._value != rhs._value {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_SubqueryExpression: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".SubqueryExpression"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "plan_id"),
    2: .standard(proto: "subquery_type"),
    3: .standard(proto: "table_arg_options"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt64Field(value: &self.planID) }()
      case 2: try { try decoder.decodeSingularEnumField(value: &self.subqueryType) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._tableArgOptions) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if self.planID != 0 {
      try visitor.visitSingularInt64Field(value: self.planID, fieldNumber: 1)
    }
    if self.subqueryType != .unknown {
      try visitor.visitSingularEnumField(value: self.subqueryType, fieldNumber: 2)
    }
    try { if let v = self._tableArgOptions {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_SubqueryExpression, rhs: Spark_Connect_SubqueryExpression) -> Bool {
    if lhs.planID != rhs.planID {return false}
    if lhs.subqueryType != rhs.subqueryType {return false}
    if lhs._tableArgOptions != rhs._tableArgOptions {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_SubqueryExpression.SubqueryType: SwiftProtobuf._ProtoNameProviding {
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    0: .same(proto: "SUBQUERY_TYPE_UNKNOWN"),
    1: .same(proto: "SUBQUERY_TYPE_SCALAR"),
    2: .same(proto: "SUBQUERY_TYPE_EXISTS"),
    3: .same(proto: "SUBQUERY_TYPE_TABLE_ARG"),
  ]
}

extension Spark_Connect_SubqueryExpression.TableArgOptions: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_SubqueryExpression.protoMessageName + ".TableArgOptions"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "partition_spec"),
    2: .standard(proto: "order_spec"),
    3: .standard(proto: "with_single_partition"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.partitionSpec) }()
      case 2: try { try decoder.decodeRepeatedMessageField(value: &self.orderSpec) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self._withSinglePartition) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.partitionSpec.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.partitionSpec, fieldNumber: 1)
    }
    if !self.orderSpec.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.orderSpec, fieldNumber: 2)
    }
    try { if let v = self._withSinglePartition {
      try visitor.visitSingularBoolField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_SubqueryExpression.TableArgOptions, rhs: Spark_Connect_SubqueryExpression.TableArgOptions) -> Bool {
    if lhs.partitionSpec != rhs.partitionSpec {return false}
    if lhs.orderSpec != rhs.orderSpec {return false}
    if lhs._withSinglePartition != rhs._withSinglePartition {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
