// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: spark/connect/catalog.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

//
// Licensed to the Apache Software Foundation (ASF) under one or more
// contributor license agreements.  See the NOTICE file distributed with
// this work for additional information regarding copyright ownership.
// The ASF licenses this file to You under the Apache License, Version 2.0
// (the "License"); you may not use this file except in compliance with
// the License.  You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Catalog messages are marked as unstable.
struct Spark_Connect_Catalog: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var catType: Spark_Connect_Catalog.OneOf_CatType? = nil

  var currentDatabase: Spark_Connect_CurrentDatabase {
    get {
      if case .currentDatabase(let v)? = catType {return v}
      return Spark_Connect_CurrentDatabase()
    }
    set {catType = .currentDatabase(newValue)}
  }

  var setCurrentDatabase: Spark_Connect_SetCurrentDatabase {
    get {
      if case .setCurrentDatabase(let v)? = catType {return v}
      return Spark_Connect_SetCurrentDatabase()
    }
    set {catType = .setCurrentDatabase(newValue)}
  }

  var listDatabases: Spark_Connect_ListDatabases {
    get {
      if case .listDatabases(let v)? = catType {return v}
      return Spark_Connect_ListDatabases()
    }
    set {catType = .listDatabases(newValue)}
  }

  var listTables: Spark_Connect_ListTables {
    get {
      if case .listTables(let v)? = catType {return v}
      return Spark_Connect_ListTables()
    }
    set {catType = .listTables(newValue)}
  }

  var listFunctions: Spark_Connect_ListFunctions {
    get {
      if case .listFunctions(let v)? = catType {return v}
      return Spark_Connect_ListFunctions()
    }
    set {catType = .listFunctions(newValue)}
  }

  var listColumns: Spark_Connect_ListColumns {
    get {
      if case .listColumns(let v)? = catType {return v}
      return Spark_Connect_ListColumns()
    }
    set {catType = .listColumns(newValue)}
  }

  var getDatabase: Spark_Connect_GetDatabase {
    get {
      if case .getDatabase(let v)? = catType {return v}
      return Spark_Connect_GetDatabase()
    }
    set {catType = .getDatabase(newValue)}
  }

  var getTable: Spark_Connect_GetTable {
    get {
      if case .getTable(let v)? = catType {return v}
      return Spark_Connect_GetTable()
    }
    set {catType = .getTable(newValue)}
  }

  var getFunction: Spark_Connect_GetFunction {
    get {
      if case .getFunction(let v)? = catType {return v}
      return Spark_Connect_GetFunction()
    }
    set {catType = .getFunction(newValue)}
  }

  var databaseExists: Spark_Connect_DatabaseExists {
    get {
      if case .databaseExists(let v)? = catType {return v}
      return Spark_Connect_DatabaseExists()
    }
    set {catType = .databaseExists(newValue)}
  }

  var tableExists: Spark_Connect_TableExists {
    get {
      if case .tableExists(let v)? = catType {return v}
      return Spark_Connect_TableExists()
    }
    set {catType = .tableExists(newValue)}
  }

  var functionExists: Spark_Connect_FunctionExists {
    get {
      if case .functionExists(let v)? = catType {return v}
      return Spark_Connect_FunctionExists()
    }
    set {catType = .functionExists(newValue)}
  }

  var createExternalTable: Spark_Connect_CreateExternalTable {
    get {
      if case .createExternalTable(let v)? = catType {return v}
      return Spark_Connect_CreateExternalTable()
    }
    set {catType = .createExternalTable(newValue)}
  }

  var createTable: Spark_Connect_CreateTable {
    get {
      if case .createTable(let v)? = catType {return v}
      return Spark_Connect_CreateTable()
    }
    set {catType = .createTable(newValue)}
  }

  var dropTempView: Spark_Connect_DropTempView {
    get {
      if case .dropTempView(let v)? = catType {return v}
      return Spark_Connect_DropTempView()
    }
    set {catType = .dropTempView(newValue)}
  }

  var dropGlobalTempView: Spark_Connect_DropGlobalTempView {
    get {
      if case .dropGlobalTempView(let v)? = catType {return v}
      return Spark_Connect_DropGlobalTempView()
    }
    set {catType = .dropGlobalTempView(newValue)}
  }

  var recoverPartitions: Spark_Connect_RecoverPartitions {
    get {
      if case .recoverPartitions(let v)? = catType {return v}
      return Spark_Connect_RecoverPartitions()
    }
    set {catType = .recoverPartitions(newValue)}
  }

  var isCached: Spark_Connect_IsCached {
    get {
      if case .isCached(let v)? = catType {return v}
      return Spark_Connect_IsCached()
    }
    set {catType = .isCached(newValue)}
  }

  var cacheTable: Spark_Connect_CacheTable {
    get {
      if case .cacheTable(let v)? = catType {return v}
      return Spark_Connect_CacheTable()
    }
    set {catType = .cacheTable(newValue)}
  }

  var uncacheTable: Spark_Connect_UncacheTable {
    get {
      if case .uncacheTable(let v)? = catType {return v}
      return Spark_Connect_UncacheTable()
    }
    set {catType = .uncacheTable(newValue)}
  }

  var clearCache_p: Spark_Connect_ClearCache {
    get {
      if case .clearCache_p(let v)? = catType {return v}
      return Spark_Connect_ClearCache()
    }
    set {catType = .clearCache_p(newValue)}
  }

  var refreshTable: Spark_Connect_RefreshTable {
    get {
      if case .refreshTable(let v)? = catType {return v}
      return Spark_Connect_RefreshTable()
    }
    set {catType = .refreshTable(newValue)}
  }

  var refreshByPath: Spark_Connect_RefreshByPath {
    get {
      if case .refreshByPath(let v)? = catType {return v}
      return Spark_Connect_RefreshByPath()
    }
    set {catType = .refreshByPath(newValue)}
  }

  var currentCatalog: Spark_Connect_CurrentCatalog {
    get {
      if case .currentCatalog(let v)? = catType {return v}
      return Spark_Connect_CurrentCatalog()
    }
    set {catType = .currentCatalog(newValue)}
  }

  var setCurrentCatalog: Spark_Connect_SetCurrentCatalog {
    get {
      if case .setCurrentCatalog(let v)? = catType {return v}
      return Spark_Connect_SetCurrentCatalog()
    }
    set {catType = .setCurrentCatalog(newValue)}
  }

  var listCatalogs: Spark_Connect_ListCatalogs {
    get {
      if case .listCatalogs(let v)? = catType {return v}
      return Spark_Connect_ListCatalogs()
    }
    set {catType = .listCatalogs(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_CatType: Equatable, Sendable {
    case currentDatabase(Spark_Connect_CurrentDatabase)
    case setCurrentDatabase(Spark_Connect_SetCurrentDatabase)
    case listDatabases(Spark_Connect_ListDatabases)
    case listTables(Spark_Connect_ListTables)
    case listFunctions(Spark_Connect_ListFunctions)
    case listColumns(Spark_Connect_ListColumns)
    case getDatabase(Spark_Connect_GetDatabase)
    case getTable(Spark_Connect_GetTable)
    case getFunction(Spark_Connect_GetFunction)
    case databaseExists(Spark_Connect_DatabaseExists)
    case tableExists(Spark_Connect_TableExists)
    case functionExists(Spark_Connect_FunctionExists)
    case createExternalTable(Spark_Connect_CreateExternalTable)
    case createTable(Spark_Connect_CreateTable)
    case dropTempView(Spark_Connect_DropTempView)
    case dropGlobalTempView(Spark_Connect_DropGlobalTempView)
    case recoverPartitions(Spark_Connect_RecoverPartitions)
    case isCached(Spark_Connect_IsCached)
    case cacheTable(Spark_Connect_CacheTable)
    case uncacheTable(Spark_Connect_UncacheTable)
    case clearCache_p(Spark_Connect_ClearCache)
    case refreshTable(Spark_Connect_RefreshTable)
    case refreshByPath(Spark_Connect_RefreshByPath)
    case currentCatalog(Spark_Connect_CurrentCatalog)
    case setCurrentCatalog(Spark_Connect_SetCurrentCatalog)
    case listCatalogs(Spark_Connect_ListCatalogs)

  }

  init() {}
}

/// See `spark.catalog.currentDatabase`
struct Spark_Connect_CurrentDatabase: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// See `spark.catalog.setCurrentDatabase`
struct Spark_Connect_SetCurrentDatabase: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var dbName: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// See `spark.catalog.listDatabases`
struct Spark_Connect_ListDatabases: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Optional) The pattern that the database name needs to match
  var pattern: String {
    get {return _pattern ?? String()}
    set {_pattern = newValue}
  }
  /// Returns true if `pattern` has been explicitly set.
  var hasPattern: Bool {return self._pattern != nil}
  /// Clears the value of `pattern`. Subsequent reads from it will return its default value.
  mutating func clearPattern() {self._pattern = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _pattern: String? = nil
}

/// See `spark.catalog.listTables`
struct Spark_Connect_ListTables: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Optional)
  var dbName: String {
    get {return _dbName ?? String()}
    set {_dbName = newValue}
  }
  /// Returns true if `dbName` has been explicitly set.
  var hasDbName: Bool {return self._dbName != nil}
  /// Clears the value of `dbName`. Subsequent reads from it will return its default value.
  mutating func clearDbName() {self._dbName = nil}

  /// (Optional) The pattern that the table name needs to match
  var pattern: String {
    get {return _pattern ?? String()}
    set {_pattern = newValue}
  }
  /// Returns true if `pattern` has been explicitly set.
  var hasPattern: Bool {return self._pattern != nil}
  /// Clears the value of `pattern`. Subsequent reads from it will return its default value.
  mutating func clearPattern() {self._pattern = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _dbName: String? = nil
  fileprivate var _pattern: String? = nil
}

/// See `spark.catalog.listFunctions`
struct Spark_Connect_ListFunctions: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Optional)
  var dbName: String {
    get {return _dbName ?? String()}
    set {_dbName = newValue}
  }
  /// Returns true if `dbName` has been explicitly set.
  var hasDbName: Bool {return self._dbName != nil}
  /// Clears the value of `dbName`. Subsequent reads from it will return its default value.
  mutating func clearDbName() {self._dbName = nil}

  /// (Optional) The pattern that the function name needs to match
  var pattern: String {
    get {return _pattern ?? String()}
    set {_pattern = newValue}
  }
  /// Returns true if `pattern` has been explicitly set.
  var hasPattern: Bool {return self._pattern != nil}
  /// Clears the value of `pattern`. Subsequent reads from it will return its default value.
  mutating func clearPattern() {self._pattern = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _dbName: String? = nil
  fileprivate var _pattern: String? = nil
}

/// See `spark.catalog.listColumns`
struct Spark_Connect_ListColumns: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var tableName: String = String()

  /// (Optional)
  var dbName: String {
    get {return _dbName ?? String()}
    set {_dbName = newValue}
  }
  /// Returns true if `dbName` has been explicitly set.
  var hasDbName: Bool {return self._dbName != nil}
  /// Clears the value of `dbName`. Subsequent reads from it will return its default value.
  mutating func clearDbName() {self._dbName = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _dbName: String? = nil
}

/// See `spark.catalog.getDatabase`
struct Spark_Connect_GetDatabase: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var dbName: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// See `spark.catalog.getTable`
struct Spark_Connect_GetTable: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var tableName: String = String()

  /// (Optional)
  var dbName: String {
    get {return _dbName ?? String()}
    set {_dbName = newValue}
  }
  /// Returns true if `dbName` has been explicitly set.
  var hasDbName: Bool {return self._dbName != nil}
  /// Clears the value of `dbName`. Subsequent reads from it will return its default value.
  mutating func clearDbName() {self._dbName = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _dbName: String? = nil
}

/// See `spark.catalog.getFunction`
struct Spark_Connect_GetFunction: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var functionName: String = String()

  /// (Optional)
  var dbName: String {
    get {return _dbName ?? String()}
    set {_dbName = newValue}
  }
  /// Returns true if `dbName` has been explicitly set.
  var hasDbName: Bool {return self._dbName != nil}
  /// Clears the value of `dbName`. Subsequent reads from it will return its default value.
  mutating func clearDbName() {self._dbName = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _dbName: String? = nil
}

/// See `spark.catalog.databaseExists`
struct Spark_Connect_DatabaseExists: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var dbName: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// See `spark.catalog.tableExists`
struct Spark_Connect_TableExists: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var tableName: String = String()

  /// (Optional)
  var dbName: String {
    get {return _dbName ?? String()}
    set {_dbName = newValue}
  }
  /// Returns true if `dbName` has been explicitly set.
  var hasDbName: Bool {return self._dbName != nil}
  /// Clears the value of `dbName`. Subsequent reads from it will return its default value.
  mutating func clearDbName() {self._dbName = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _dbName: String? = nil
}

/// See `spark.catalog.functionExists`
struct Spark_Connect_FunctionExists: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var functionName: String = String()

  /// (Optional)
  var dbName: String {
    get {return _dbName ?? String()}
    set {_dbName = newValue}
  }
  /// Returns true if `dbName` has been explicitly set.
  var hasDbName: Bool {return self._dbName != nil}
  /// Clears the value of `dbName`. Subsequent reads from it will return its default value.
  mutating func clearDbName() {self._dbName = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _dbName: String? = nil
}

/// See `spark.catalog.createExternalTable`
struct Spark_Connect_CreateExternalTable: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var tableName: String = String()

  /// (Optional)
  var path: String {
    get {return _path ?? String()}
    set {_path = newValue}
  }
  /// Returns true if `path` has been explicitly set.
  var hasPath: Bool {return self._path != nil}
  /// Clears the value of `path`. Subsequent reads from it will return its default value.
  mutating func clearPath() {self._path = nil}

  /// (Optional)
  var source: String {
    get {return _source ?? String()}
    set {_source = newValue}
  }
  /// Returns true if `source` has been explicitly set.
  var hasSource: Bool {return self._source != nil}
  /// Clears the value of `source`. Subsequent reads from it will return its default value.
  mutating func clearSource() {self._source = nil}

  /// (Optional)
  var schema: Spark_Connect_DataType {
    get {return _schema ?? Spark_Connect_DataType()}
    set {_schema = newValue}
  }
  /// Returns true if `schema` has been explicitly set.
  var hasSchema: Bool {return self._schema != nil}
  /// Clears the value of `schema`. Subsequent reads from it will return its default value.
  mutating func clearSchema() {self._schema = nil}

  /// Options could be empty for valid data source format.
  /// The map key is case insensitive.
  var options: Dictionary<String,String> = [:]

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _path: String? = nil
  fileprivate var _source: String? = nil
  fileprivate var _schema: Spark_Connect_DataType? = nil
}

/// See `spark.catalog.createTable`
struct Spark_Connect_CreateTable: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var tableName: String = String()

  /// (Optional)
  var path: String {
    get {return _path ?? String()}
    set {_path = newValue}
  }
  /// Returns true if `path` has been explicitly set.
  var hasPath: Bool {return self._path != nil}
  /// Clears the value of `path`. Subsequent reads from it will return its default value.
  mutating func clearPath() {self._path = nil}

  /// (Optional)
  var source: String {
    get {return _source ?? String()}
    set {_source = newValue}
  }
  /// Returns true if `source` has been explicitly set.
  var hasSource: Bool {return self._source != nil}
  /// Clears the value of `source`. Subsequent reads from it will return its default value.
  mutating func clearSource() {self._source = nil}

  /// (Optional)
  var description_p: String {
    get {return _description_p ?? String()}
    set {_description_p = newValue}
  }
  /// Returns true if `description_p` has been explicitly set.
  var hasDescription_p: Bool {return self._description_p != nil}
  /// Clears the value of `description_p`. Subsequent reads from it will return its default value.
  mutating func clearDescription_p() {self._description_p = nil}

  /// (Optional)
  var schema: Spark_Connect_DataType {
    get {return _schema ?? Spark_Connect_DataType()}
    set {_schema = newValue}
  }
  /// Returns true if `schema` has been explicitly set.
  var hasSchema: Bool {return self._schema != nil}
  /// Clears the value of `schema`. Subsequent reads from it will return its default value.
  mutating func clearSchema() {self._schema = nil}

  /// Options could be empty for valid data source format.
  /// The map key is case insensitive.
  var options: Dictionary<String,String> = [:]

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _path: String? = nil
  fileprivate var _source: String? = nil
  fileprivate var _description_p: String? = nil
  fileprivate var _schema: Spark_Connect_DataType? = nil
}

/// See `spark.catalog.dropTempView`
struct Spark_Connect_DropTempView: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var viewName: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// See `spark.catalog.dropGlobalTempView`
struct Spark_Connect_DropGlobalTempView: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var viewName: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// See `spark.catalog.recoverPartitions`
struct Spark_Connect_RecoverPartitions: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var tableName: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// See `spark.catalog.isCached`
struct Spark_Connect_IsCached: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var tableName: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// See `spark.catalog.cacheTable`
struct Spark_Connect_CacheTable: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var tableName: String = String()

  /// (Optional)
  var storageLevel: Spark_Connect_StorageLevel {
    get {return _storageLevel ?? Spark_Connect_StorageLevel()}
    set {_storageLevel = newValue}
  }
  /// Returns true if `storageLevel` has been explicitly set.
  var hasStorageLevel: Bool {return self._storageLevel != nil}
  /// Clears the value of `storageLevel`. Subsequent reads from it will return its default value.
  mutating func clearStorageLevel() {self._storageLevel = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _storageLevel: Spark_Connect_StorageLevel? = nil
}

/// See `spark.catalog.uncacheTable`
struct Spark_Connect_UncacheTable: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var tableName: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// See `spark.catalog.clearCache`
struct Spark_Connect_ClearCache: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// See `spark.catalog.refreshTable`
struct Spark_Connect_RefreshTable: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var tableName: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// See `spark.catalog.refreshByPath`
struct Spark_Connect_RefreshByPath: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var path: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// See `spark.catalog.currentCatalog`
struct Spark_Connect_CurrentCatalog: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// See `spark.catalog.setCurrentCatalog`
struct Spark_Connect_SetCurrentCatalog: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Required)
  var catalogName: String = String()

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}
}

/// See `spark.catalog.listCatalogs`
struct Spark_Connect_ListCatalogs: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  /// (Optional) The pattern that the catalog name needs to match
  var pattern: String {
    get {return _pattern ?? String()}
    set {_pattern = newValue}
  }
  /// Returns true if `pattern` has been explicitly set.
  var hasPattern: Bool {return self._pattern != nil}
  /// Clears the value of `pattern`. Subsequent reads from it will return its default value.
  mutating func clearPattern() {self._pattern = nil}

  var unknownFields = SwiftProtobuf.UnknownStorage()

  init() {}

  fileprivate var _pattern: String? = nil
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "spark.connect"

extension Spark_Connect_Catalog: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".Catalog"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}current_database\0\u{3}set_current_database\0\u{3}list_databases\0\u{3}list_tables\0\u{3}list_functions\0\u{3}list_columns\0\u{3}get_database\0\u{3}get_table\0\u{3}get_function\0\u{3}database_exists\0\u{3}table_exists\0\u{3}function_exists\0\u{3}create_external_table\0\u{3}create_table\0\u{3}drop_temp_view\0\u{3}drop_global_temp_view\0\u{3}recover_partitions\0\u{3}is_cached\0\u{3}cache_table\0\u{3}uncache_table\0\u{3}clear_cache\0\u{3}refresh_table\0\u{3}refresh_by_path\0\u{3}current_catalog\0\u{3}set_current_catalog\0\u{3}list_catalogs\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Spark_Connect_CurrentDatabase?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .currentDatabase(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .currentDatabase(v)
        }
      }()
      case 2: try {
        var v: Spark_Connect_SetCurrentDatabase?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .setCurrentDatabase(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .setCurrentDatabase(v)
        }
      }()
      case 3: try {
        var v: Spark_Connect_ListDatabases?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .listDatabases(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .listDatabases(v)
        }
      }()
      case 4: try {
        var v: Spark_Connect_ListTables?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .listTables(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .listTables(v)
        }
      }()
      case 5: try {
        var v: Spark_Connect_ListFunctions?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .listFunctions(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .listFunctions(v)
        }
      }()
      case 6: try {
        var v: Spark_Connect_ListColumns?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .listColumns(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .listColumns(v)
        }
      }()
      case 7: try {
        var v: Spark_Connect_GetDatabase?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .getDatabase(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .getDatabase(v)
        }
      }()
      case 8: try {
        var v: Spark_Connect_GetTable?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .getTable(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .getTable(v)
        }
      }()
      case 9: try {
        var v: Spark_Connect_GetFunction?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .getFunction(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .getFunction(v)
        }
      }()
      case 10: try {
        var v: Spark_Connect_DatabaseExists?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .databaseExists(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .databaseExists(v)
        }
      }()
      case 11: try {
        var v: Spark_Connect_TableExists?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .tableExists(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .tableExists(v)
        }
      }()
      case 12: try {
        var v: Spark_Connect_FunctionExists?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .functionExists(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .functionExists(v)
        }
      }()
      case 13: try {
        var v: Spark_Connect_CreateExternalTable?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .createExternalTable(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .createExternalTable(v)
        }
      }()
      case 14: try {
        var v: Spark_Connect_CreateTable?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .createTable(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .createTable(v)
        }
      }()
      case 15: try {
        var v: Spark_Connect_DropTempView?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .dropTempView(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .dropTempView(v)
        }
      }()
      case 16: try {
        var v: Spark_Connect_DropGlobalTempView?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .dropGlobalTempView(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .dropGlobalTempView(v)
        }
      }()
      case 17: try {
        var v: Spark_Connect_RecoverPartitions?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .recoverPartitions(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .recoverPartitions(v)
        }
      }()
      case 18: try {
        var v: Spark_Connect_IsCached?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .isCached(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .isCached(v)
        }
      }()
      case 19: try {
        var v: Spark_Connect_CacheTable?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .cacheTable(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .cacheTable(v)
        }
      }()
      case 20: try {
        var v: Spark_Connect_UncacheTable?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .uncacheTable(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .uncacheTable(v)
        }
      }()
      case 21: try {
        var v: Spark_Connect_ClearCache?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .clearCache_p(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .clearCache_p(v)
        }
      }()
      case 22: try {
        var v: Spark_Connect_RefreshTable?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .refreshTable(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .refreshTable(v)
        }
      }()
      case 23: try {
        var v: Spark_Connect_RefreshByPath?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .refreshByPath(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .refreshByPath(v)
        }
      }()
      case 24: try {
        var v: Spark_Connect_CurrentCatalog?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .currentCatalog(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .currentCatalog(v)
        }
      }()
      case 25: try {
        var v: Spark_Connect_SetCurrentCatalog?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .setCurrentCatalog(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .setCurrentCatalog(v)
        }
      }()
      case 26: try {
        var v: Spark_Connect_ListCatalogs?
        var hadOneofValue = false
        if let current = self.catType {
          hadOneofValue = true
          if case .listCatalogs(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.catType = .listCatalogs(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.catType {
    case .currentDatabase?: try {
      guard case .currentDatabase(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .setCurrentDatabase?: try {
      guard case .setCurrentDatabase(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case .listDatabases?: try {
      guard case .listDatabases(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case .listTables?: try {
      guard case .listTables(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }()
    case .listFunctions?: try {
      guard case .listFunctions(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }()
    case .listColumns?: try {
      guard case .listColumns(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }()
    case .getDatabase?: try {
      guard case .getDatabase(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    }()
    case .getTable?: try {
      guard case .getTable(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    }()
    case .getFunction?: try {
      guard case .getFunction(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
    }()
    case .databaseExists?: try {
      guard case .databaseExists(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
    }()
    case .tableExists?: try {
      guard case .tableExists(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
    }()
    case .functionExists?: try {
      guard case .functionExists(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
    }()
    case .createExternalTable?: try {
      guard case .createExternalTable(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 13)
    }()
    case .createTable?: try {
      guard case .createTable(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 14)
    }()
    case .dropTempView?: try {
      guard case .dropTempView(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 15)
    }()
    case .dropGlobalTempView?: try {
      guard case .dropGlobalTempView(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 16)
    }()
    case .recoverPartitions?: try {
      guard case .recoverPartitions(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 17)
    }()
    case .isCached?: try {
      guard case .isCached(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 18)
    }()
    case .cacheTable?: try {
      guard case .cacheTable(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 19)
    }()
    case .uncacheTable?: try {
      guard case .uncacheTable(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 20)
    }()
    case .clearCache_p?: try {
      guard case .clearCache_p(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 21)
    }()
    case .refreshTable?: try {
      guard case .refreshTable(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 22)
    }()
    case .refreshByPath?: try {
      guard case .refreshByPath(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 23)
    }()
    case .currentCatalog?: try {
      guard case .currentCatalog(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 24)
    }()
    case .setCurrentCatalog?: try {
      guard case .setCurrentCatalog(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 25)
    }()
    case .listCatalogs?: try {
      guard case .listCatalogs(let v)? = self.catType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 26)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_Catalog, rhs: Spark_Connect_Catalog) -> Bool {
    if lhs.catType != rhs.catType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_CurrentDatabase: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".CurrentDatabase"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    // Load everything into unknown fields
    while try decoder.nextFieldNumber() != nil {}
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_CurrentDatabase, rhs: Spark_Connect_CurrentDatabase) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_SetCurrentDatabase: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".SetCurrentDatabase"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}db_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.dbName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.dbName.isEmpty {
      try visitor.visitSingularStringField(value: self.dbName, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_SetCurrentDatabase, rhs: Spark_Connect_SetCurrentDatabase) -> Bool {
    if lhs.dbName != rhs.dbName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_ListDatabases: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".ListDatabases"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}pattern\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self._pattern) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._pattern {
      try visitor.visitSingularStringField(value: v, fieldNumber: 1)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_ListDatabases, rhs: Spark_Connect_ListDatabases) -> Bool {
    if lhs._pattern != rhs._pattern {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_ListTables: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".ListTables"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}db_name\0\u{1}pattern\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self._dbName) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self._pattern) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._dbName {
      try visitor.visitSingularStringField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._pattern {
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_ListTables, rhs: Spark_Connect_ListTables) -> Bool {
    if lhs._dbName != rhs._dbName {return false}
    if lhs._pattern != rhs._pattern {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_ListFunctions: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".ListFunctions"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}db_name\0\u{1}pattern\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self._dbName) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self._pattern) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._dbName {
      try visitor.visitSingularStringField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._pattern {
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_ListFunctions, rhs: Spark_Connect_ListFunctions) -> Bool {
    if lhs._dbName != rhs._dbName {return false}
    if lhs._pattern != rhs._pattern {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_ListColumns: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".ListColumns"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}table_name\0\u{3}db_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.tableName) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self._dbName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.tableName.isEmpty {
      try visitor.visitSingularStringField(value: self.tableName, fieldNumber: 1)
    }
    try { if let v = self._dbName {
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_ListColumns, rhs: Spark_Connect_ListColumns) -> Bool {
    if lhs.tableName != rhs.tableName {return false}
    if lhs._dbName != rhs._dbName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_GetDatabase: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".GetDatabase"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}db_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.dbName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.dbName.isEmpty {
      try visitor.visitSingularStringField(value: self.dbName, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_GetDatabase, rhs: Spark_Connect_GetDatabase) -> Bool {
    if lhs.dbName != rhs.dbName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_GetTable: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".GetTable"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}table_name\0\u{3}db_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.tableName) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self._dbName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.tableName.isEmpty {
      try visitor.visitSingularStringField(value: self.tableName, fieldNumber: 1)
    }
    try { if let v = self._dbName {
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_GetTable, rhs: Spark_Connect_GetTable) -> Bool {
    if lhs.tableName != rhs.tableName {return false}
    if lhs._dbName != rhs._dbName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_GetFunction: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".GetFunction"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}function_name\0\u{3}db_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.functionName) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self._dbName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.functionName.isEmpty {
      try visitor.visitSingularStringField(value: self.functionName, fieldNumber: 1)
    }
    try { if let v = self._dbName {
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_GetFunction, rhs: Spark_Connect_GetFunction) -> Bool {
    if lhs.functionName != rhs.functionName {return false}
    if lhs._dbName != rhs._dbName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DatabaseExists: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".DatabaseExists"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}db_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.dbName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.dbName.isEmpty {
      try visitor.visitSingularStringField(value: self.dbName, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DatabaseExists, rhs: Spark_Connect_DatabaseExists) -> Bool {
    if lhs.dbName != rhs.dbName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_TableExists: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".TableExists"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}table_name\0\u{3}db_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.tableName) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self._dbName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.tableName.isEmpty {
      try visitor.visitSingularStringField(value: self.tableName, fieldNumber: 1)
    }
    try { if let v = self._dbName {
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_TableExists, rhs: Spark_Connect_TableExists) -> Bool {
    if lhs.tableName != rhs.tableName {return false}
    if lhs._dbName != rhs._dbName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_FunctionExists: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".FunctionExists"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}function_name\0\u{3}db_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.functionName) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self._dbName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.functionName.isEmpty {
      try visitor.visitSingularStringField(value: self.functionName, fieldNumber: 1)
    }
    try { if let v = self._dbName {
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_FunctionExists, rhs: Spark_Connect_FunctionExists) -> Bool {
    if lhs.functionName != rhs.functionName {return false}
    if lhs._dbName != rhs._dbName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_CreateExternalTable: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".CreateExternalTable"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}table_name\0\u{1}path\0\u{1}source\0\u{1}schema\0\u{1}options\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.tableName) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self._path) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self._source) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._schema) }()
      case 5: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &self.options) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.tableName.isEmpty {
      try visitor.visitSingularStringField(value: self.tableName, fieldNumber: 1)
    }
    try { if let v = self._path {
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._source {
      try visitor.visitSingularStringField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._schema {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    if !self.options.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: self.options, fieldNumber: 5)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_CreateExternalTable, rhs: Spark_Connect_CreateExternalTable) -> Bool {
    if lhs.tableName != rhs.tableName {return false}
    if lhs._path != rhs._path {return false}
    if lhs._source != rhs._source {return false}
    if lhs._schema != rhs._schema {return false}
    if lhs.options != rhs.options {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_CreateTable: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".CreateTable"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}table_name\0\u{1}path\0\u{1}source\0\u{1}description\0\u{1}schema\0\u{1}options\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.tableName) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self._path) }()
      case 3: try { try decoder.decodeSingularStringField(value: &self._source) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self._description_p) }()
      case 5: try { try decoder.decodeSingularMessageField(value: &self._schema) }()
      case 6: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &self.options) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.tableName.isEmpty {
      try visitor.visitSingularStringField(value: self.tableName, fieldNumber: 1)
    }
    try { if let v = self._path {
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._source {
      try visitor.visitSingularStringField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._description_p {
      try visitor.visitSingularStringField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._schema {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    } }()
    if !self.options.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: self.options, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_CreateTable, rhs: Spark_Connect_CreateTable) -> Bool {
    if lhs.tableName != rhs.tableName {return false}
    if lhs._path != rhs._path {return false}
    if lhs._source != rhs._source {return false}
    if lhs._description_p != rhs._description_p {return false}
    if lhs._schema != rhs._schema {return false}
    if lhs.options != rhs.options {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DropTempView: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".DropTempView"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}view_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.viewName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.viewName.isEmpty {
      try visitor.visitSingularStringField(value: self.viewName, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DropTempView, rhs: Spark_Connect_DropTempView) -> Bool {
    if lhs.viewName != rhs.viewName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DropGlobalTempView: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".DropGlobalTempView"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}view_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.viewName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.viewName.isEmpty {
      try visitor.visitSingularStringField(value: self.viewName, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DropGlobalTempView, rhs: Spark_Connect_DropGlobalTempView) -> Bool {
    if lhs.viewName != rhs.viewName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_RecoverPartitions: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".RecoverPartitions"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}table_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.tableName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.tableName.isEmpty {
      try visitor.visitSingularStringField(value: self.tableName, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_RecoverPartitions, rhs: Spark_Connect_RecoverPartitions) -> Bool {
    if lhs.tableName != rhs.tableName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_IsCached: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".IsCached"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}table_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.tableName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.tableName.isEmpty {
      try visitor.visitSingularStringField(value: self.tableName, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_IsCached, rhs: Spark_Connect_IsCached) -> Bool {
    if lhs.tableName != rhs.tableName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_CacheTable: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".CacheTable"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}table_name\0\u{3}storage_level\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.tableName) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._storageLevel) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.tableName.isEmpty {
      try visitor.visitSingularStringField(value: self.tableName, fieldNumber: 1)
    }
    try { if let v = self._storageLevel {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_CacheTable, rhs: Spark_Connect_CacheTable) -> Bool {
    if lhs.tableName != rhs.tableName {return false}
    if lhs._storageLevel != rhs._storageLevel {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_UncacheTable: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".UncacheTable"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}table_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.tableName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.tableName.isEmpty {
      try visitor.visitSingularStringField(value: self.tableName, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_UncacheTable, rhs: Spark_Connect_UncacheTable) -> Bool {
    if lhs.tableName != rhs.tableName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_ClearCache: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".ClearCache"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    // Load everything into unknown fields
    while try decoder.nextFieldNumber() != nil {}
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_ClearCache, rhs: Spark_Connect_ClearCache) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_RefreshTable: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".RefreshTable"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}table_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.tableName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.tableName.isEmpty {
      try visitor.visitSingularStringField(value: self.tableName, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_RefreshTable, rhs: Spark_Connect_RefreshTable) -> Bool {
    if lhs.tableName != rhs.tableName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_RefreshByPath: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".RefreshByPath"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}path\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.path) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.path.isEmpty {
      try visitor.visitSingularStringField(value: self.path, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_RefreshByPath, rhs: Spark_Connect_RefreshByPath) -> Bool {
    if lhs.path != rhs.path {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_CurrentCatalog: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".CurrentCatalog"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    // Load everything into unknown fields
    while try decoder.nextFieldNumber() != nil {}
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_CurrentCatalog, rhs: Spark_Connect_CurrentCatalog) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_SetCurrentCatalog: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".SetCurrentCatalog"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}catalog_name\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.catalogName) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.catalogName.isEmpty {
      try visitor.visitSingularStringField(value: self.catalogName, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_SetCurrentCatalog, rhs: Spark_Connect_SetCurrentCatalog) -> Bool {
    if lhs.catalogName != rhs.catalogName {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_ListCatalogs: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".ListCatalogs"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}pattern\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self._pattern) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._pattern {
      try visitor.visitSingularStringField(value: v, fieldNumber: 1)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_ListCatalogs, rhs: Spark_Connect_ListCatalogs) -> Bool {
    if lhs._pattern != rhs._pattern {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
