// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: spark/connect/types.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

//
// Licensed to the Apache Software Foundation (ASF) under one or more
// contributor license agreements.  See the NOTICE file distributed with
// this work for additional information regarding copyright ownership.
// The ASF licenses this file to You under the Apache License, Version 2.0
// (the "License"); you may not use this file except in compliance with
// the License.  You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// This message describes the logical [[DataType]] of something. It does not carry the value
/// itself but only describes it.
struct Spark_Connect_DataType: @unchecked Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var kind: OneOf_Kind? {
    get {return _storage._kind}
    set {_uniqueStorage()._kind = newValue}
  }

  var null: Spark_Connect_DataType.NULL {
    get {
      if case .null(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.NULL()
    }
    set {_uniqueStorage()._kind = .null(newValue)}
  }

  var binary: Spark_Connect_DataType.Binary {
    get {
      if case .binary(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Binary()
    }
    set {_uniqueStorage()._kind = .binary(newValue)}
  }

  var boolean: Spark_Connect_DataType.Boolean {
    get {
      if case .boolean(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Boolean()
    }
    set {_uniqueStorage()._kind = .boolean(newValue)}
  }

  /// Numeric types
  var byte: Spark_Connect_DataType.Byte {
    get {
      if case .byte(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Byte()
    }
    set {_uniqueStorage()._kind = .byte(newValue)}
  }

  var short: Spark_Connect_DataType.Short {
    get {
      if case .short(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Short()
    }
    set {_uniqueStorage()._kind = .short(newValue)}
  }

  var integer: Spark_Connect_DataType.Integer {
    get {
      if case .integer(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Integer()
    }
    set {_uniqueStorage()._kind = .integer(newValue)}
  }

  var long: Spark_Connect_DataType.Long {
    get {
      if case .long(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Long()
    }
    set {_uniqueStorage()._kind = .long(newValue)}
  }

  var float: Spark_Connect_DataType.FloatMessage {
    get {
      if case .float(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.FloatMessage()
    }
    set {_uniqueStorage()._kind = .float(newValue)}
  }

  var double: Spark_Connect_DataType.DoubleMessage {
    get {
      if case .double(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.DoubleMessage()
    }
    set {_uniqueStorage()._kind = .double(newValue)}
  }

  var decimal: Spark_Connect_DataType.Decimal {
    get {
      if case .decimal(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Decimal()
    }
    set {_uniqueStorage()._kind = .decimal(newValue)}
  }

  /// String types
  var string: Spark_Connect_DataType.StringMessage {
    get {
      if case .string(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.StringMessage()
    }
    set {_uniqueStorage()._kind = .string(newValue)}
  }

  var char: Spark_Connect_DataType.Char {
    get {
      if case .char(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Char()
    }
    set {_uniqueStorage()._kind = .char(newValue)}
  }

  var varChar: Spark_Connect_DataType.VarChar {
    get {
      if case .varChar(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.VarChar()
    }
    set {_uniqueStorage()._kind = .varChar(newValue)}
  }

  /// Datatime types
  var date: Spark_Connect_DataType.Date {
    get {
      if case .date(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Date()
    }
    set {_uniqueStorage()._kind = .date(newValue)}
  }

  var timestamp: Spark_Connect_DataType.Timestamp {
    get {
      if case .timestamp(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Timestamp()
    }
    set {_uniqueStorage()._kind = .timestamp(newValue)}
  }

  var timestampNtz: Spark_Connect_DataType.TimestampNTZ {
    get {
      if case .timestampNtz(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.TimestampNTZ()
    }
    set {_uniqueStorage()._kind = .timestampNtz(newValue)}
  }

  /// Interval types
  var calendarInterval: Spark_Connect_DataType.CalendarInterval {
    get {
      if case .calendarInterval(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.CalendarInterval()
    }
    set {_uniqueStorage()._kind = .calendarInterval(newValue)}
  }

  var yearMonthInterval: Spark_Connect_DataType.YearMonthInterval {
    get {
      if case .yearMonthInterval(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.YearMonthInterval()
    }
    set {_uniqueStorage()._kind = .yearMonthInterval(newValue)}
  }

  var dayTimeInterval: Spark_Connect_DataType.DayTimeInterval {
    get {
      if case .dayTimeInterval(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.DayTimeInterval()
    }
    set {_uniqueStorage()._kind = .dayTimeInterval(newValue)}
  }

  /// Complex types
  var array: Spark_Connect_DataType.Array {
    get {
      if case .array(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Array()
    }
    set {_uniqueStorage()._kind = .array(newValue)}
  }

  var `struct`: Spark_Connect_DataType.Struct {
    get {
      if case .struct(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Struct()
    }
    set {_uniqueStorage()._kind = .struct(newValue)}
  }

  var map: Spark_Connect_DataType.Map {
    get {
      if case .map(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Map()
    }
    set {_uniqueStorage()._kind = .map(newValue)}
  }

  var variant: Spark_Connect_DataType.Variant {
    get {
      if case .variant(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Variant()
    }
    set {_uniqueStorage()._kind = .variant(newValue)}
  }

  /// UserDefinedType
  var udt: Spark_Connect_DataType.UDT {
    get {
      if case .udt(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.UDT()
    }
    set {_uniqueStorage()._kind = .udt(newValue)}
  }

  /// UnparsedDataType
  var unparsed: Spark_Connect_DataType.Unparsed {
    get {
      if case .unparsed(let v)? = _storage._kind {return v}
      return Spark_Connect_DataType.Unparsed()
    }
    set {_uniqueStorage()._kind = .unparsed(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_Kind: Equatable, Sendable {
    case null(Spark_Connect_DataType.NULL)
    case binary(Spark_Connect_DataType.Binary)
    case boolean(Spark_Connect_DataType.Boolean)
    /// Numeric types
    case byte(Spark_Connect_DataType.Byte)
    case short(Spark_Connect_DataType.Short)
    case integer(Spark_Connect_DataType.Integer)
    case long(Spark_Connect_DataType.Long)
    case float(Spark_Connect_DataType.FloatMessage)
    case double(Spark_Connect_DataType.DoubleMessage)
    case decimal(Spark_Connect_DataType.Decimal)
    /// String types
    case string(Spark_Connect_DataType.StringMessage)
    case char(Spark_Connect_DataType.Char)
    case varChar(Spark_Connect_DataType.VarChar)
    /// Datatime types
    case date(Spark_Connect_DataType.Date)
    case timestamp(Spark_Connect_DataType.Timestamp)
    case timestampNtz(Spark_Connect_DataType.TimestampNTZ)
    /// Interval types
    case calendarInterval(Spark_Connect_DataType.CalendarInterval)
    case yearMonthInterval(Spark_Connect_DataType.YearMonthInterval)
    case dayTimeInterval(Spark_Connect_DataType.DayTimeInterval)
    /// Complex types
    case array(Spark_Connect_DataType.Array)
    case `struct`(Spark_Connect_DataType.Struct)
    case map(Spark_Connect_DataType.Map)
    case variant(Spark_Connect_DataType.Variant)
    /// UserDefinedType
    case udt(Spark_Connect_DataType.UDT)
    /// UnparsedDataType
    case unparsed(Spark_Connect_DataType.Unparsed)

  }

  struct Boolean: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct Byte: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct Short: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct Integer: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct Long: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct FloatMessage: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct DoubleMessage: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct StringMessage: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var collation: String = String()

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct Binary: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct NULL: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct Timestamp: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct Date: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct TimestampNTZ: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct CalendarInterval: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct YearMonthInterval: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var startField: Int32 {
      get {return _startField ?? 0}
      set {_startField = newValue}
    }
    /// Returns true if `startField` has been explicitly set.
    var hasStartField: Bool {return self._startField != nil}
    /// Clears the value of `startField`. Subsequent reads from it will return its default value.
    mutating func clearStartField() {self._startField = nil}

    var endField: Int32 {
      get {return _endField ?? 0}
      set {_endField = newValue}
    }
    /// Returns true if `endField` has been explicitly set.
    var hasEndField: Bool {return self._endField != nil}
    /// Clears the value of `endField`. Subsequent reads from it will return its default value.
    mutating func clearEndField() {self._endField = nil}

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _startField: Int32? = nil
    fileprivate var _endField: Int32? = nil
  }

  struct DayTimeInterval: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var startField: Int32 {
      get {return _startField ?? 0}
      set {_startField = newValue}
    }
    /// Returns true if `startField` has been explicitly set.
    var hasStartField: Bool {return self._startField != nil}
    /// Clears the value of `startField`. Subsequent reads from it will return its default value.
    mutating func clearStartField() {self._startField = nil}

    var endField: Int32 {
      get {return _endField ?? 0}
      set {_endField = newValue}
    }
    /// Returns true if `endField` has been explicitly set.
    var hasEndField: Bool {return self._endField != nil}
    /// Clears the value of `endField`. Subsequent reads from it will return its default value.
    mutating func clearEndField() {self._endField = nil}

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _startField: Int32? = nil
    fileprivate var _endField: Int32? = nil
  }

  /// Start compound types.
  struct Char: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var length: Int32 = 0

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct VarChar: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var length: Int32 = 0

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct Decimal: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var scale: Int32 {
      get {return _scale ?? 0}
      set {_scale = newValue}
    }
    /// Returns true if `scale` has been explicitly set.
    var hasScale: Bool {return self._scale != nil}
    /// Clears the value of `scale`. Subsequent reads from it will return its default value.
    mutating func clearScale() {self._scale = nil}

    var precision: Int32 {
      get {return _precision ?? 0}
      set {_precision = newValue}
    }
    /// Returns true if `precision` has been explicitly set.
    var hasPrecision: Bool {return self._precision != nil}
    /// Clears the value of `precision`. Subsequent reads from it will return its default value.
    mutating func clearPrecision() {self._precision = nil}

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _scale: Int32? = nil
    fileprivate var _precision: Int32? = nil
  }

  struct StructField: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var name: String = String()

    var dataType: Spark_Connect_DataType {
      get {return _dataType ?? Spark_Connect_DataType()}
      set {_dataType = newValue}
    }
    /// Returns true if `dataType` has been explicitly set.
    var hasDataType: Bool {return self._dataType != nil}
    /// Clears the value of `dataType`. Subsequent reads from it will return its default value.
    mutating func clearDataType() {self._dataType = nil}

    var nullable: Bool = false

    var metadata: String {
      get {return _metadata ?? String()}
      set {_metadata = newValue}
    }
    /// Returns true if `metadata` has been explicitly set.
    var hasMetadata: Bool {return self._metadata != nil}
    /// Clears the value of `metadata`. Subsequent reads from it will return its default value.
    mutating func clearMetadata() {self._metadata = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _dataType: Spark_Connect_DataType? = nil
    fileprivate var _metadata: String? = nil
  }

  struct Struct: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var fields: [Spark_Connect_DataType.StructField] = []

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct Array: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var elementType: Spark_Connect_DataType {
      get {return _storage._elementType ?? Spark_Connect_DataType()}
      set {_uniqueStorage()._elementType = newValue}
    }
    /// Returns true if `elementType` has been explicitly set.
    var hasElementType: Bool {return _storage._elementType != nil}
    /// Clears the value of `elementType`. Subsequent reads from it will return its default value.
    mutating func clearElementType() {_uniqueStorage()._elementType = nil}

    var containsNull: Bool {
      get {return _storage._containsNull}
      set {_uniqueStorage()._containsNull = newValue}
    }

    var typeVariationReference: UInt32 {
      get {return _storage._typeVariationReference}
      set {_uniqueStorage()._typeVariationReference = newValue}
    }

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  struct Map: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var keyType: Spark_Connect_DataType {
      get {return _storage._keyType ?? Spark_Connect_DataType()}
      set {_uniqueStorage()._keyType = newValue}
    }
    /// Returns true if `keyType` has been explicitly set.
    var hasKeyType: Bool {return _storage._keyType != nil}
    /// Clears the value of `keyType`. Subsequent reads from it will return its default value.
    mutating func clearKeyType() {_uniqueStorage()._keyType = nil}

    var valueType: Spark_Connect_DataType {
      get {return _storage._valueType ?? Spark_Connect_DataType()}
      set {_uniqueStorage()._valueType = newValue}
    }
    /// Returns true if `valueType` has been explicitly set.
    var hasValueType: Bool {return _storage._valueType != nil}
    /// Clears the value of `valueType`. Subsequent reads from it will return its default value.
    mutating func clearValueType() {_uniqueStorage()._valueType = nil}

    var valueContainsNull: Bool {
      get {return _storage._valueContainsNull}
      set {_uniqueStorage()._valueContainsNull = newValue}
    }

    var typeVariationReference: UInt32 {
      get {return _storage._typeVariationReference}
      set {_uniqueStorage()._typeVariationReference = newValue}
    }

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  struct Variant: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var typeVariationReference: UInt32 = 0

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  struct UDT: @unchecked Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var type: String {
      get {return _storage._type}
      set {_uniqueStorage()._type = newValue}
    }

    /// Required for Scala/Java UDT
    var jvmClass: String {
      get {return _storage._jvmClass ?? String()}
      set {_uniqueStorage()._jvmClass = newValue}
    }
    /// Returns true if `jvmClass` has been explicitly set.
    var hasJvmClass: Bool {return _storage._jvmClass != nil}
    /// Clears the value of `jvmClass`. Subsequent reads from it will return its default value.
    mutating func clearJvmClass() {_uniqueStorage()._jvmClass = nil}

    /// Required for Python UDT
    var pythonClass: String {
      get {return _storage._pythonClass ?? String()}
      set {_uniqueStorage()._pythonClass = newValue}
    }
    /// Returns true if `pythonClass` has been explicitly set.
    var hasPythonClass: Bool {return _storage._pythonClass != nil}
    /// Clears the value of `pythonClass`. Subsequent reads from it will return its default value.
    mutating func clearPythonClass() {_uniqueStorage()._pythonClass = nil}

    /// Required for Python UDT
    var serializedPythonClass: String {
      get {return _storage._serializedPythonClass ?? String()}
      set {_uniqueStorage()._serializedPythonClass = newValue}
    }
    /// Returns true if `serializedPythonClass` has been explicitly set.
    var hasSerializedPythonClass: Bool {return _storage._serializedPythonClass != nil}
    /// Clears the value of `serializedPythonClass`. Subsequent reads from it will return its default value.
    mutating func clearSerializedPythonClass() {_uniqueStorage()._serializedPythonClass = nil}

    /// Required for Python UDT
    var sqlType: Spark_Connect_DataType {
      get {return _storage._sqlType ?? Spark_Connect_DataType()}
      set {_uniqueStorage()._sqlType = newValue}
    }
    /// Returns true if `sqlType` has been explicitly set.
    var hasSqlType: Bool {return _storage._sqlType != nil}
    /// Clears the value of `sqlType`. Subsequent reads from it will return its default value.
    mutating func clearSqlType() {_uniqueStorage()._sqlType = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _storage = _StorageClass.defaultInstance
  }

  struct Unparsed: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) The unparsed data type string
    var dataTypeString: String = String()

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  init() {}

  fileprivate var _storage = _StorageClass.defaultInstance
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "spark.connect"

extension Spark_Connect_DataType: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".DataType"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}null\0\u{1}binary\0\u{1}boolean\0\u{1}byte\0\u{1}short\0\u{1}integer\0\u{1}long\0\u{1}float\0\u{1}double\0\u{1}decimal\0\u{1}string\0\u{1}char\0\u{3}var_char\0\u{1}date\0\u{1}timestamp\0\u{3}timestamp_ntz\0\u{3}calendar_interval\0\u{3}year_month_interval\0\u{3}day_time_interval\0\u{1}array\0\u{1}struct\0\u{1}map\0\u{1}udt\0\u{1}unparsed\0\u{1}variant\0\u{c}\u{1a}\u{1}\u{c}\u{1b}\u{1}")

  fileprivate class _StorageClass {
    var _kind: Spark_Connect_DataType.OneOf_Kind?

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _kind = source._kind
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try {
          var v: Spark_Connect_DataType.NULL?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .null(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .null(v)
          }
        }()
        case 2: try {
          var v: Spark_Connect_DataType.Binary?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .binary(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .binary(v)
          }
        }()
        case 3: try {
          var v: Spark_Connect_DataType.Boolean?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .boolean(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .boolean(v)
          }
        }()
        case 4: try {
          var v: Spark_Connect_DataType.Byte?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .byte(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .byte(v)
          }
        }()
        case 5: try {
          var v: Spark_Connect_DataType.Short?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .short(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .short(v)
          }
        }()
        case 6: try {
          var v: Spark_Connect_DataType.Integer?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .integer(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .integer(v)
          }
        }()
        case 7: try {
          var v: Spark_Connect_DataType.Long?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .long(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .long(v)
          }
        }()
        case 8: try {
          var v: Spark_Connect_DataType.FloatMessage?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .float(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .float(v)
          }
        }()
        case 9: try {
          var v: Spark_Connect_DataType.DoubleMessage?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .double(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .double(v)
          }
        }()
        case 10: try {
          var v: Spark_Connect_DataType.Decimal?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .decimal(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .decimal(v)
          }
        }()
        case 11: try {
          var v: Spark_Connect_DataType.StringMessage?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .string(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .string(v)
          }
        }()
        case 12: try {
          var v: Spark_Connect_DataType.Char?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .char(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .char(v)
          }
        }()
        case 13: try {
          var v: Spark_Connect_DataType.VarChar?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .varChar(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .varChar(v)
          }
        }()
        case 14: try {
          var v: Spark_Connect_DataType.Date?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .date(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .date(v)
          }
        }()
        case 15: try {
          var v: Spark_Connect_DataType.Timestamp?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .timestamp(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .timestamp(v)
          }
        }()
        case 16: try {
          var v: Spark_Connect_DataType.TimestampNTZ?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .timestampNtz(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .timestampNtz(v)
          }
        }()
        case 17: try {
          var v: Spark_Connect_DataType.CalendarInterval?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .calendarInterval(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .calendarInterval(v)
          }
        }()
        case 18: try {
          var v: Spark_Connect_DataType.YearMonthInterval?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .yearMonthInterval(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .yearMonthInterval(v)
          }
        }()
        case 19: try {
          var v: Spark_Connect_DataType.DayTimeInterval?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .dayTimeInterval(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .dayTimeInterval(v)
          }
        }()
        case 20: try {
          var v: Spark_Connect_DataType.Array?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .array(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .array(v)
          }
        }()
        case 21: try {
          var v: Spark_Connect_DataType.Struct?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .struct(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .struct(v)
          }
        }()
        case 22: try {
          var v: Spark_Connect_DataType.Map?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .map(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .map(v)
          }
        }()
        case 23: try {
          var v: Spark_Connect_DataType.UDT?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .udt(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .udt(v)
          }
        }()
        case 24: try {
          var v: Spark_Connect_DataType.Unparsed?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .unparsed(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .unparsed(v)
          }
        }()
        case 25: try {
          var v: Spark_Connect_DataType.Variant?
          var hadOneofValue = false
          if let current = _storage._kind {
            hadOneofValue = true
            if case .variant(let m) = current {v = m}
          }
          try decoder.decodeSingularMessageField(value: &v)
          if let v = v {
            if hadOneofValue {try decoder.handleConflictingOneOf()}
            _storage._kind = .variant(v)
          }
        }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      switch _storage._kind {
      case .null?: try {
        guard case .null(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      }()
      case .binary?: try {
        guard case .binary(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      }()
      case .boolean?: try {
        guard case .boolean(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
      }()
      case .byte?: try {
        guard case .byte(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
      }()
      case .short?: try {
        guard case .short(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      }()
      case .integer?: try {
        guard case .integer(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
      }()
      case .long?: try {
        guard case .long(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
      }()
      case .float?: try {
        guard case .float(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
      }()
      case .double?: try {
        guard case .double(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
      }()
      case .decimal?: try {
        guard case .decimal(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
      }()
      case .string?: try {
        guard case .string(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 11)
      }()
      case .char?: try {
        guard case .char(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 12)
      }()
      case .varChar?: try {
        guard case .varChar(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 13)
      }()
      case .date?: try {
        guard case .date(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 14)
      }()
      case .timestamp?: try {
        guard case .timestamp(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 15)
      }()
      case .timestampNtz?: try {
        guard case .timestampNtz(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 16)
      }()
      case .calendarInterval?: try {
        guard case .calendarInterval(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 17)
      }()
      case .yearMonthInterval?: try {
        guard case .yearMonthInterval(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 18)
      }()
      case .dayTimeInterval?: try {
        guard case .dayTimeInterval(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 19)
      }()
      case .array?: try {
        guard case .array(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 20)
      }()
      case .struct?: try {
        guard case .struct(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 21)
      }()
      case .map?: try {
        guard case .map(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 22)
      }()
      case .udt?: try {
        guard case .udt(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 23)
      }()
      case .unparsed?: try {
        guard case .unparsed(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 24)
      }()
      case .variant?: try {
        guard case .variant(let v)? = _storage._kind else { preconditionFailure() }
        try visitor.visitSingularMessageField(value: v, fieldNumber: 25)
      }()
      case nil: break
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType, rhs: Spark_Connect_DataType) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._kind != rhs_storage._kind {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Boolean: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Boolean"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Boolean, rhs: Spark_Connect_DataType.Boolean) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Byte: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Byte"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Byte, rhs: Spark_Connect_DataType.Byte) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Short: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Short"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Short, rhs: Spark_Connect_DataType.Short) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Integer: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Integer"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Integer, rhs: Spark_Connect_DataType.Integer) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Long: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Long"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Long, rhs: Spark_Connect_DataType.Long) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.FloatMessage: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Float"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.FloatMessage, rhs: Spark_Connect_DataType.FloatMessage) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.DoubleMessage: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Double"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.DoubleMessage, rhs: Spark_Connect_DataType.DoubleMessage) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.StringMessage: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".String"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0\u{1}collation\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.collation) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    if !self.collation.isEmpty {
      try visitor.visitSingularStringField(value: self.collation, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.StringMessage, rhs: Spark_Connect_DataType.StringMessage) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.collation != rhs.collation {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Binary: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Binary"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Binary, rhs: Spark_Connect_DataType.Binary) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.NULL: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".NULL"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.NULL, rhs: Spark_Connect_DataType.NULL) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Timestamp: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Timestamp"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Timestamp, rhs: Spark_Connect_DataType.Timestamp) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Date: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Date"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Date, rhs: Spark_Connect_DataType.Date) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.TimestampNTZ: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".TimestampNTZ"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.TimestampNTZ, rhs: Spark_Connect_DataType.TimestampNTZ) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.CalendarInterval: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".CalendarInterval"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.CalendarInterval, rhs: Spark_Connect_DataType.CalendarInterval) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.YearMonthInterval: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".YearMonthInterval"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}start_field\0\u{3}end_field\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt32Field(value: &self._startField) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self._endField) }()
      case 3: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._startField {
      try visitor.visitSingularInt32Field(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._endField {
      try visitor.visitSingularInt32Field(value: v, fieldNumber: 2)
    } }()
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.YearMonthInterval, rhs: Spark_Connect_DataType.YearMonthInterval) -> Bool {
    if lhs._startField != rhs._startField {return false}
    if lhs._endField != rhs._endField {return false}
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.DayTimeInterval: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".DayTimeInterval"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}start_field\0\u{3}end_field\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt32Field(value: &self._startField) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self._endField) }()
      case 3: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._startField {
      try visitor.visitSingularInt32Field(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._endField {
      try visitor.visitSingularInt32Field(value: v, fieldNumber: 2)
    } }()
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.DayTimeInterval, rhs: Spark_Connect_DataType.DayTimeInterval) -> Bool {
    if lhs._startField != rhs._startField {return false}
    if lhs._endField != rhs._endField {return false}
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Char: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Char"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}length\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt32Field(value: &self.length) }()
      case 2: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.length != 0 {
      try visitor.visitSingularInt32Field(value: self.length, fieldNumber: 1)
    }
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Char, rhs: Spark_Connect_DataType.Char) -> Bool {
    if lhs.length != rhs.length {return false}
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.VarChar: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".VarChar"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}length\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt32Field(value: &self.length) }()
      case 2: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.length != 0 {
      try visitor.visitSingularInt32Field(value: self.length, fieldNumber: 1)
    }
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.VarChar, rhs: Spark_Connect_DataType.VarChar) -> Bool {
    if lhs.length != rhs.length {return false}
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Decimal: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Decimal"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}scale\0\u{1}precision\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularInt32Field(value: &self._scale) }()
      case 2: try { try decoder.decodeSingularInt32Field(value: &self._precision) }()
      case 3: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._scale {
      try visitor.visitSingularInt32Field(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._precision {
      try visitor.visitSingularInt32Field(value: v, fieldNumber: 2)
    } }()
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 3)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Decimal, rhs: Spark_Connect_DataType.Decimal) -> Bool {
    if lhs._scale != rhs._scale {return false}
    if lhs._precision != rhs._precision {return false}
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.StructField: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".StructField"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}name\0\u{3}data_type\0\u{1}nullable\0\u{1}metadata\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.name) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._dataType) }()
      case 3: try { try decoder.decodeSingularBoolField(value: &self.nullable) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self._metadata) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.name.isEmpty {
      try visitor.visitSingularStringField(value: self.name, fieldNumber: 1)
    }
    try { if let v = self._dataType {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    if self.nullable != false {
      try visitor.visitSingularBoolField(value: self.nullable, fieldNumber: 3)
    }
    try { if let v = self._metadata {
      try visitor.visitSingularStringField(value: v, fieldNumber: 4)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.StructField, rhs: Spark_Connect_DataType.StructField) -> Bool {
    if lhs.name != rhs.name {return false}
    if lhs._dataType != rhs._dataType {return false}
    if lhs.nullable != rhs.nullable {return false}
    if lhs._metadata != rhs._metadata {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Struct: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Struct"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}fields\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.fields) }()
      case 2: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.fields.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.fields, fieldNumber: 1)
    }
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Struct, rhs: Spark_Connect_DataType.Struct) -> Bool {
    if lhs.fields != rhs.fields {return false}
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Array: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Array"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}element_type\0\u{3}contains_null\0\u{3}type_variation_reference\0")

  fileprivate class _StorageClass {
    var _elementType: Spark_Connect_DataType? = nil
    var _containsNull: Bool = false
    var _typeVariationReference: UInt32 = 0

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _elementType = source._elementType
      _containsNull = source._containsNull
      _typeVariationReference = source._typeVariationReference
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._elementType) }()
        case 2: try { try decoder.decodeSingularBoolField(value: &_storage._containsNull) }()
        case 3: try { try decoder.decodeSingularUInt32Field(value: &_storage._typeVariationReference) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._elementType {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      } }()
      if _storage._containsNull != false {
        try visitor.visitSingularBoolField(value: _storage._containsNull, fieldNumber: 2)
      }
      if _storage._typeVariationReference != 0 {
        try visitor.visitSingularUInt32Field(value: _storage._typeVariationReference, fieldNumber: 3)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Array, rhs: Spark_Connect_DataType.Array) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._elementType != rhs_storage._elementType {return false}
        if _storage._containsNull != rhs_storage._containsNull {return false}
        if _storage._typeVariationReference != rhs_storage._typeVariationReference {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Map: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Map"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}key_type\0\u{3}value_type\0\u{3}value_contains_null\0\u{3}type_variation_reference\0")

  fileprivate class _StorageClass {
    var _keyType: Spark_Connect_DataType? = nil
    var _valueType: Spark_Connect_DataType? = nil
    var _valueContainsNull: Bool = false
    var _typeVariationReference: UInt32 = 0

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _keyType = source._keyType
      _valueType = source._valueType
      _valueContainsNull = source._valueContainsNull
      _typeVariationReference = source._typeVariationReference
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularMessageField(value: &_storage._keyType) }()
        case 2: try { try decoder.decodeSingularMessageField(value: &_storage._valueType) }()
        case 3: try { try decoder.decodeSingularBoolField(value: &_storage._valueContainsNull) }()
        case 4: try { try decoder.decodeSingularUInt32Field(value: &_storage._typeVariationReference) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      try { if let v = _storage._keyType {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
      } }()
      try { if let v = _storage._valueType {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
      } }()
      if _storage._valueContainsNull != false {
        try visitor.visitSingularBoolField(value: _storage._valueContainsNull, fieldNumber: 3)
      }
      if _storage._typeVariationReference != 0 {
        try visitor.visitSingularUInt32Field(value: _storage._typeVariationReference, fieldNumber: 4)
      }
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Map, rhs: Spark_Connect_DataType.Map) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._keyType != rhs_storage._keyType {return false}
        if _storage._valueType != rhs_storage._valueType {return false}
        if _storage._valueContainsNull != rhs_storage._valueContainsNull {return false}
        if _storage._typeVariationReference != rhs_storage._typeVariationReference {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Variant: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Variant"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}type_variation_reference\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularUInt32Field(value: &self.typeVariationReference) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if self.typeVariationReference != 0 {
      try visitor.visitSingularUInt32Field(value: self.typeVariationReference, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Variant, rhs: Spark_Connect_DataType.Variant) -> Bool {
    if lhs.typeVariationReference != rhs.typeVariationReference {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.UDT: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".UDT"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}type\0\u{3}jvm_class\0\u{3}python_class\0\u{3}serialized_python_class\0\u{3}sql_type\0")

  fileprivate class _StorageClass {
    var _type: String = String()
    var _jvmClass: String? = nil
    var _pythonClass: String? = nil
    var _serializedPythonClass: String? = nil
    var _sqlType: Spark_Connect_DataType? = nil

      // This property is used as the initial default value for new instances of the type.
      // The type itself is protecting the reference to its storage via CoW semantics.
      // This will force a copy to be made of this reference when the first mutation occurs;
      // hence, it is safe to mark this as `nonisolated(unsafe)`.
      static nonisolated(unsafe) let defaultInstance = _StorageClass()

    private init() {}

    init(copying source: _StorageClass) {
      _type = source._type
      _jvmClass = source._jvmClass
      _pythonClass = source._pythonClass
      _serializedPythonClass = source._serializedPythonClass
      _sqlType = source._sqlType
    }
  }

  fileprivate mutating func _uniqueStorage() -> _StorageClass {
    if !isKnownUniquelyReferenced(&_storage) {
      _storage = _StorageClass(copying: _storage)
    }
    return _storage
  }

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    _ = _uniqueStorage()
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      while let fieldNumber = try decoder.nextFieldNumber() {
        // The use of inline closures is to circumvent an issue where the compiler
        // allocates stack space for every case branch when no optimizations are
        // enabled. https://github.com/apple/swift-protobuf/issues/1034
        switch fieldNumber {
        case 1: try { try decoder.decodeSingularStringField(value: &_storage._type) }()
        case 2: try { try decoder.decodeSingularStringField(value: &_storage._jvmClass) }()
        case 3: try { try decoder.decodeSingularStringField(value: &_storage._pythonClass) }()
        case 4: try { try decoder.decodeSingularStringField(value: &_storage._serializedPythonClass) }()
        case 5: try { try decoder.decodeSingularMessageField(value: &_storage._sqlType) }()
        default: break
        }
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try withExtendedLifetime(_storage) { (_storage: _StorageClass) in
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every if/case branch local when no optimizations
      // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
      // https://github.com/apple/swift-protobuf/issues/1182
      if !_storage._type.isEmpty {
        try visitor.visitSingularStringField(value: _storage._type, fieldNumber: 1)
      }
      try { if let v = _storage._jvmClass {
        try visitor.visitSingularStringField(value: v, fieldNumber: 2)
      } }()
      try { if let v = _storage._pythonClass {
        try visitor.visitSingularStringField(value: v, fieldNumber: 3)
      } }()
      try { if let v = _storage._serializedPythonClass {
        try visitor.visitSingularStringField(value: v, fieldNumber: 4)
      } }()
      try { if let v = _storage._sqlType {
        try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
      } }()
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.UDT, rhs: Spark_Connect_DataType.UDT) -> Bool {
    if lhs._storage !== rhs._storage {
      let storagesAreEqual: Bool = withExtendedLifetime((lhs._storage, rhs._storage)) { (_args: (_StorageClass, _StorageClass)) in
        let _storage = _args.0
        let rhs_storage = _args.1
        if _storage._type != rhs_storage._type {return false}
        if _storage._jvmClass != rhs_storage._jvmClass {return false}
        if _storage._pythonClass != rhs_storage._pythonClass {return false}
        if _storage._serializedPythonClass != rhs_storage._serializedPythonClass {return false}
        if _storage._sqlType != rhs_storage._sqlType {return false}
        return true
      }
      if !storagesAreEqual {return false}
    }
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_DataType.Unparsed: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_DataType.protoMessageName + ".Unparsed"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}data_type_string\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularStringField(value: &self.dataTypeString) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    if !self.dataTypeString.isEmpty {
      try visitor.visitSingularStringField(value: self.dataTypeString, fieldNumber: 1)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_DataType.Unparsed, rhs: Spark_Connect_DataType.Unparsed) -> Bool {
    if lhs.dataTypeString != rhs.dataTypeString {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
