// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: spark/connect/ml.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

//
// Licensed to the Apache Software Foundation (ASF) under one or more
// contributor license agreements.  See the NOTICE file distributed with
// this work for additional information regarding copyright ownership.
// The ASF licenses this file to You under the Apache License, Version 2.0
// (the "License"); you may not use this file except in compliance with
// the License.  You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Command for ML
struct Spark_Connect_MlCommand: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var command: Spark_Connect_MlCommand.OneOf_Command? = nil

  var fit: Spark_Connect_MlCommand.Fit {
    get {
      if case .fit(let v)? = command {return v}
      return Spark_Connect_MlCommand.Fit()
    }
    set {command = .fit(newValue)}
  }

  var fetch: Spark_Connect_Fetch {
    get {
      if case .fetch(let v)? = command {return v}
      return Spark_Connect_Fetch()
    }
    set {command = .fetch(newValue)}
  }

  var delete: Spark_Connect_MlCommand.Delete {
    get {
      if case .delete(let v)? = command {return v}
      return Spark_Connect_MlCommand.Delete()
    }
    set {command = .delete(newValue)}
  }

  var write: Spark_Connect_MlCommand.Write {
    get {
      if case .write(let v)? = command {return v}
      return Spark_Connect_MlCommand.Write()
    }
    set {command = .write(newValue)}
  }

  var read: Spark_Connect_MlCommand.Read {
    get {
      if case .read(let v)? = command {return v}
      return Spark_Connect_MlCommand.Read()
    }
    set {command = .read(newValue)}
  }

  var evaluate: Spark_Connect_MlCommand.Evaluate {
    get {
      if case .evaluate(let v)? = command {return v}
      return Spark_Connect_MlCommand.Evaluate()
    }
    set {command = .evaluate(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_Command: Equatable, Sendable {
    case fit(Spark_Connect_MlCommand.Fit)
    case fetch(Spark_Connect_Fetch)
    case delete(Spark_Connect_MlCommand.Delete)
    case write(Spark_Connect_MlCommand.Write)
    case read(Spark_Connect_MlCommand.Read)
    case evaluate(Spark_Connect_MlCommand.Evaluate)

  }

  /// Command for estimator.fit(dataset)
  struct Fit: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) Estimator information (its type should be OPERATOR_TYPE_ESTIMATOR)
    var estimator: Spark_Connect_MlOperator {
      get {return _estimator ?? Spark_Connect_MlOperator()}
      set {_estimator = newValue}
    }
    /// Returns true if `estimator` has been explicitly set.
    var hasEstimator: Bool {return self._estimator != nil}
    /// Clears the value of `estimator`. Subsequent reads from it will return its default value.
    mutating func clearEstimator() {self._estimator = nil}

    /// (Optional) parameters of the Estimator
    var params: Spark_Connect_MlParams {
      get {return _params ?? Spark_Connect_MlParams()}
      set {_params = newValue}
    }
    /// Returns true if `params` has been explicitly set.
    var hasParams: Bool {return self._params != nil}
    /// Clears the value of `params`. Subsequent reads from it will return its default value.
    mutating func clearParams() {self._params = nil}

    /// (Required) the training dataset
    var dataset: Spark_Connect_Relation {
      get {return _dataset ?? Spark_Connect_Relation()}
      set {_dataset = newValue}
    }
    /// Returns true if `dataset` has been explicitly set.
    var hasDataset: Bool {return self._dataset != nil}
    /// Clears the value of `dataset`. Subsequent reads from it will return its default value.
    mutating func clearDataset() {self._dataset = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _estimator: Spark_Connect_MlOperator? = nil
    fileprivate var _params: Spark_Connect_MlParams? = nil
    fileprivate var _dataset: Spark_Connect_Relation? = nil
  }

  /// Command to delete the cached object which could be a model
  /// or summary evaluated by a model
  struct Delete: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var objRef: Spark_Connect_ObjectRef {
      get {return _objRef ?? Spark_Connect_ObjectRef()}
      set {_objRef = newValue}
    }
    /// Returns true if `objRef` has been explicitly set.
    var hasObjRef: Bool {return self._objRef != nil}
    /// Clears the value of `objRef`. Subsequent reads from it will return its default value.
    mutating func clearObjRef() {self._objRef = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _objRef: Spark_Connect_ObjectRef? = nil
  }

  /// Command to write ML operator
  struct Write: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// It could be an estimator/evaluator or the cached model
    var type: Spark_Connect_MlCommand.Write.OneOf_Type? = nil

    /// Estimator or evaluator
    var `operator`: Spark_Connect_MlOperator {
      get {
        if case .operator(let v)? = type {return v}
        return Spark_Connect_MlOperator()
      }
      set {type = .operator(newValue)}
    }

    /// The cached model
    var objRef: Spark_Connect_ObjectRef {
      get {
        if case .objRef(let v)? = type {return v}
        return Spark_Connect_ObjectRef()
      }
      set {type = .objRef(newValue)}
    }

    /// (Optional) The parameters of operator which could be estimator/evaluator or a cached model
    var params: Spark_Connect_MlParams {
      get {return _params ?? Spark_Connect_MlParams()}
      set {_params = newValue}
    }
    /// Returns true if `params` has been explicitly set.
    var hasParams: Bool {return self._params != nil}
    /// Clears the value of `params`. Subsequent reads from it will return its default value.
    mutating func clearParams() {self._params = nil}

    /// (Required) Save the ML instance to the path
    var path: String = String()

    /// (Optional) Overwrites if the output path already exists.
    var shouldOverwrite: Bool {
      get {return _shouldOverwrite ?? false}
      set {_shouldOverwrite = newValue}
    }
    /// Returns true if `shouldOverwrite` has been explicitly set.
    var hasShouldOverwrite: Bool {return self._shouldOverwrite != nil}
    /// Clears the value of `shouldOverwrite`. Subsequent reads from it will return its default value.
    mutating func clearShouldOverwrite() {self._shouldOverwrite = nil}

    /// (Optional) The options of the writer
    var options: Dictionary<String,String> = [:]

    var unknownFields = SwiftProtobuf.UnknownStorage()

    /// It could be an estimator/evaluator or the cached model
    enum OneOf_Type: Equatable, Sendable {
      /// Estimator or evaluator
      case `operator`(Spark_Connect_MlOperator)
      /// The cached model
      case objRef(Spark_Connect_ObjectRef)

    }

    init() {}

    fileprivate var _params: Spark_Connect_MlParams? = nil
    fileprivate var _shouldOverwrite: Bool? = nil
  }

  /// Command to load ML operator.
  struct Read: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) ML operator information
    var `operator`: Spark_Connect_MlOperator {
      get {return _operator ?? Spark_Connect_MlOperator()}
      set {_operator = newValue}
    }
    /// Returns true if ``operator`` has been explicitly set.
    var hasOperator: Bool {return self._operator != nil}
    /// Clears the value of ``operator``. Subsequent reads from it will return its default value.
    mutating func clearOperator() {self._operator = nil}

    /// (Required) Load the ML instance from the input path
    var path: String = String()

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _operator: Spark_Connect_MlOperator? = nil
  }

  /// Command for evaluator.evaluate(dataset)
  struct Evaluate: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) Evaluator information (its type should be OPERATOR_TYPE_EVALUATOR)
    var evaluator: Spark_Connect_MlOperator {
      get {return _evaluator ?? Spark_Connect_MlOperator()}
      set {_evaluator = newValue}
    }
    /// Returns true if `evaluator` has been explicitly set.
    var hasEvaluator: Bool {return self._evaluator != nil}
    /// Clears the value of `evaluator`. Subsequent reads from it will return its default value.
    mutating func clearEvaluator() {self._evaluator = nil}

    /// (Optional) parameters of the Evaluator
    var params: Spark_Connect_MlParams {
      get {return _params ?? Spark_Connect_MlParams()}
      set {_params = newValue}
    }
    /// Returns true if `params` has been explicitly set.
    var hasParams: Bool {return self._params != nil}
    /// Clears the value of `params`. Subsequent reads from it will return its default value.
    mutating func clearParams() {self._params = nil}

    /// (Required) the evaluating dataset
    var dataset: Spark_Connect_Relation {
      get {return _dataset ?? Spark_Connect_Relation()}
      set {_dataset = newValue}
    }
    /// Returns true if `dataset` has been explicitly set.
    var hasDataset: Bool {return self._dataset != nil}
    /// Clears the value of `dataset`. Subsequent reads from it will return its default value.
    mutating func clearDataset() {self._dataset = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _evaluator: Spark_Connect_MlOperator? = nil
    fileprivate var _params: Spark_Connect_MlParams? = nil
    fileprivate var _dataset: Spark_Connect_Relation? = nil
  }

  init() {}
}

/// The result of MlCommand
struct Spark_Connect_MlCommandResult: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var resultType: Spark_Connect_MlCommandResult.OneOf_ResultType? = nil

  /// The result of the attribute
  var param: Spark_Connect_Expression.Literal {
    get {
      if case .param(let v)? = resultType {return v}
      return Spark_Connect_Expression.Literal()
    }
    set {resultType = .param(newValue)}
  }

  /// Evaluate a Dataset in a model and return the cached ID of summary
  var summary: String {
    get {
      if case .summary(let v)? = resultType {return v}
      return String()
    }
    set {resultType = .summary(newValue)}
  }

  /// Operator information
  var operatorInfo: Spark_Connect_MlCommandResult.MlOperatorInfo {
    get {
      if case .operatorInfo(let v)? = resultType {return v}
      return Spark_Connect_MlCommandResult.MlOperatorInfo()
    }
    set {resultType = .operatorInfo(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_ResultType: Equatable, Sendable {
    /// The result of the attribute
    case param(Spark_Connect_Expression.Literal)
    /// Evaluate a Dataset in a model and return the cached ID of summary
    case summary(String)
    /// Operator information
    case operatorInfo(Spark_Connect_MlCommandResult.MlOperatorInfo)

  }

  /// Represents an operator info
  struct MlOperatorInfo: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var type: Spark_Connect_MlCommandResult.MlOperatorInfo.OneOf_Type? = nil

    /// The cached object which could be a model or summary evaluated by a model
    var objRef: Spark_Connect_ObjectRef {
      get {
        if case .objRef(let v)? = type {return v}
        return Spark_Connect_ObjectRef()
      }
      set {type = .objRef(newValue)}
    }

    /// Operator name
    var name: String {
      get {
        if case .name(let v)? = type {return v}
        return String()
      }
      set {type = .name(newValue)}
    }

    /// (Optional) the 'uid' of a ML object
    /// Note it is different from the 'id' of a cached object.
    var uid: String {
      get {return _uid ?? String()}
      set {_uid = newValue}
    }
    /// Returns true if `uid` has been explicitly set.
    var hasUid: Bool {return self._uid != nil}
    /// Clears the value of `uid`. Subsequent reads from it will return its default value.
    mutating func clearUid() {self._uid = nil}

    /// (Optional) parameters
    var params: Spark_Connect_MlParams {
      get {return _params ?? Spark_Connect_MlParams()}
      set {_params = newValue}
    }
    /// Returns true if `params` has been explicitly set.
    var hasParams: Bool {return self._params != nil}
    /// Clears the value of `params`. Subsequent reads from it will return its default value.
    mutating func clearParams() {self._params = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    enum OneOf_Type: Equatable, Sendable {
      /// The cached object which could be a model or summary evaluated by a model
      case objRef(Spark_Connect_ObjectRef)
      /// Operator name
      case name(String)

    }

    init() {}

    fileprivate var _uid: String? = nil
    fileprivate var _params: Spark_Connect_MlParams? = nil
  }

  init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "spark.connect"

extension Spark_Connect_MlCommand: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".MlCommand"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "fit"),
    2: .same(proto: "fetch"),
    3: .same(proto: "delete"),
    4: .same(proto: "write"),
    5: .same(proto: "read"),
    6: .same(proto: "evaluate"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Spark_Connect_MlCommand.Fit?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .fit(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .fit(v)
        }
      }()
      case 2: try {
        var v: Spark_Connect_Fetch?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .fetch(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .fetch(v)
        }
      }()
      case 3: try {
        var v: Spark_Connect_MlCommand.Delete?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .delete(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .delete(v)
        }
      }()
      case 4: try {
        var v: Spark_Connect_MlCommand.Write?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .write(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .write(v)
        }
      }()
      case 5: try {
        var v: Spark_Connect_MlCommand.Read?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .read(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .read(v)
        }
      }()
      case 6: try {
        var v: Spark_Connect_MlCommand.Evaluate?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .evaluate(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .evaluate(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.command {
    case .fit?: try {
      guard case .fit(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .fetch?: try {
      guard case .fetch(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case .delete?: try {
      guard case .delete(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case .write?: try {
      guard case .write(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }()
    case .read?: try {
      guard case .read(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }()
    case .evaluate?: try {
      guard case .evaluate(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand, rhs: Spark_Connect_MlCommand) -> Bool {
    if lhs.command != rhs.command {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommand.Fit: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommand.protoMessageName + ".Fit"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "estimator"),
    2: .same(proto: "params"),
    3: .same(proto: "dataset"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._estimator) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._params) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._dataset) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._estimator {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._params {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._dataset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand.Fit, rhs: Spark_Connect_MlCommand.Fit) -> Bool {
    if lhs._estimator != rhs._estimator {return false}
    if lhs._params != rhs._params {return false}
    if lhs._dataset != rhs._dataset {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommand.Delete: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommand.protoMessageName + ".Delete"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "obj_ref"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._objRef) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._objRef {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand.Delete, rhs: Spark_Connect_MlCommand.Delete) -> Bool {
    if lhs._objRef != rhs._objRef {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommand.Write: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommand.protoMessageName + ".Write"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "operator"),
    2: .standard(proto: "obj_ref"),
    3: .same(proto: "params"),
    4: .same(proto: "path"),
    5: .standard(proto: "should_overwrite"),
    6: .same(proto: "options"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Spark_Connect_MlOperator?
        var hadOneofValue = false
        if let current = self.type {
          hadOneofValue = true
          if case .operator(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.type = .operator(v)
        }
      }()
      case 2: try {
        var v: Spark_Connect_ObjectRef?
        var hadOneofValue = false
        if let current = self.type {
          hadOneofValue = true
          if case .objRef(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.type = .objRef(v)
        }
      }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._params) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.path) }()
      case 5: try { try decoder.decodeSingularBoolField(value: &self._shouldOverwrite) }()
      case 6: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &self.options) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.type {
    case .operator?: try {
      guard case .operator(let v)? = self.type else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .objRef?: try {
      guard case .objRef(let v)? = self.type else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try { if let v = self._params {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    if !self.path.isEmpty {
      try visitor.visitSingularStringField(value: self.path, fieldNumber: 4)
    }
    try { if let v = self._shouldOverwrite {
      try visitor.visitSingularBoolField(value: v, fieldNumber: 5)
    } }()
    if !self.options.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: self.options, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand.Write, rhs: Spark_Connect_MlCommand.Write) -> Bool {
    if lhs.type != rhs.type {return false}
    if lhs._params != rhs._params {return false}
    if lhs.path != rhs.path {return false}
    if lhs._shouldOverwrite != rhs._shouldOverwrite {return false}
    if lhs.options != rhs.options {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommand.Read: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommand.protoMessageName + ".Read"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "operator"),
    2: .same(proto: "path"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._operator) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.path) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._operator {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.path.isEmpty {
      try visitor.visitSingularStringField(value: self.path, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand.Read, rhs: Spark_Connect_MlCommand.Read) -> Bool {
    if lhs._operator != rhs._operator {return false}
    if lhs.path != rhs.path {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommand.Evaluate: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommand.protoMessageName + ".Evaluate"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "evaluator"),
    2: .same(proto: "params"),
    3: .same(proto: "dataset"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._evaluator) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._params) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._dataset) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._evaluator {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._params {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._dataset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand.Evaluate, rhs: Spark_Connect_MlCommand.Evaluate) -> Bool {
    if lhs._evaluator != rhs._evaluator {return false}
    if lhs._params != rhs._params {return false}
    if lhs._dataset != rhs._dataset {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommandResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".MlCommandResult"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .same(proto: "param"),
    2: .same(proto: "summary"),
    3: .standard(proto: "operator_info"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Spark_Connect_Expression.Literal?
        var hadOneofValue = false
        if let current = self.resultType {
          hadOneofValue = true
          if case .param(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.resultType = .param(v)
        }
      }()
      case 2: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.resultType != nil {try decoder.handleConflictingOneOf()}
          self.resultType = .summary(v)
        }
      }()
      case 3: try {
        var v: Spark_Connect_MlCommandResult.MlOperatorInfo?
        var hadOneofValue = false
        if let current = self.resultType {
          hadOneofValue = true
          if case .operatorInfo(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.resultType = .operatorInfo(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.resultType {
    case .param?: try {
      guard case .param(let v)? = self.resultType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .summary?: try {
      guard case .summary(let v)? = self.resultType else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    }()
    case .operatorInfo?: try {
      guard case .operatorInfo(let v)? = self.resultType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommandResult, rhs: Spark_Connect_MlCommandResult) -> Bool {
    if lhs.resultType != rhs.resultType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommandResult.MlOperatorInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommandResult.protoMessageName + ".MlOperatorInfo"
  static let _protobuf_nameMap: SwiftProtobuf._NameMap = [
    1: .standard(proto: "obj_ref"),
    2: .same(proto: "name"),
    3: .same(proto: "uid"),
    4: .same(proto: "params"),
  ]

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Spark_Connect_ObjectRef?
        var hadOneofValue = false
        if let current = self.type {
          hadOneofValue = true
          if case .objRef(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.type = .objRef(v)
        }
      }()
      case 2: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.type != nil {try decoder.handleConflictingOneOf()}
          self.type = .name(v)
        }
      }()
      case 3: try { try decoder.decodeSingularStringField(value: &self._uid) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._params) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.type {
    case .objRef?: try {
      guard case .objRef(let v)? = self.type else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .name?: try {
      guard case .name(let v)? = self.type else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try { if let v = self._uid {
      try visitor.visitSingularStringField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._params {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommandResult.MlOperatorInfo, rhs: Spark_Connect_MlCommandResult.MlOperatorInfo) -> Bool {
    if lhs.type != rhs.type {return false}
    if lhs._uid != rhs._uid {return false}
    if lhs._params != rhs._params {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
