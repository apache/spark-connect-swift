// DO NOT EDIT.
// swift-format-ignore-file
// swiftlint:disable all
//
// Generated by the Swift generator plugin for the protocol buffer compiler.
// Source: spark/connect/ml.proto
//
// For information on using the generated types, please see the documentation:
//   https://github.com/apple/swift-protobuf/

//
// Licensed to the Apache Software Foundation (ASF) under one or more
// contributor license agreements.  See the NOTICE file distributed with
// this work for additional information regarding copyright ownership.
// The ASF licenses this file to You under the Apache License, Version 2.0
// (the "License"); you may not use this file except in compliance with
// the License.  You may obtain a copy of the License at
//
//    http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

import SwiftProtobuf

// If the compiler emits an error on this type, it is because this file
// was generated by a version of the `protoc` Swift plug-in that is
// incompatible with the version of SwiftProtobuf to which you are linking.
// Please ensure that you are building against the same version of the API
// that was used to generate this file.
fileprivate struct _GeneratedWithProtocGenSwiftVersion: SwiftProtobuf.ProtobufAPIVersionCheck {
  struct _2: SwiftProtobuf.ProtobufAPIVersion_2 {}
  typealias Version = _2
}

/// Command for ML
struct Spark_Connect_MlCommand: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var command: Spark_Connect_MlCommand.OneOf_Command? = nil

  var fit: Spark_Connect_MlCommand.Fit {
    get {
      if case .fit(let v)? = command {return v}
      return Spark_Connect_MlCommand.Fit()
    }
    set {command = .fit(newValue)}
  }

  var fetch: Spark_Connect_Fetch {
    get {
      if case .fetch(let v)? = command {return v}
      return Spark_Connect_Fetch()
    }
    set {command = .fetch(newValue)}
  }

  var delete: Spark_Connect_MlCommand.Delete {
    get {
      if case .delete(let v)? = command {return v}
      return Spark_Connect_MlCommand.Delete()
    }
    set {command = .delete(newValue)}
  }

  var write: Spark_Connect_MlCommand.Write {
    get {
      if case .write(let v)? = command {return v}
      return Spark_Connect_MlCommand.Write()
    }
    set {command = .write(newValue)}
  }

  var read: Spark_Connect_MlCommand.Read {
    get {
      if case .read(let v)? = command {return v}
      return Spark_Connect_MlCommand.Read()
    }
    set {command = .read(newValue)}
  }

  var evaluate: Spark_Connect_MlCommand.Evaluate {
    get {
      if case .evaluate(let v)? = command {return v}
      return Spark_Connect_MlCommand.Evaluate()
    }
    set {command = .evaluate(newValue)}
  }

  var cleanCache: Spark_Connect_MlCommand.CleanCache {
    get {
      if case .cleanCache(let v)? = command {return v}
      return Spark_Connect_MlCommand.CleanCache()
    }
    set {command = .cleanCache(newValue)}
  }

  var getCacheInfo: Spark_Connect_MlCommand.GetCacheInfo {
    get {
      if case .getCacheInfo(let v)? = command {return v}
      return Spark_Connect_MlCommand.GetCacheInfo()
    }
    set {command = .getCacheInfo(newValue)}
  }

  var createSummary: Spark_Connect_MlCommand.CreateSummary {
    get {
      if case .createSummary(let v)? = command {return v}
      return Spark_Connect_MlCommand.CreateSummary()
    }
    set {command = .createSummary(newValue)}
  }

  var getModelSize: Spark_Connect_MlCommand.GetModelSize {
    get {
      if case .getModelSize(let v)? = command {return v}
      return Spark_Connect_MlCommand.GetModelSize()
    }
    set {command = .getModelSize(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_Command: Equatable, Sendable {
    case fit(Spark_Connect_MlCommand.Fit)
    case fetch(Spark_Connect_Fetch)
    case delete(Spark_Connect_MlCommand.Delete)
    case write(Spark_Connect_MlCommand.Write)
    case read(Spark_Connect_MlCommand.Read)
    case evaluate(Spark_Connect_MlCommand.Evaluate)
    case cleanCache(Spark_Connect_MlCommand.CleanCache)
    case getCacheInfo(Spark_Connect_MlCommand.GetCacheInfo)
    case createSummary(Spark_Connect_MlCommand.CreateSummary)
    case getModelSize(Spark_Connect_MlCommand.GetModelSize)

  }

  /// Command for estimator.fit(dataset)
  struct Fit: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) Estimator information (its type should be OPERATOR_TYPE_ESTIMATOR)
    var estimator: Spark_Connect_MlOperator {
      get {return _estimator ?? Spark_Connect_MlOperator()}
      set {_estimator = newValue}
    }
    /// Returns true if `estimator` has been explicitly set.
    var hasEstimator: Bool {return self._estimator != nil}
    /// Clears the value of `estimator`. Subsequent reads from it will return its default value.
    mutating func clearEstimator() {self._estimator = nil}

    /// (Optional) parameters of the Estimator
    var params: Spark_Connect_MlParams {
      get {return _params ?? Spark_Connect_MlParams()}
      set {_params = newValue}
    }
    /// Returns true if `params` has been explicitly set.
    var hasParams: Bool {return self._params != nil}
    /// Clears the value of `params`. Subsequent reads from it will return its default value.
    mutating func clearParams() {self._params = nil}

    /// (Required) the training dataset
    var dataset: Spark_Connect_Relation {
      get {return _dataset ?? Spark_Connect_Relation()}
      set {_dataset = newValue}
    }
    /// Returns true if `dataset` has been explicitly set.
    var hasDataset: Bool {return self._dataset != nil}
    /// Clears the value of `dataset`. Subsequent reads from it will return its default value.
    mutating func clearDataset() {self._dataset = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _estimator: Spark_Connect_MlOperator? = nil
    fileprivate var _params: Spark_Connect_MlParams? = nil
    fileprivate var _dataset: Spark_Connect_Relation? = nil
  }

  /// Command to delete the cached objects which could be a model
  /// or summary evaluated by a model
  struct Delete: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var objRefs: [Spark_Connect_ObjectRef] = []

    /// if set `evict_only` to true, only evict the cached model from memory,
    /// but keep the offloaded model in Spark driver local disk.
    var evictOnly: Bool {
      get {return _evictOnly ?? false}
      set {_evictOnly = newValue}
    }
    /// Returns true if `evictOnly` has been explicitly set.
    var hasEvictOnly: Bool {return self._evictOnly != nil}
    /// Clears the value of `evictOnly`. Subsequent reads from it will return its default value.
    mutating func clearEvictOnly() {self._evictOnly = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _evictOnly: Bool? = nil
  }

  /// Force to clean up all the ML cached objects
  struct CleanCache: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  /// Get the information of all the ML cached objects
  struct GetCacheInfo: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}
  }

  /// Command to write ML operator
  struct Write: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// It could be an estimator/evaluator or the cached model
    var type: Spark_Connect_MlCommand.Write.OneOf_Type? = nil

    /// Estimator or evaluator
    var `operator`: Spark_Connect_MlOperator {
      get {
        if case .operator(let v)? = type {return v}
        return Spark_Connect_MlOperator()
      }
      set {type = .operator(newValue)}
    }

    /// The cached model
    var objRef: Spark_Connect_ObjectRef {
      get {
        if case .objRef(let v)? = type {return v}
        return Spark_Connect_ObjectRef()
      }
      set {type = .objRef(newValue)}
    }

    /// (Optional) The parameters of operator which could be estimator/evaluator or a cached model
    var params: Spark_Connect_MlParams {
      get {return _params ?? Spark_Connect_MlParams()}
      set {_params = newValue}
    }
    /// Returns true if `params` has been explicitly set.
    var hasParams: Bool {return self._params != nil}
    /// Clears the value of `params`. Subsequent reads from it will return its default value.
    mutating func clearParams() {self._params = nil}

    /// (Required) Save the ML instance to the path
    var path: String = String()

    /// (Optional) Overwrites if the output path already exists.
    var shouldOverwrite: Bool {
      get {return _shouldOverwrite ?? false}
      set {_shouldOverwrite = newValue}
    }
    /// Returns true if `shouldOverwrite` has been explicitly set.
    var hasShouldOverwrite: Bool {return self._shouldOverwrite != nil}
    /// Clears the value of `shouldOverwrite`. Subsequent reads from it will return its default value.
    mutating func clearShouldOverwrite() {self._shouldOverwrite = nil}

    /// (Optional) The options of the writer
    var options: Dictionary<String,String> = [:]

    var unknownFields = SwiftProtobuf.UnknownStorage()

    /// It could be an estimator/evaluator or the cached model
    enum OneOf_Type: Equatable, Sendable {
      /// Estimator or evaluator
      case `operator`(Spark_Connect_MlOperator)
      /// The cached model
      case objRef(Spark_Connect_ObjectRef)

    }

    init() {}

    fileprivate var _params: Spark_Connect_MlParams? = nil
    fileprivate var _shouldOverwrite: Bool? = nil
  }

  /// Command to load ML operator.
  struct Read: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) ML operator information
    var `operator`: Spark_Connect_MlOperator {
      get {return _operator ?? Spark_Connect_MlOperator()}
      set {_operator = newValue}
    }
    /// Returns true if ``operator`` has been explicitly set.
    var hasOperator: Bool {return self._operator != nil}
    /// Clears the value of ``operator``. Subsequent reads from it will return its default value.
    mutating func clearOperator() {self._operator = nil}

    /// (Required) Load the ML instance from the input path
    var path: String = String()

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _operator: Spark_Connect_MlOperator? = nil
  }

  /// Command for evaluator.evaluate(dataset)
  struct Evaluate: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    /// (Required) Evaluator information (its type should be OPERATOR_TYPE_EVALUATOR)
    var evaluator: Spark_Connect_MlOperator {
      get {return _evaluator ?? Spark_Connect_MlOperator()}
      set {_evaluator = newValue}
    }
    /// Returns true if `evaluator` has been explicitly set.
    var hasEvaluator: Bool {return self._evaluator != nil}
    /// Clears the value of `evaluator`. Subsequent reads from it will return its default value.
    mutating func clearEvaluator() {self._evaluator = nil}

    /// (Optional) parameters of the Evaluator
    var params: Spark_Connect_MlParams {
      get {return _params ?? Spark_Connect_MlParams()}
      set {_params = newValue}
    }
    /// Returns true if `params` has been explicitly set.
    var hasParams: Bool {return self._params != nil}
    /// Clears the value of `params`. Subsequent reads from it will return its default value.
    mutating func clearParams() {self._params = nil}

    /// (Required) the evaluating dataset
    var dataset: Spark_Connect_Relation {
      get {return _dataset ?? Spark_Connect_Relation()}
      set {_dataset = newValue}
    }
    /// Returns true if `dataset` has been explicitly set.
    var hasDataset: Bool {return self._dataset != nil}
    /// Clears the value of `dataset`. Subsequent reads from it will return its default value.
    mutating func clearDataset() {self._dataset = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _evaluator: Spark_Connect_MlOperator? = nil
    fileprivate var _params: Spark_Connect_MlParams? = nil
    fileprivate var _dataset: Spark_Connect_Relation? = nil
  }

  /// This is for re-creating the model summary when the model summary is lost
  /// (model summary is lost when the model is offloaded and then loaded back)
  struct CreateSummary: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var modelRef: Spark_Connect_ObjectRef {
      get {return _modelRef ?? Spark_Connect_ObjectRef()}
      set {_modelRef = newValue}
    }
    /// Returns true if `modelRef` has been explicitly set.
    var hasModelRef: Bool {return self._modelRef != nil}
    /// Clears the value of `modelRef`. Subsequent reads from it will return its default value.
    mutating func clearModelRef() {self._modelRef = nil}

    var dataset: Spark_Connect_Relation {
      get {return _dataset ?? Spark_Connect_Relation()}
      set {_dataset = newValue}
    }
    /// Returns true if `dataset` has been explicitly set.
    var hasDataset: Bool {return self._dataset != nil}
    /// Clears the value of `dataset`. Subsequent reads from it will return its default value.
    mutating func clearDataset() {self._dataset = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _modelRef: Spark_Connect_ObjectRef? = nil
    fileprivate var _dataset: Spark_Connect_Relation? = nil
  }

  /// This is for query the model estimated in-memory size
  struct GetModelSize: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var modelRef: Spark_Connect_ObjectRef {
      get {return _modelRef ?? Spark_Connect_ObjectRef()}
      set {_modelRef = newValue}
    }
    /// Returns true if `modelRef` has been explicitly set.
    var hasModelRef: Bool {return self._modelRef != nil}
    /// Clears the value of `modelRef`. Subsequent reads from it will return its default value.
    mutating func clearModelRef() {self._modelRef = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    init() {}

    fileprivate var _modelRef: Spark_Connect_ObjectRef? = nil
  }

  init() {}
}

/// The result of MlCommand
struct Spark_Connect_MlCommandResult: Sendable {
  // SwiftProtobuf.Message conformance is added in an extension below. See the
  // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
  // methods supported on all messages.

  var resultType: Spark_Connect_MlCommandResult.OneOf_ResultType? = nil

  /// The result of the attribute
  var param: Spark_Connect_Expression.Literal {
    get {
      if case .param(let v)? = resultType {return v}
      return Spark_Connect_Expression.Literal()
    }
    set {resultType = .param(newValue)}
  }

  /// Evaluate a Dataset in a model and return the cached ID of summary
  var summary: String {
    get {
      if case .summary(let v)? = resultType {return v}
      return String()
    }
    set {resultType = .summary(newValue)}
  }

  /// Operator information
  var operatorInfo: Spark_Connect_MlCommandResult.MlOperatorInfo {
    get {
      if case .operatorInfo(let v)? = resultType {return v}
      return Spark_Connect_MlCommandResult.MlOperatorInfo()
    }
    set {resultType = .operatorInfo(newValue)}
  }

  var unknownFields = SwiftProtobuf.UnknownStorage()

  enum OneOf_ResultType: Equatable, Sendable {
    /// The result of the attribute
    case param(Spark_Connect_Expression.Literal)
    /// Evaluate a Dataset in a model and return the cached ID of summary
    case summary(String)
    /// Operator information
    case operatorInfo(Spark_Connect_MlCommandResult.MlOperatorInfo)

  }

  /// Represents an operator info
  struct MlOperatorInfo: Sendable {
    // SwiftProtobuf.Message conformance is added in an extension below. See the
    // `Message` and `Message+*Additions` files in the SwiftProtobuf library for
    // methods supported on all messages.

    var type: Spark_Connect_MlCommandResult.MlOperatorInfo.OneOf_Type? = nil

    /// The cached object which could be a model or summary evaluated by a model
    var objRef: Spark_Connect_ObjectRef {
      get {
        if case .objRef(let v)? = type {return v}
        return Spark_Connect_ObjectRef()
      }
      set {type = .objRef(newValue)}
    }

    /// Operator name
    var name: String {
      get {
        if case .name(let v)? = type {return v}
        return String()
      }
      set {type = .name(newValue)}
    }

    /// (Optional) the 'uid' of a ML object
    /// Note it is different from the 'id' of a cached object.
    var uid: String {
      get {return _uid ?? String()}
      set {_uid = newValue}
    }
    /// Returns true if `uid` has been explicitly set.
    var hasUid: Bool {return self._uid != nil}
    /// Clears the value of `uid`. Subsequent reads from it will return its default value.
    mutating func clearUid() {self._uid = nil}

    /// (Optional) parameters
    var params: Spark_Connect_MlParams {
      get {return _params ?? Spark_Connect_MlParams()}
      set {_params = newValue}
    }
    /// Returns true if `params` has been explicitly set.
    var hasParams: Bool {return self._params != nil}
    /// Clears the value of `params`. Subsequent reads from it will return its default value.
    mutating func clearParams() {self._params = nil}

    /// (Optional) warning message generated during the ML command execution
    var warningMessage: String {
      get {return _warningMessage ?? String()}
      set {_warningMessage = newValue}
    }
    /// Returns true if `warningMessage` has been explicitly set.
    var hasWarningMessage: Bool {return self._warningMessage != nil}
    /// Clears the value of `warningMessage`. Subsequent reads from it will return its default value.
    mutating func clearWarningMessage() {self._warningMessage = nil}

    var unknownFields = SwiftProtobuf.UnknownStorage()

    enum OneOf_Type: Equatable, Sendable {
      /// The cached object which could be a model or summary evaluated by a model
      case objRef(Spark_Connect_ObjectRef)
      /// Operator name
      case name(String)

    }

    init() {}

    fileprivate var _uid: String? = nil
    fileprivate var _params: Spark_Connect_MlParams? = nil
    fileprivate var _warningMessage: String? = nil
  }

  init() {}
}

// MARK: - Code below here is support for the SwiftProtobuf runtime.

fileprivate let _protobuf_package = "spark.connect"

extension Spark_Connect_MlCommand: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".MlCommand"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}fit\0\u{1}fetch\0\u{1}delete\0\u{1}write\0\u{1}read\0\u{1}evaluate\0\u{3}clean_cache\0\u{3}get_cache_info\0\u{3}create_summary\0\u{3}get_model_size\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Spark_Connect_MlCommand.Fit?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .fit(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .fit(v)
        }
      }()
      case 2: try {
        var v: Spark_Connect_Fetch?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .fetch(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .fetch(v)
        }
      }()
      case 3: try {
        var v: Spark_Connect_MlCommand.Delete?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .delete(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .delete(v)
        }
      }()
      case 4: try {
        var v: Spark_Connect_MlCommand.Write?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .write(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .write(v)
        }
      }()
      case 5: try {
        var v: Spark_Connect_MlCommand.Read?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .read(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .read(v)
        }
      }()
      case 6: try {
        var v: Spark_Connect_MlCommand.Evaluate?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .evaluate(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .evaluate(v)
        }
      }()
      case 7: try {
        var v: Spark_Connect_MlCommand.CleanCache?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .cleanCache(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .cleanCache(v)
        }
      }()
      case 8: try {
        var v: Spark_Connect_MlCommand.GetCacheInfo?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .getCacheInfo(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .getCacheInfo(v)
        }
      }()
      case 9: try {
        var v: Spark_Connect_MlCommand.CreateSummary?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .createSummary(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .createSummary(v)
        }
      }()
      case 10: try {
        var v: Spark_Connect_MlCommand.GetModelSize?
        var hadOneofValue = false
        if let current = self.command {
          hadOneofValue = true
          if case .getModelSize(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.command = .getModelSize(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.command {
    case .fit?: try {
      guard case .fit(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .fetch?: try {
      guard case .fetch(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case .delete?: try {
      guard case .delete(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case .write?: try {
      guard case .write(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    }()
    case .read?: try {
      guard case .read(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 5)
    }()
    case .evaluate?: try {
      guard case .evaluate(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 6)
    }()
    case .cleanCache?: try {
      guard case .cleanCache(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 7)
    }()
    case .getCacheInfo?: try {
      guard case .getCacheInfo(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 8)
    }()
    case .createSummary?: try {
      guard case .createSummary(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 9)
    }()
    case .getModelSize?: try {
      guard case .getModelSize(let v)? = self.command else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 10)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand, rhs: Spark_Connect_MlCommand) -> Bool {
    if lhs.command != rhs.command {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommand.Fit: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommand.protoMessageName + ".Fit"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}estimator\0\u{1}params\0\u{1}dataset\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._estimator) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._params) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._dataset) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._estimator {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._params {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._dataset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand.Fit, rhs: Spark_Connect_MlCommand.Fit) -> Bool {
    if lhs._estimator != rhs._estimator {return false}
    if lhs._params != rhs._params {return false}
    if lhs._dataset != rhs._dataset {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommand.Delete: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommand.protoMessageName + ".Delete"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}obj_refs\0\u{3}evict_only\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeRepeatedMessageField(value: &self.objRefs) }()
      case 2: try { try decoder.decodeSingularBoolField(value: &self._evictOnly) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    if !self.objRefs.isEmpty {
      try visitor.visitRepeatedMessageField(value: self.objRefs, fieldNumber: 1)
    }
    try { if let v = self._evictOnly {
      try visitor.visitSingularBoolField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand.Delete, rhs: Spark_Connect_MlCommand.Delete) -> Bool {
    if lhs.objRefs != rhs.objRefs {return false}
    if lhs._evictOnly != rhs._evictOnly {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommand.CleanCache: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommand.protoMessageName + ".CleanCache"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    // Load everything into unknown fields
    while try decoder.nextFieldNumber() != nil {}
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand.CleanCache, rhs: Spark_Connect_MlCommand.CleanCache) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommand.GetCacheInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommand.protoMessageName + ".GetCacheInfo"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap()

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    // Load everything into unknown fields
    while try decoder.nextFieldNumber() != nil {}
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand.GetCacheInfo, rhs: Spark_Connect_MlCommand.GetCacheInfo) -> Bool {
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommand.Write: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommand.protoMessageName + ".Write"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}operator\0\u{3}obj_ref\0\u{1}params\0\u{1}path\0\u{3}should_overwrite\0\u{1}options\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Spark_Connect_MlOperator?
        var hadOneofValue = false
        if let current = self.type {
          hadOneofValue = true
          if case .operator(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.type = .operator(v)
        }
      }()
      case 2: try {
        var v: Spark_Connect_ObjectRef?
        var hadOneofValue = false
        if let current = self.type {
          hadOneofValue = true
          if case .objRef(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.type = .objRef(v)
        }
      }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._params) }()
      case 4: try { try decoder.decodeSingularStringField(value: &self.path) }()
      case 5: try { try decoder.decodeSingularBoolField(value: &self._shouldOverwrite) }()
      case 6: try { try decoder.decodeMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: &self.options) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.type {
    case .operator?: try {
      guard case .operator(let v)? = self.type else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .objRef?: try {
      guard case .objRef(let v)? = self.type else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try { if let v = self._params {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    if !self.path.isEmpty {
      try visitor.visitSingularStringField(value: self.path, fieldNumber: 4)
    }
    try { if let v = self._shouldOverwrite {
      try visitor.visitSingularBoolField(value: v, fieldNumber: 5)
    } }()
    if !self.options.isEmpty {
      try visitor.visitMapField(fieldType: SwiftProtobuf._ProtobufMap<SwiftProtobuf.ProtobufString,SwiftProtobuf.ProtobufString>.self, value: self.options, fieldNumber: 6)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand.Write, rhs: Spark_Connect_MlCommand.Write) -> Bool {
    if lhs.type != rhs.type {return false}
    if lhs._params != rhs._params {return false}
    if lhs.path != rhs.path {return false}
    if lhs._shouldOverwrite != rhs._shouldOverwrite {return false}
    if lhs.options != rhs.options {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommand.Read: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommand.protoMessageName + ".Read"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}operator\0\u{1}path\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._operator) }()
      case 2: try { try decoder.decodeSingularStringField(value: &self.path) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._operator {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    if !self.path.isEmpty {
      try visitor.visitSingularStringField(value: self.path, fieldNumber: 2)
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand.Read, rhs: Spark_Connect_MlCommand.Read) -> Bool {
    if lhs._operator != rhs._operator {return false}
    if lhs.path != rhs.path {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommand.Evaluate: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommand.protoMessageName + ".Evaluate"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}evaluator\0\u{1}params\0\u{1}dataset\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._evaluator) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._params) }()
      case 3: try { try decoder.decodeSingularMessageField(value: &self._dataset) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._evaluator {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._params {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try { if let v = self._dataset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand.Evaluate, rhs: Spark_Connect_MlCommand.Evaluate) -> Bool {
    if lhs._evaluator != rhs._evaluator {return false}
    if lhs._params != rhs._params {return false}
    if lhs._dataset != rhs._dataset {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommand.CreateSummary: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommand.protoMessageName + ".CreateSummary"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}model_ref\0\u{1}dataset\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._modelRef) }()
      case 2: try { try decoder.decodeSingularMessageField(value: &self._dataset) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._modelRef {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try { if let v = self._dataset {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 2)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand.CreateSummary, rhs: Spark_Connect_MlCommand.CreateSummary) -> Bool {
    if lhs._modelRef != rhs._modelRef {return false}
    if lhs._dataset != rhs._dataset {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommand.GetModelSize: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommand.protoMessageName + ".GetModelSize"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}model_ref\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try { try decoder.decodeSingularMessageField(value: &self._modelRef) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    try { if let v = self._modelRef {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommand.GetModelSize, rhs: Spark_Connect_MlCommand.GetModelSize) -> Bool {
    if lhs._modelRef != rhs._modelRef {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommandResult: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = _protobuf_package + ".MlCommandResult"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{1}param\0\u{1}summary\0\u{3}operator_info\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Spark_Connect_Expression.Literal?
        var hadOneofValue = false
        if let current = self.resultType {
          hadOneofValue = true
          if case .param(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.resultType = .param(v)
        }
      }()
      case 2: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.resultType != nil {try decoder.handleConflictingOneOf()}
          self.resultType = .summary(v)
        }
      }()
      case 3: try {
        var v: Spark_Connect_MlCommandResult.MlOperatorInfo?
        var hadOneofValue = false
        if let current = self.resultType {
          hadOneofValue = true
          if case .operatorInfo(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.resultType = .operatorInfo(v)
        }
      }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.resultType {
    case .param?: try {
      guard case .param(let v)? = self.resultType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .summary?: try {
      guard case .summary(let v)? = self.resultType else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    }()
    case .operatorInfo?: try {
      guard case .operatorInfo(let v)? = self.resultType else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 3)
    }()
    case nil: break
    }
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommandResult, rhs: Spark_Connect_MlCommandResult) -> Bool {
    if lhs.resultType != rhs.resultType {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}

extension Spark_Connect_MlCommandResult.MlOperatorInfo: SwiftProtobuf.Message, SwiftProtobuf._MessageImplementationBase, SwiftProtobuf._ProtoNameProviding {
  static let protoMessageName: String = Spark_Connect_MlCommandResult.protoMessageName + ".MlOperatorInfo"
  static let _protobuf_nameMap = SwiftProtobuf._NameMap(bytecode: "\0\u{3}obj_ref\0\u{1}name\0\u{1}uid\0\u{1}params\0\u{3}warning_message\0")

  mutating func decodeMessage<D: SwiftProtobuf.Decoder>(decoder: inout D) throws {
    while let fieldNumber = try decoder.nextFieldNumber() {
      // The use of inline closures is to circumvent an issue where the compiler
      // allocates stack space for every case branch when no optimizations are
      // enabled. https://github.com/apple/swift-protobuf/issues/1034
      switch fieldNumber {
      case 1: try {
        var v: Spark_Connect_ObjectRef?
        var hadOneofValue = false
        if let current = self.type {
          hadOneofValue = true
          if case .objRef(let m) = current {v = m}
        }
        try decoder.decodeSingularMessageField(value: &v)
        if let v = v {
          if hadOneofValue {try decoder.handleConflictingOneOf()}
          self.type = .objRef(v)
        }
      }()
      case 2: try {
        var v: String?
        try decoder.decodeSingularStringField(value: &v)
        if let v = v {
          if self.type != nil {try decoder.handleConflictingOneOf()}
          self.type = .name(v)
        }
      }()
      case 3: try { try decoder.decodeSingularStringField(value: &self._uid) }()
      case 4: try { try decoder.decodeSingularMessageField(value: &self._params) }()
      case 5: try { try decoder.decodeSingularStringField(value: &self._warningMessage) }()
      default: break
      }
    }
  }

  func traverse<V: SwiftProtobuf.Visitor>(visitor: inout V) throws {
    // The use of inline closures is to circumvent an issue where the compiler
    // allocates stack space for every if/case branch local when no optimizations
    // are enabled. https://github.com/apple/swift-protobuf/issues/1034 and
    // https://github.com/apple/swift-protobuf/issues/1182
    switch self.type {
    case .objRef?: try {
      guard case .objRef(let v)? = self.type else { preconditionFailure() }
      try visitor.visitSingularMessageField(value: v, fieldNumber: 1)
    }()
    case .name?: try {
      guard case .name(let v)? = self.type else { preconditionFailure() }
      try visitor.visitSingularStringField(value: v, fieldNumber: 2)
    }()
    case nil: break
    }
    try { if let v = self._uid {
      try visitor.visitSingularStringField(value: v, fieldNumber: 3)
    } }()
    try { if let v = self._params {
      try visitor.visitSingularMessageField(value: v, fieldNumber: 4)
    } }()
    try { if let v = self._warningMessage {
      try visitor.visitSingularStringField(value: v, fieldNumber: 5)
    } }()
    try unknownFields.traverse(visitor: &visitor)
  }

  static func ==(lhs: Spark_Connect_MlCommandResult.MlOperatorInfo, rhs: Spark_Connect_MlCommandResult.MlOperatorInfo) -> Bool {
    if lhs.type != rhs.type {return false}
    if lhs._uid != rhs._uid {return false}
    if lhs._params != rhs._params {return false}
    if lhs._warningMessage != rhs._warningMessage {return false}
    if lhs.unknownFields != rhs.unknownFields {return false}
    return true
  }
}
